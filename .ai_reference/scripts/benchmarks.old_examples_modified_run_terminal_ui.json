{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\benchmarks.old\\examples\\modified\\run_terminal_ui.py",
  "imports": [
    {
      "name": "os",
      "line": 15
    },
    {
      "name": "sys",
      "line": 16
    },
    {
      "name": "time",
      "line": 17
    },
    {
      "name": "argparse",
      "line": 18
    },
    {
      "name": "logging",
      "line": 19
    },
    {
      "name": "torch",
      "line": 20
    },
    {
      "name": "torch.nn",
      "line": 21
    },
    {
      "name": "torch.optim",
      "line": 22
    },
    {
      "name": "torchvision",
      "line": 23
    },
    {
      "name": "torchvision.transforms",
      "line": 24
    },
    {
      "name": "datetime.datetime",
      "line": 25
    },
    {
      "name": "typing.Dict",
      "line": 26
    },
    {
      "name": "typing.List",
      "line": 26
    },
    {
      "name": "typing.Any",
      "line": 26
    },
    {
      "name": "typing.Optional",
      "line": 26
    },
    {
      "name": "typing.Tuple",
      "line": 26
    },
    {
      "name": "terminal_ui.TerminalUI",
      "line": 32
    },
    {
      "name": "terminal_ui.UrwidTerminalUI",
      "line": 32
    },
    {
      "name": "hardware_diagnostics.HardwareDiagnostics",
      "line": 41
    },
    {
      "name": "training_monitor.TrainingMonitor",
      "line": 42
    },
    {
      "name": "simplified_pattern_mapping.SimplifiedPatternMapper",
      "line": 43
    },
    {
      "name": "urwid_compatibility.wrap_urwid_ui",
      "line": 36
    },
    {
      "name": "isekaizen.optimizers.eve_unified_ratio.EVEUnifiedRatio",
      "line": 47
    },
    {
      "name": "terminal_ui.UrwidTerminalUI",
      "line": 369
    }
  ],
  "classes": {},
  "functions": {
    "get_model": {
      "start_line": 58,
      "end_line": 83,
      "parameters": [
        {
          "name": "model_name",
          "type": "str"
        },
        {
          "name": "num_classes",
          "type": "int"
        },
        {
          "name": "pretrained",
          "type": "bool"
        }
      ],
      "return_type": null,
      "calls": [
        {
          "name": "torchvision.models.resnet18",
          "line": 61
        },
        {
          "name": "nn.Linear",
          "line": 62
        },
        {
          "name": "torchvision.models.resnet34",
          "line": 64
        },
        {
          "name": "nn.Linear",
          "line": 65
        },
        {
          "name": "torchvision.models.resnet50",
          "line": 67
        },
        {
          "name": "nn.Linear",
          "line": 68
        },
        {
          "name": "torchvision.models.vgg16",
          "line": 70
        },
        {
          "name": "nn.Linear",
          "line": 71
        },
        {
          "name": "torchvision.models.mobilenet_v2",
          "line": 73
        },
        {
          "name": "nn.Linear",
          "line": 74
        },
        {
          "name": "torchvision.models.efficientnet_b0",
          "line": 76
        },
        {
          "name": "nn.Linear",
          "line": 77
        },
        {
          "name": "ValueError",
          "line": 79
        }
      ],
      "docstring": "Get a PyTorch model by name",
      "code_snippet": "\n\ndef get_model(model_name: str, num_classes: int = 10, pretrained: bool = False) -> nn.Module:\n    \"\"\"Get a PyTorch model by name\"\"\"\n    if model_name == \"resnet18\":\n        model = torchvision.models.resnet18(weights='IMAGENET1K_V1' if pretrained else None)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    elif model_name == \"resnet34\":\n        model = torchvision.models.resnet34(weights='IMAGENET1K_V1' if pretrained else None)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    elif model_name == \"resnet50\":\n        model = torchvision.models.resnet50(weights='IMAGENET1K_V1' if pretrained else None)\n        model.fc = nn.Linear(model.fc.in_features, num_classes)\n    elif model_name == \"vgg16\":\n        model = torchvision.models.vgg16(weights='IMAGENET1K_V1' if pretrained else None)\n        model.classifier[6] = nn.Linear(4096, num_classes)\n    elif model_name == \"mobilenet_v2\":\n        model = torchvision.models.mobilenet_v2(weights='IMAGENET1K_V1' if pretrained else None)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    elif model_name == \"efficientnet_b0\":\n        model = torchvision.models.efficientnet_b0(weights='IMAGENET1K_V1' if pretrained else None)\n        model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n    else:\n        raise ValueError(f\"Unsupported model: {model_name}\")\n    \n    return model\n\n\ndef get_dataset(dataset_name: str, input_size: int = 224, augment: bool = True) -> Tuple[Any, Any]:\n    \"\"\"Get a PyTorch dataset by name\"\"\""
    },
    "get_dataset": {
      "start_line": 84,
      "end_line": 151,
      "parameters": [
        {
          "name": "dataset_name",
          "type": "str"
        },
        {
          "name": "input_size",
          "type": "int"
        },
        {
          "name": "augment",
          "type": "bool"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "transforms.Compose",
          "line": 103
        },
        {
          "name": "torchvision.datasets.CIFAR10",
          "line": 110
        },
        {
          "name": "torchvision.datasets.CIFAR10",
          "line": 113
        },
        {
          "name": "transforms.Compose",
          "line": 89
        },
        {
          "name": "transforms.Compose",
          "line": 97
        },
        {
          "name": "transforms.Compose",
          "line": 133
        },
        {
          "name": "torchvision.datasets.CIFAR100",
          "line": 140
        },
        {
          "name": "torchvision.datasets.CIFAR100",
          "line": 143
        },
        {
          "name": "ValueError",
          "line": 147
        },
        {
          "name": "transforms.Resize",
          "line": 104
        },
        {
          "name": "transforms.ToTensor",
          "line": 105
        },
        {
          "name": "transforms.Normalize",
          "line": 106
        },
        {
          "name": "transforms.Compose",
          "line": 119
        },
        {
          "name": "transforms.Compose",
          "line": 127
        },
        {
          "name": "transforms.Resize",
          "line": 90
        },
        {
          "name": "transforms.RandomCrop",
          "line": 91
        },
        {
          "name": "transforms.RandomHorizontalFlip",
          "line": 92
        },
        {
          "name": "transforms.ToTensor",
          "line": 93
        },
        {
          "name": "transforms.Normalize",
          "line": 94
        },
        {
          "name": "transforms.Resize",
          "line": 98
        },
        {
          "name": "transforms.ToTensor",
          "line": 99
        },
        {
          "name": "transforms.Normalize",
          "line": 100
        },
        {
          "name": "transforms.Resize",
          "line": 134
        },
        {
          "name": "transforms.ToTensor",
          "line": 135
        },
        {
          "name": "transforms.Normalize",
          "line": 136
        },
        {
          "name": "transforms.Resize",
          "line": 120
        },
        {
          "name": "transforms.RandomCrop",
          "line": 121
        },
        {
          "name": "transforms.RandomHorizontalFlip",
          "line": 122
        },
        {
          "name": "transforms.ToTensor",
          "line": 123
        },
        {
          "name": "transforms.Normalize",
          "line": 124
        },
        {
          "name": "transforms.Resize",
          "line": 128
        },
        {
          "name": "transforms.ToTensor",
          "line": 129
        },
        {
          "name": "transforms.Normalize",
          "line": 130
        }
      ],
      "docstring": "Get a PyTorch dataset by name",
      "code_snippet": "\n\ndef get_dataset(dataset_name: str, input_size: int = 224, augment: bool = True) -> Tuple[Any, Any]:\n    \"\"\"Get a PyTorch dataset by name\"\"\"\n    if dataset_name == \"cifar10\":\n        # Define transformations\n        if augment:\n            train_transform = transforms.Compose([\n                transforms.Resize(input_size),\n                transforms.RandomCrop(input_size, padding=4),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n            ])\n        else:\n            train_transform = transforms.Compose([\n                transforms.Resize(input_size),\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n            ])\n        \n        test_transform = transforms.Compose([\n            transforms.Resize(input_size),\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n        ])\n        \n        # Load datasets\n        trainset = torchvision.datasets.CIFAR10(\n            root='./data', train=True, download=True, transform=train_transform)\n        \n        testset = torchvision.datasets.CIFAR10(\n            root='./data', train=False, download=True, transform=test_transform)\n    \n    elif dataset_name == \"cifar100\":\n        # Define transformations\n        if augment:\n            train_transform = transforms.Compose([\n                transforms.Resize(input_size),\n                transforms.RandomCrop(input_size, padding=4),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n            ])\n        else:\n            train_transform = transforms.Compose([\n                transforms.Resize(input_size),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n            ])\n        \n        test_transform = transforms.Compose([\n            transforms.Resize(input_size),\n            transforms.ToTensor(),\n            transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n        ])\n        \n        # Load datasets\n        trainset = torchvision.datasets.CIFAR100(\n            root='./data', train=True, download=True, transform=train_transform)\n        \n        testset = torchvision.datasets.CIFAR100(\n            root='./data', train=False, download=True, transform=test_transform)\n    \n    else:\n        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n    \n    return trainset, testset\n\n\ndef train_model(\n    model: nn.Module,"
    },
    "train_model": {
      "start_line": 152,
      "end_line": 350,
      "parameters": [
        {
          "name": "model"
        },
        {
          "name": "trainset",
          "type": "Any"
        },
        {
          "name": "testset",
          "type": "Any"
        },
        {
          "name": "settings"
        },
        {
          "name": "ui",
          "type": "TerminalUI"
        },
        {
          "name": "use_isekaizen",
          "type": "bool"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "torch.device",
          "line": 162
        },
        {
          "name": "model.to",
          "line": 163
        },
        {
          "name": "TrainingMonitor",
          "line": 166
        },
        {
          "name": "settings.get",
          "line": 169
        },
        {
          "name": "nn.CrossEntropyLoss",
          "line": 172
        },
        {
          "name": "torch.utils.data.DataLoader",
          "line": 192
        },
        {
          "name": "torch.utils.data.DataLoader",
          "line": 195
        },
        {
          "name": "time.time",
          "line": 209
        },
        {
          "name": "range",
          "line": 211
        },
        {
          "name": "monitor.get_final_metrics",
          "line": 331
        },
        {
          "name": "ui.end_training_ui",
          "line": 341
        },
        {
          "name": "EVEUnifiedRatio",
          "line": 177
        },
        {
          "name": "optim.SGD",
          "line": 184
        },
        {
          "name": "model.train",
          "line": 213
        },
        {
          "name": "hasattr",
          "line": 219
        },
        {
          "name": "hasattr",
          "line": 224
        },
        {
          "name": "enumerate",
          "line": 235
        },
        {
          "name": "model.eval",
          "line": 277
        },
        {
          "name": "....append",
          "line": 309
        },
        {
          "name": "....append",
          "line": 310
        },
        {
          "name": "....append",
          "line": 311
        },
        {
          "name": "....append",
          "line": 312
        },
        {
          "name": "....append",
          "line": 313
        },
        {
          "name": "....append",
          "line": 314
        },
        {
          "name": "monitor.update",
          "line": 317
        },
        {
          "name": "monitor._get_gpu_memory_info",
          "line": 320
        },
        {
          "name": "ui.display_training_progress",
          "line": 321
        },
        {
          "name": "settings.get",
          "line": 333
        },
        {
          "name": "settings.get",
          "line": 334
        },
        {
          "name": "torch.cuda.is_available",
          "line": 162
        },
        {
          "name": "model.parameters",
          "line": 178
        },
        {
          "name": "model.parameters",
          "line": 185
        },
        {
          "name": "optimizer.get_current_batch_size",
          "line": 220
        },
        {
          "name": "optimizer.get_current_lr",
          "line": 225
        },
        {
          "name": "torch.utils.data.DataLoader",
          "line": 231
        },
        {
          "name": "optimizer.zero_grad",
          "line": 238
        },
        {
          "name": "model",
          "line": 239
        },
        {
          "name": "criterion",
          "line": 240
        },
        {
          "name": "loss.backward",
          "line": 241
        },
        {
          "name": "optimizer.step",
          "line": 242
        },
        {
          "name": "loss.item",
          "line": 244
        },
        {
          "name": "outputs.max",
          "line": 245
        },
        {
          "name": "targets.size",
          "line": 246
        },
        {
          "name": "....item",
          "line": 247
        },
        {
          "name": "torch.no_grad",
          "line": 282
        },
        {
          "name": "len",
          "line": 294
        },
        {
          "name": "len",
          "line": 296
        },
        {
          "name": "len",
          "line": 230
        },
        {
          "name": "inputs.to",
          "line": 236
        },
        {
          "name": "targets.to",
          "line": 236
        },
        {
          "name": "torch.cuda.is_available",
          "line": 257
        },
        {
          "name": "ui.display_training_progress",
          "line": 267
        },
        {
          "name": "model",
          "line": 285
        },
        {
          "name": "criterion",
          "line": 286
        },
        {
          "name": "loss.item",
          "line": 288
        },
        {
          "name": "outputs.max",
          "line": 289
        },
        {
          "name": "targets.size",
          "line": 290
        },
        {
          "name": "....item",
          "line": 291
        },
        {
          "name": "....sum",
          "line": 247
        },
        {
          "name": "inputs.to",
          "line": 284
        },
        {
          "name": "targets.to",
          "line": 284
        },
        {
          "name": "time.time",
          "line": 327
        },
        {
          "name": "torch.cuda.memory_allocated",
          "line": 259
        },
        {
          "name": "torch.cuda.memory_reserved",
          "line": 260
        },
        {
          "name": "....sum",
          "line": 291
        },
        {
          "name": "predicted.eq",
          "line": 247
        },
        {
          "name": "torch.cuda.get_device_properties",
          "line": 261
        },
        {
          "name": "time.time",
          "line": 273
        },
        {
          "name": "predicted.eq",
          "line": 291
        }
      ],
      "docstring": "Train a model with the specified settings and display progress using the terminal UI",
      "code_snippet": "\n\ndef train_model(\n    model: nn.Module,\n    trainset: Any,\n    testset: Any,\n    settings: Dict[str, Any],\n    ui: TerminalUI,\n    use_isekaizen: bool = True\n) -> Dict[str, Any]:\n    \"\"\"Train a model with the specified settings and display progress using the terminal UI\"\"\"\n    # Set device\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = model.to(device)\n    \n    # Create monitor\n    monitor = TrainingMonitor(model)\n    \n    # Set initial parameters\n    epochs = settings.get(\"epochs\", 15)\n    initial_batch_size = 64\n    initial_lr = 0.01\n    criterion = nn.CrossEntropyLoss()\n    \n    # Create optimizer\n    if use_isekaizen and ISEKAIZEN_AVAILABLE:\n        # Use IsekaiZen optimizer\n        optimizer = EVEUnifiedRatio(\n            model.parameters(),\n            lr=initial_lr,\n            weight_decay=5e-4\n        )\n    else:\n        # Fall back to SGD\n        optimizer = optim.SGD(\n            model.parameters(),\n            lr=initial_lr,\n            momentum=0.9,\n            weight_decay=5e-4\n        )\n    \n    # Create dataloaders\n    train_loader = torch.utils.data.DataLoader(\n        trainset, batch_size=initial_batch_size, shuffle=True, num_workers=2)\n    \n    test_loader = torch.utils.data.DataLoader(\n        testset, batch_size=100, shuffle=False, num_workers=2)\n    \n    # Initialize training metrics\n    history = {\n        \"train_loss\": [],\n        \"train_acc\": [],\n        \"val_loss\": [],\n        \"val_acc\": [],\n        \"batch_sizes\": [],\n        \"learning_rates\": []\n    }\n    \n    # Train the model\n    start_time = time.time()\n    \n    for epoch in range(1, epochs + 1):\n        # Training\n        model.train()\n        train_loss = 0.0\n        correct = 0\n        total = 0\n        \n        # Get current batch size and learning rate\n        if hasattr(optimizer, \"get_current_batch_size\"):\n            batch_size = optimizer.get_current_batch_size()\n        else:\n            batch_size = initial_batch_size\n        \n        if hasattr(optimizer, \"get_current_lr\"):\n            lr = optimizer.get_current_lr()\n        else:\n            lr = optimizer.param_groups[0]['lr']\n        \n        # Update dataloader if batch size changed\n        if len(history[\"batch_sizes\"]) > 0 and batch_size != history[\"batch_sizes\"][-1]:\n            train_loader = torch.utils.data.DataLoader(\n                trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n        \n        # Train for one epoch\n        for i, (inputs, targets) in enumerate(train_loader):\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            \n            train_loss += loss.item()\n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            \n            if i % 50 == 0:\n                # Update UI every 50 batches\n                epoch_progress = {\n                    \"train_loss\": train_loss / (i + 1),\n                    \"train_acc\": 100 * correct / total if total > 0 else 0\n                }\n                \n                # Get memory usage\n                if torch.cuda.is_available():\n                    memory_usage = {\n                        \"allocated\": torch.cuda.memory_allocated(),\n                        \"reserved\": torch.cuda.memory_reserved(),\n                        \"total\": torch.cuda.get_device_properties(0).total_memory\n                    }\n                else:\n                    memory_usage = {\"allocated\": 0, \"reserved\": 0, \"total\": 0}\n                \n                # Display progress\n                ui.display_training_progress(\n                    epoch=epoch,\n                    total_epochs=epochs,\n                    metrics=epoch_progress,\n                    batch_size=batch_size,\n                    memory_usage=memory_usage,\n                    elapsed_time=time.time() - start_time\n                )\n        \n        # Validation\n        model.eval()\n        val_loss = 0.0\n        correct = 0\n        total = 0\n        \n        with torch.no_grad():\n            for inputs, targets in test_loader:\n                inputs, targets = inputs.to(device), targets.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, targets)\n                \n                val_loss += loss.item()\n                _, predicted = outputs.max(1)\n                total += targets.size(0)\n                correct += predicted.eq(targets).sum().item()\n        \n        # Calculate epoch metrics\n        train_loss = train_loss / len(train_loader)\n        train_acc = 100 * correct / total if total > 0 else 0\n        val_loss = val_loss / len(test_loader)\n        val_acc = 100 * correct / total if total > 0 else 0\n        \n        # Update metrics\n        epoch_metrics = {\n            \"train_loss\": train_loss,\n            \"train_acc\": train_acc,\n            \"val_loss\": val_loss,\n            \"val_acc\": val_acc,\n            \"learning_rate\": lr\n        }\n        \n        # Update history\n        history[\"train_loss\"].append(train_loss)\n        history[\"train_acc\"].append(train_acc)\n        history[\"val_loss\"].append(val_loss)\n        history[\"val_acc\"].append(val_acc)\n        history[\"batch_sizes\"].append(batch_size)\n        history[\"learning_rates\"].append(lr)\n        \n        # Update monitor\n        monitor.update(epoch, epoch_metrics, batch_size, lr)\n        \n        # Display full epoch results\n        memory_usage = monitor._get_gpu_memory_info()\n        ui.display_training_progress(\n            epoch=epoch,\n            total_epochs=epochs,\n            metrics=epoch_metrics,\n            batch_size=batch_size,\n            memory_usage=memory_usage,\n            elapsed_time=time.time() - start_time\n        )\n    \n    # Get final metrics and model info\n    final_metrics = monitor.get_final_metrics()\n    model_info = {\n        \"model_type\": settings.get(\"model_type\"),\n        \"dataset_type\": settings.get(\"dataset_type\"),\n        \"model\": model,\n        \"parameter_count\": final_metrics[\"model\"][\"parameter_count\"],\n        \"model_size\": final_metrics[\"model\"][\"model_size\"]\n    }\n    \n    # End training UI\n    ui.end_training_ui(history, model_info, final_metrics)\n    \n    # Return results\n    return {\n        \"history\": history,\n        \"model\": model,\n        \"model_info\": model_info,\n        \"metrics\": final_metrics\n    }\n\n\ndef main():"
    },
    "main": {
      "start_line": 352,
      "end_line": 461,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "argparse.ArgumentParser",
          "line": 355
        },
        {
          "name": "parser.add_argument",
          "line": 356
        },
        {
          "name": "parser.add_argument",
          "line": 357
        },
        {
          "name": "parser.add_argument",
          "line": 358
        },
        {
          "name": "parser.add_argument",
          "line": 359
        },
        {
          "name": "parser.add_argument",
          "line": 360
        },
        {
          "name": "parser.add_argument",
          "line": 361
        },
        {
          "name": "parser.add_argument",
          "line": 362
        },
        {
          "name": "parser.parse_args",
          "line": 363
        },
        {
          "name": "TerminalUI",
          "line": 394
        },
        {
          "name": "get_model",
          "line": 437
        },
        {
          "name": "get_dataset",
          "line": 443
        },
        {
          "name": "train_model",
          "line": 450
        },
        {
          "name": "print",
          "line": 459
        },
        {
          "name": "print",
          "line": 368
        },
        {
          "name": "UrwidTerminalUI",
          "line": 370
        },
        {
          "name": "ui.run",
          "line": 371
        },
        {
          "name": "settings.get",
          "line": 374
        },
        {
          "name": "settings.get",
          "line": 375
        },
        {
          "name": "settings.get",
          "line": 376
        },
        {
          "name": "print",
          "line": 384
        },
        {
          "name": "print",
          "line": 388
        },
        {
          "name": "print",
          "line": 390
        },
        {
          "name": "sys.exit",
          "line": 391
        },
        {
          "name": "ui.display_header",
          "line": 398
        },
        {
          "name": "print",
          "line": 399
        },
        {
          "name": "HardwareDiagnostics",
          "line": 400
        },
        {
          "name": "diagnostics.run_full_diagnostics",
          "line": 401
        },
        {
          "name": "diagnostics.print_summary",
          "line": 402
        },
        {
          "name": "print",
          "line": 403
        },
        {
          "name": "input",
          "line": 404
        },
        {
          "name": "ui.start_training_ui",
          "line": 423
        },
        {
          "name": "ui.display_header",
          "line": 427
        },
        {
          "name": "print",
          "line": 428
        },
        {
          "name": "SimplifiedPatternMapper",
          "line": 430
        },
        {
          "name": "mapper.run_mapping",
          "line": 431
        },
        {
          "name": "....startswith",
          "line": 456
        }
      ],
      "docstring": "Main function to run terminal UI and training process",
      "code_snippet": "\n\ndef main():\n    \"\"\"Main function to run terminal UI and training process\"\"\"\n    # Parse command-line arguments\n    parser = argparse.ArgumentParser(description=\"IsekaiZen ML Optimizer Terminal UI\")\n    parser.add_argument(\"--no-ui\", action=\"store_true\", help=\"Run without interactive UI (use default settings)\")\n    parser.add_argument(\"--model\", type=str, default=\"resnet18\", help=\"Model architecture\")\n    parser.add_argument(\"--dataset\", type=str, default=\"cifar10\", help=\"Dataset name\")\n    parser.add_argument(\"--epochs\", type=int, default=15, help=\"Number of training epochs\")\n    parser.add_argument(\"--skip-diagnostics\", action=\"store_true\", help=\"Skip hardware diagnostics\")\n    parser.add_argument(\"--skip-mapping\", action=\"store_true\", help=\"Skip pattern mapping\")\n    parser.add_argument(\"--basic-ui\", action=\"store_true\", help=\"Use basic UI instead of urwid UI\")\n    args = parser.parse_args()\n    \n    # Use urwid UI exclusively when requested (default unless --basic-ui is specified)\n    if not args.basic_ui and not args.no_ui:\n        # Use the urwid UI\n        print(\"Starting urwid UI...\")\n        from terminal_ui import UrwidTerminalUI\n        ui = UrwidTerminalUI()\n        settings = ui.run()\n        \n        # Update args with settings from urwid UI\n        args.model = settings.get('model_type', args.model)\n        args.dataset = settings.get('dataset_type', args.dataset)\n        args.epochs = settings.get('epochs', args.epochs)\n        \n        # Set flags to skip further UI selection\n        args.no_ui = True  \n        args.skip_diagnostics = True\n        args.skip_mapping = True\n        \n        # Show selected settings\n        print(f\"\\nSelected settings: {settings}\")\n        \n        # We'll stop here and only train with terminal UI\n        # This makes it clear if there's an issue with the urwid UI\n        print(\"\\nExiting urwid UI mode. To train with these settings, run:\")\n        cmd = f\"python {sys.argv[0]} --no-ui --model {args.model} --dataset {args.dataset} --epochs {args.epochs}\"\n        print(f\"  {cmd}\")\n        sys.exit(0)\n    \n    # If we got here, we're using the basic Terminal UI or no UI\n    ui = TerminalUI()\n    \n    # Run hardware diagnostics\n    if not args.skip_diagnostics:\n        ui.display_header(\"Hardware Diagnostics\")\n        print(\"\\nRunning hardware diagnostics...\")\n        diagnostics = HardwareDiagnostics()\n        diagnostics.run_full_diagnostics()\n        diagnostics.print_summary()\n        print(\"\\nPress Enter to continue...\")\n        input()\n    \n    # Get user settings\n    if args.no_ui:\n        # Non-interactive mode with command line arguments\n        settings = {\n            'model_type': args.model,\n            'dataset_type': args.dataset,\n            'epochs': args.epochs,\n            'optimizer': 'eve_unified' if ISEKAIZEN_AVAILABLE else 'sgd',\n            'use_pretrained': False,\n            'input_size': 224 if args.model in [\"resnet50\", \"vgg16\"] else 32,\n            'num_classes': 10 if args.dataset == \"cifar10\" else 100,\n            'weight_range': 'default',\n            'lr_sensitivity': 'high',\n            'use_augmentation': True\n        }\n    else:\n        # Interactive UI mode\n        settings = ui.start_training_ui()\n    \n    # Run pattern mapping if not skipped\n    if not args.skip_mapping:\n        ui.display_header(\"Pattern Mapping\")\n        print(\"\\nRunning pattern mapping for dataset...\")\n        \n        mapper = SimplifiedPatternMapper()\n        pattern_map = mapper.run_mapping(\n            dataset_name=settings['dataset_type'],\n            sample_limit=1000  # Use smaller sample for quicker mapping\n        )\n    \n    # Load model and dataset\n    model = get_model(\n        settings['model_type'],\n        num_classes=settings['num_classes'],\n        pretrained=settings['use_pretrained']\n    )\n    \n    trainset, testset = get_dataset(\n        settings['dataset_type'],\n        input_size=settings['input_size'],\n        augment=settings['use_augmentation']\n    )\n    \n    # Train model\n    results = train_model(\n        model=model,\n        trainset=trainset,\n        testset=testset,\n        settings=settings,\n        ui=ui,\n        use_isekaizen=settings['optimizer'].startswith('eve') and ISEKAIZEN_AVAILABLE\n    )\n    \n    print(\"\\nTraining complete. Thank you for using IsekaiZen ML Optimizer!\")\n\n\nif __name__ == \"__main__\":\n    main()"
    }
  },
  "constants": {}
}