{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\tools\\pattern_mapper.py",
  "imports": [
    {
      "name": "sys",
      "line": 2
    },
    {
      "name": "os",
      "line": 25
    },
    {
      "name": "sys",
      "line": 26
    },
    {
      "name": "json",
      "line": 27
    },
    {
      "name": "time",
      "line": 28
    },
    {
      "name": "logging",
      "line": 29
    },
    {
      "name": "argparse",
      "line": 30
    },
    {
      "name": "numpy",
      "line": 31
    },
    {
      "name": "torch",
      "line": 32
    },
    {
      "name": "torch.nn",
      "line": 33
    },
    {
      "name": "torch.cuda",
      "line": 34
    },
    {
      "name": "torchvision",
      "line": 35
    },
    {
      "name": "torchvision.transforms",
      "line": 36
    },
    {
      "name": "datetime.datetime",
      "line": 37
    },
    {
      "name": "typing.Dict",
      "line": 38
    },
    {
      "name": "typing.List",
      "line": 38
    },
    {
      "name": "typing.Any",
      "line": 38
    },
    {
      "name": "typing.Optional",
      "line": 38
    },
    {
      "name": "typing.Tuple",
      "line": 38
    },
    {
      "name": "typing.Union",
      "line": 38
    },
    {
      "name": "isekaizen.configs.PATTERN_MAPS_DIR",
      "line": 41
    },
    {
      "name": "isekaizen.configs.MODELS_DIR",
      "line": 41
    },
    {
      "name": "isekaizen.configs.METRICS_DIR",
      "line": 41
    },
    {
      "name": "isekaizen.core.models.architecture.create_model",
      "line": 48
    },
    {
      "name": "isekaizen.pattern.bias_testing.test_pattern_bias",
      "line": 49
    },
    {
      "name": "isekaizen.pattern.pre_augmentation.create_pattern_biased_augmentations",
      "line": 50
    },
    {
      "name": "isekaizen.pattern.pre_augmentation.save_augmentation_data",
      "line": 50
    },
    {
      "name": "isekaizen.pattern.detection.generate_pattern_map_for_non_image_dataset",
      "line": 1101
    },
    {
      "name": "signal",
      "line": 1561
    },
    {
      "name": "sys",
      "line": 1741
    },
    {
      "name": "multiprocessing",
      "line": 1742
    },
    {
      "name": "matplotlib.pyplot",
      "line": 739
    },
    {
      "name": "traceback",
      "line": 1731
    },
    {
      "name": "multiprocessing",
      "line": 227
    },
    {
      "name": "math",
      "line": 261
    },
    {
      "name": "psutil",
      "line": 234
    }
  ],
  "classes": {
    "BatchProcessedPatternMapper": {
      "start_line": 60,
      "end_line": 813,
      "methods": {
        "__init__": {
          "start_line": 68,
          "end_line": 94,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "output_dir",
              "type": "str"
            },
            {
              "name": "min_batch",
              "type": "int"
            },
            {
              "name": "max_batch",
              "type": "int"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "os.makedirs",
              "line": 78
            },
            {
              "name": "torch.device",
              "line": 85
            },
            {
              "name": "logger.info",
              "line": 86
            },
            {
              "name": "....strftime",
              "line": 89
            },
            {
              "name": "os.path.join",
              "line": 92
            },
            {
              "name": "torch.cuda.is_available",
              "line": 85
            },
            {
              "name": "datetime.now",
              "line": 89
            }
          ],
          "docstring": "\n        Initialize the pattern mapper.\n        \n        Args:\n            output_dir: Directory for saving results (defaults to PATTERN_MAPS_DIR)\n            min_batch: Minimum batch size to use\n            max_batch: Maximum batch size to use\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(self, output_dir: str = None, min_batch: int = 16, max_batch: int = 256):\n        \"\"\"\n        Initialize the pattern mapper.\n        \n        Args:\n            output_dir: Directory for saving results (defaults to PATTERN_MAPS_DIR)\n            min_batch: Minimum batch size to use\n            max_batch: Maximum batch size to use\n        \"\"\"\n        self.output_dir = output_dir or PATTERN_MAPS_DIR\n        os.makedirs(self.output_dir, exist_ok=True)\n        \n        # Set batch size boundaries\n        self.min_batch = min_batch\n        self.max_batch = max_batch\n        \n        # Initialize device\n        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        logger.info(f\"Using device: {self.device}\")\n        \n        # Set timestamp for output files\n        self.timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        \n        # Create visualization directory if needed\n        self.pattern_vis_dir = os.path.join(self.output_dir, f\"pattern_vis_{self.timestamp}\")\n        \n    def load_dataset(self, dataset_path_or_name: str) -> Tuple[Any, Any]:\n        \"\"\"\n        Load the specified dataset."
        },
        "load_dataset": {
          "start_line": 94,
          "end_line": 181,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "dataset_path_or_name",
              "type": "str"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "logger.info",
              "line": 104
            },
            {
              "name": "logger.info",
              "line": 174
            },
            {
              "name": "dataset_path_or_name.lower",
              "line": 107
            },
            {
              "name": "transforms.Compose",
              "line": 109
            },
            {
              "name": "transforms.Compose",
              "line": 115
            },
            {
              "name": "torchvision.datasets.CIFAR10",
              "line": 122
            },
            {
              "name": "torchvision.datasets.CIFAR10",
              "line": 125
            },
            {
              "name": "torchvision.datasets.CIFAR10",
              "line": 128
            },
            {
              "name": "dataset_path_or_name.lower",
              "line": 131
            },
            {
              "name": "transforms.Compose",
              "line": 132
            },
            {
              "name": "transforms.Compose",
              "line": 138
            },
            {
              "name": "torchvision.datasets.CIFAR100",
              "line": 145
            },
            {
              "name": "torchvision.datasets.CIFAR100",
              "line": 148
            },
            {
              "name": "torchvision.datasets.CIFAR100",
              "line": 151
            },
            {
              "name": "transforms.ToTensor",
              "line": 110
            },
            {
              "name": "transforms.Normalize",
              "line": 111
            },
            {
              "name": "transforms.RandomCrop",
              "line": 116
            },
            {
              "name": "transforms.RandomHorizontalFlip",
              "line": 117
            },
            {
              "name": "transforms.ToTensor",
              "line": 118
            },
            {
              "name": "transforms.Normalize",
              "line": 119
            },
            {
              "name": "dataset_path_or_name.lower",
              "line": 154
            },
            {
              "name": "transforms.Compose",
              "line": 155
            },
            {
              "name": "torchvision.datasets.MNIST",
              "line": 160
            },
            {
              "name": "torchvision.datasets.MNIST",
              "line": 166
            },
            {
              "name": "ValueError",
              "line": 172
            },
            {
              "name": "len",
              "line": 174
            },
            {
              "name": "len",
              "line": 174
            },
            {
              "name": "transforms.ToTensor",
              "line": 133
            },
            {
              "name": "transforms.Normalize",
              "line": 134
            },
            {
              "name": "transforms.RandomCrop",
              "line": 139
            },
            {
              "name": "transforms.RandomHorizontalFlip",
              "line": 140
            },
            {
              "name": "transforms.ToTensor",
              "line": 141
            },
            {
              "name": "transforms.Normalize",
              "line": 142
            },
            {
              "name": "transforms.ToTensor",
              "line": 156
            },
            {
              "name": "transforms.Normalize",
              "line": 157
            }
          ],
          "docstring": "\n        Load the specified dataset.\n        \n        Args:\n            dataset_path_or_name: Path or name of the dataset to load\n            \n        Returns:\n            Tuple of (train_dataset, test_dataset)\n        ",
          "code_snippet": "        self.pattern_vis_dir = os.path.join(self.output_dir, f\"pattern_vis_{self.timestamp}\")\n        \n    def load_dataset(self, dataset_path_or_name: str) -> Tuple[Any, Any]:\n        \"\"\"\n        Load the specified dataset.\n        \n        Args:\n            dataset_path_or_name: Path or name of the dataset to load\n            \n        Returns:\n            Tuple of (train_dataset, test_dataset)\n        \"\"\"\n        logger.info(f\"Loading dataset: {dataset_path_or_name}\")\n        \n        # Handle standard dataset names\n        if dataset_path_or_name.lower() == \"cifar10\":\n            # For mapping, we avoid augmentation\n            transform = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n            ])\n            \n            # For training later (with standard augmentations)\n            transform_train = transforms.Compose([\n                transforms.RandomCrop(32, padding=4),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n            ])\n            \n            trainset = torchvision.datasets.CIFAR10(\n                root='./data', train=True, download=True, transform=transform)\n            \n            trainset_with_aug = torchvision.datasets.CIFAR10(\n                root='./data', train=True, download=True, transform=transform_train)\n            \n            testset = torchvision.datasets.CIFAR10(\n                root='./data', train=False, download=True, transform=transform)\n        \n        elif dataset_path_or_name.lower() == \"cifar100\":\n            transform = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n            ])\n            \n            # For training later (with standard augmentations)\n            transform_train = transforms.Compose([\n                transforms.RandomCrop(32, padding=4),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize((0.5071, 0.4867, 0.4408), (0.2675, 0.2565, 0.2761)),\n            ])\n            \n            trainset = torchvision.datasets.CIFAR100(\n                root='./data', train=True, download=True, transform=transform)\n            \n            trainset_with_aug = torchvision.datasets.CIFAR100(\n                root='./data', train=True, download=True, transform=transform_train)\n            \n            testset = torchvision.datasets.CIFAR100(\n                root='./data', train=False, download=True, transform=transform)\n        \n        elif dataset_path_or_name.lower() == \"mnist\":\n            transform = transforms.Compose([\n                transforms.ToTensor(),\n                transforms.Normalize((0.1307,), (0.3081,))\n            ])\n            \n            trainset = torchvision.datasets.MNIST(\n                root='./data', train=True, download=True, transform=transform)\n            \n            # For MNIST, we use the same transform for training\n            trainset_with_aug = trainset\n            \n            testset = torchvision.datasets.MNIST(\n                root='./data', train=False, download=True, transform=transform)\n        \n        else:\n            # Custom dataset handling would go here\n            # This would include checking if path_or_name is a directory, CSV file, etc.\n            raise ValueError(f\"Unsupported dataset: {dataset_path_or_name}\")\n        \n        logger.info(f\"Dataset loaded: {len(trainset)} training samples, {len(testset)} test samples\")\n        \n        # Store the trainset with standard augmentations for later use\n        self.trainset_with_aug = trainset_with_aug\n        \n        return trainset, testset\n    \n    def run_hardware_diagnostics(self, model=None):\n        \"\"\"\n        Run diagnostics to determine optimal batch size boundaries based on hardware."
        },
        "run_hardware_diagnostics": {
          "start_line": 181,
          "end_line": 270,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "model"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logger.info",
              "line": 191
            },
            {
              "name": "logger.info",
              "line": 267
            },
            {
              "name": "torch.cuda.is_available",
              "line": 194
            },
            {
              "name": "any",
              "line": 251
            },
            {
              "name": "torch.cuda.get_device_properties",
              "line": 198
            },
            {
              "name": "logger.debug",
              "line": 202
            },
            {
              "name": "max",
              "line": 206
            },
            {
              "name": "logger.info",
              "line": 208
            },
            {
              "name": "min",
              "line": 214
            },
            {
              "name": "logger.info",
              "line": 216
            },
            {
              "name": "multiprocessing.cpu_count",
              "line": 228
            },
            {
              "name": "max",
              "line": 230
            },
            {
              "name": "logger.info",
              "line": 240
            },
            {
              "name": "logger.info",
              "line": 257
            },
            {
              "name": "round",
              "line": 263
            },
            {
              "name": "max",
              "line": 264
            },
            {
              "name": "logger.info",
              "line": 265
            },
            {
              "name": "int",
              "line": 214
            },
            {
              "name": "logger.warning",
              "line": 220
            },
            {
              "name": "min",
              "line": 236
            },
            {
              "name": "logger.warning",
              "line": 244
            },
            {
              "name": "isinstance",
              "line": 251
            },
            {
              "name": "math.log2",
              "line": 263
            },
            {
              "name": "min",
              "line": 264
            },
            {
              "name": "int",
              "line": 236
            },
            {
              "name": "model.modules",
              "line": 252
            },
            {
              "name": "psutil.virtual_memory",
              "line": 235
            },
            {
              "name": "str",
              "line": 220
            },
            {
              "name": "str",
              "line": 244
            }
          ],
          "docstring": "\n        Run diagnostics to determine optimal batch size boundaries based on hardware.\n        \n        Args:\n            model: Optional model to check for BatchNorm layers\n            \n        Returns:\n            Tuple of (min_batch, max_batch)\n        ",
          "code_snippet": "        return trainset, testset\n    \n    def run_hardware_diagnostics(self, model=None):\n        \"\"\"\n        Run diagnostics to determine optimal batch size boundaries based on hardware.\n        \n        Args:\n            model: Optional model to check for BatchNorm layers\n            \n        Returns:\n            Tuple of (min_batch, max_batch)\n        \"\"\"\n        logger.info(\"Running hardware diagnostics for batch size boundaries\")\n        \n        # Calculate minimum batch size based on hardware characteristics\n        if self.device.type == \"cuda\" and torch.cuda.is_available():\n            # Get properties of the specified or default GPU\n            device_index = self.device.index if self.device.index is not None else 0\n            try:\n                device_props = torch.cuda.get_device_properties(device_index)\n                \n                # Get the number of Streaming Multiprocessors (SMs)\n                sm_count = device_props.multi_processor_count\n                logger.debug(f\"GPU has {sm_count} streaming multiprocessors\")\n                \n                # Calculate minimum batch size that ensures reasonable SM utilization\n                # We want at least 1 sample per 4 SMs to ensure reasonable parallelism\n                min_batch = max(1, sm_count // 4)\n                \n                logger.info(f\"Calculated hardware-based minimum batch size: {min_batch} based on {sm_count} streaming multiprocessors\")\n                self.min_batch = min_batch\n                \n                # Calculate maximum batch size based on GPU memory\n                # This is a rough estimate - 4GB should handle most standard models with batch size 256\n                mem_gb = device_props.total_memory / (1024**3)\n                max_batch = min(256, int(mem_gb * 64))  # 64 samples per GB as a rough estimate\n                \n                logger.info(f\"Calculated hardware-based maximum batch size: {max_batch} based on {mem_gb:.1f}GB GPU memory\")\n                self.max_batch = max_batch\n                \n            except Exception as e:\n                logger.warning(f\"Error calculating GPU-based batch size limits: {str(e)}\")\n                # Fallback to defaults\n                self.min_batch = 16\n                self.max_batch = 256\n        else:\n            # For CPU, base it on core count\n            try:\n                import multiprocessing\n                cpu_count = multiprocessing.cpu_count()\n                # CPUs benefit from smaller min batch sizes due to different parallelism model\n                min_batch = max(1, cpu_count // 8)\n                \n                # For max batch, use a reasonable value based on likely available memory\n                try:\n                    import psutil\n                    mem_gb = psutil.virtual_memory().total / (1024**3)\n                    max_batch = min(256, int(mem_gb * 32))  # 32 samples per GB as a rough estimate\n                except:\n                    max_batch = 128  # Conservative default\n                \n                logger.info(f\"Calculated hardware-based batch sizes: min={min_batch} (based on {cpu_count} CPU cores), max={max_batch}\")\n                self.min_batch = min_batch\n                self.max_batch = max_batch\n            except Exception as e:\n                logger.warning(f\"Error calculating CPU-based batch size limits: {str(e)}\")\n                # Absolute fallback\n                self.min_batch = 8\n                self.max_batch = 128\n        \n        # Check for BatchNorm if model is provided\n        if model is not None:\n            has_batch_norm = any(isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)) \n                                for m in model.modules())\n            \n            # Ensure minimum batch size is at least 2 for BatchNorm\n            if has_batch_norm and self.min_batch < 2:\n                self.min_batch = 2\n                logger.info(\"Adjusted minimum batch size to 2 for BatchNorm compatibility\")\n                \n            # Use power-of-2 batch size if possible for better performance with BatchNorm\n            if has_batch_norm:\n                import math\n                mid_batch = (self.min_batch + self.max_batch) // 3  # Start with 1/3 of range\n                power = round(math.log2(mid_batch))\n                suggested_batch = max(self.min_batch, min(self.max_batch, 2 ** power))\n                logger.info(f\"Suggested power-of-2 batch size for BatchNorm model: {suggested_batch}\")\n        \n        logger.info(f\"Final batch size boundaries: [{self.min_batch}, {self.max_batch}]\")\n        return self.min_batch, self.max_batch\n    \n    def create_pattern_map_batched(self, dataset, batch_size: int = None, sample_limit: Optional[int] = None) -> Dict[str, Any]:\n        \"\"\"\n        Create a pattern map using batch processing for efficiency while performing real analysis."
        },
        "create_pattern_map_batched": {
          "start_line": 270,
          "end_line": 386,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "dataset"
            },
            {
              "name": "batch_size",
              "type": "int"
            },
            {
              "name": "sample_limit"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "time.time",
              "line": 289
            },
            {
              "name": "logger.info",
              "line": 290
            },
            {
              "name": "len",
              "line": 293
            },
            {
              "name": "range",
              "line": 307
            },
            {
              "name": "logger.info",
              "line": 349
            },
            {
              "name": "self._calculate_pattern_complexity_stats",
              "line": 352
            },
            {
              "name": "self._order_patterns_by_complexity",
              "line": 355
            },
            {
              "name": "pattern_map.items",
              "line": 359
            },
            {
              "name": "logger.info",
              "line": 286
            },
            {
              "name": "min",
              "line": 310
            },
            {
              "name": "list",
              "line": 311
            },
            {
              "name": "logger.info",
              "line": 315
            },
            {
              "name": "self._extract_batch_features",
              "line": 324
            },
            {
              "name": "enumerate",
              "line": 327
            },
            {
              "name": "time.time",
              "line": 348
            },
            {
              "name": "range",
              "line": 311
            },
            {
              "name": "batch_tensors.append",
              "line": 321
            },
            {
              "name": "self._determine_pattern_type",
              "line": 331
            },
            {
              "name": "self._calculate_pattern_complexity",
              "line": 334
            },
            {
              "name": "....append",
              "line": 345
            },
            {
              "name": "....strftime",
              "line": 371
            },
            {
              "name": "str",
              "line": 337
            },
            {
              "name": "str",
              "line": 377
            },
            {
              "name": "datetime.now",
              "line": 371
            }
          ],
          "docstring": "\n        Create a pattern map using batch processing for efficiency while performing real analysis.\n        \n        Args:\n            dataset: The dataset to analyze\n            batch_size: Batch size for processing (None to automatically determine)\n            sample_limit: Maximum number of samples to analyze (None = all)\n            \n        Returns:\n            Pattern map dictionary\n        ",
          "code_snippet": "        return self.min_batch, self.max_batch\n    \n    def create_pattern_map_batched(self, dataset, batch_size: int = None, sample_limit: Optional[int] = None) -> Dict[str, Any]:\n        \"\"\"\n        Create a pattern map using batch processing for efficiency while performing real analysis.\n        \n        Args:\n            dataset: The dataset to analyze\n            batch_size: Batch size for processing (None to automatically determine)\n            sample_limit: Maximum number of samples to analyze (None = all)\n            \n        Returns:\n            Pattern map dictionary\n        \"\"\"\n        # Use hardware-aware batch size if not specified\n        if batch_size is None:\n            # Choose batch size in the middle of the range, favoring smaller sizes for accuracy\n            batch_size = self.min_batch + (self.max_batch - self.min_batch) // 3\n            logger.info(f\"Using automatically determined batch size: {batch_size}\")\n        \n        # Start timing\n        start_time = time.time()\n        logger.info(f\"Creating pattern map with batch size {batch_size}\")\n        \n        # Get dataset size and apply sample limit if needed\n        dataset_size = len(dataset)\n        if sample_limit is not None and sample_limit < dataset_size:\n            dataset_size = sample_limit\n        \n        # Calculate number of batches\n        num_batches = (dataset_size + batch_size - 1) // batch_size\n        \n        # Initialize pattern tracking structures\n        pattern_map = {}  # Index to pattern mapping\n        pattern_types = [\"structural\", \"statistical\", \"temporal\"]\n        pattern_counts = {pt: 0 for pt in pattern_types}\n        pattern_complexities = {pt: [] for pt in pattern_types}\n        \n        # Process batches\n        for batch_idx in range(num_batches):\n            # Get batch indices\n            start_idx = batch_idx * batch_size\n            end_idx = min(start_idx + batch_size, dataset_size)\n            batch_indices = list(range(start_idx, end_idx))\n            \n            # Display progress\n            progress = (batch_idx + 1) / num_batches * 100\n            logger.info(f\"Processing batch {batch_idx+1}/{num_batches} ({progress:.1f}%)\")\n            \n            # Load batch images and preprocess for analysis\n            batch_tensors = []\n            for idx in batch_indices:\n                image, _ = dataset[idx]\n                batch_tensors.append(image)\n            \n            # Process the entire batch at once\n            batch_features = self._extract_batch_features(batch_tensors, batch_indices)\n            \n            # Assign patterns based on actual features and calculate complexities\n            for i, idx in enumerate(batch_indices):\n                features = batch_features[i]\n                \n                # Determine pattern type based on REAL features (not predetermined)\n                pattern_type = self._determine_pattern_type(features)\n                \n                # Calculate complexity from features (real analysis)\n                complexity = self._calculate_pattern_complexity(features)\n                \n                # Store pattern information\n                pattern_map[str(idx)] = {\n                    'pattern_type': pattern_type,\n                    'complexity': complexity,\n                    'confidence': 0.8  # Default confidence\n                }\n                \n                # Update counts and track complexities\n                pattern_counts[pattern_type] += 1\n                pattern_complexities[pattern_type].append(complexity)\n        \n        # Calculate elapsed time\n        elapsed_time = time.time() - start_time\n        logger.info(f\"Pattern mapping completed in {elapsed_time:.2f} seconds\")\n        \n        # Calculate pattern complexity statistics\n        pattern_complexity_stats = self._calculate_pattern_complexity_stats(pattern_complexities)\n        \n        # Create pattern ordering by complexity\n        patterns_by_complexity = self._order_patterns_by_complexity(pattern_complexity_stats)\n        \n        # Create sample_to_pattern mapping for easy lookup (used during training)\n        sample_to_pattern = {}\n        for idx_str, pattern_info in pattern_map.items():\n            sample_to_pattern[idx_str] = pattern_info['pattern_type']\n        \n        # Assemble final pattern map structure\n        result = {\n            'pattern_map': pattern_map,\n            'pattern_distribution': pattern_counts,\n            'pattern_complexities': pattern_complexity_stats,\n            'patterns_by_complexity': patterns_by_complexity,\n            'sample_to_pattern': sample_to_pattern,  # Add direct lookup mapping\n            'pattern_types': pattern_types,          # Add list of pattern types\n            'metadata': {\n                'timestamp': datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n                'samples_analyzed': dataset_size,\n                'analysis_time': elapsed_time,\n                'batch_size': batch_size,\n                'version': '3.0-batched',\n                'hardware': {\n                    'device': str(self.device),\n                    'min_batch': self.min_batch,\n                    'max_batch': self.max_batch\n                }\n            }\n        }\n        \n        return result\n    \n    def _extract_batch_features(self, batch_tensors: List[torch.Tensor], batch_indices: List[int]) -> List[Dict[str, float]]:\n        \"\"\"\n        Extract features from a batch of images using vectorized operations."
        },
        "_extract_batch_features": {
          "start_line": 386,
          "end_line": 478,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "batch_tensors"
            },
            {
              "name": "batch_indices"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "enumerate",
              "line": 401
            },
            {
              "name": "batch_features.append",
              "line": 474
            },
            {
              "name": "....numpy",
              "line": 409
            },
            {
              "name": "np.mean",
              "line": 421
            },
            {
              "name": "np.std",
              "line": 422
            },
            {
              "name": "float",
              "line": 424
            },
            {
              "name": "float",
              "line": 425
            },
            {
              "name": "float",
              "line": 426
            },
            {
              "name": "float",
              "line": 427
            },
            {
              "name": "np.mean",
              "line": 430
            },
            {
              "name": "float",
              "line": 434
            },
            {
              "name": "float",
              "line": 435
            },
            {
              "name": "np.diff",
              "line": 440
            },
            {
              "name": "np.diff",
              "line": 441
            },
            {
              "name": "np.sqrt",
              "line": 444
            },
            {
              "name": "np.percentile",
              "line": 447
            },
            {
              "name": "np.mean",
              "line": 449
            },
            {
              "name": "float",
              "line": 450
            },
            {
              "name": "np.var",
              "line": 453
            },
            {
              "name": "float",
              "line": 454
            },
            {
              "name": "logger.warning",
              "line": 467
            },
            {
              "name": "tensor.dim",
              "line": 407
            },
            {
              "name": "tensor.size",
              "line": 407
            },
            {
              "name": "....numpy",
              "line": 411
            },
            {
              "name": "....numpy",
              "line": 413
            },
            {
              "name": "len",
              "line": 416
            },
            {
              "name": "np.mean",
              "line": 427
            },
            {
              "name": "np.mean",
              "line": 434
            },
            {
              "name": "np.std",
              "line": 435
            },
            {
              "name": "np.mean",
              "line": 461
            },
            {
              "name": "float",
              "line": 462
            },
            {
              "name": "....cpu",
              "line": 409
            },
            {
              "name": "tensor.dim",
              "line": 410
            },
            {
              "name": "tensor.size",
              "line": 410
            },
            {
              "name": "np.max",
              "line": 457
            },
            {
              "name": "np.min",
              "line": 457
            },
            {
              "name": "....cpu",
              "line": 411
            },
            {
              "name": "tensor.cpu",
              "line": 413
            },
            {
              "name": "np.min",
              "line": 458
            },
            {
              "name": "np.max",
              "line": 458
            },
            {
              "name": "np.min",
              "line": 458
            },
            {
              "name": "str",
              "line": 467
            },
            {
              "name": "tensor.permute",
              "line": 409
            },
            {
              "name": "tensor.squeeze",
              "line": 411
            }
          ],
          "docstring": "\n        Extract features from a batch of images using vectorized operations.\n        \n        Args:\n            batch_tensors: List of image tensors\n            batch_indices: List of corresponding indices\n            \n        Returns:\n            List of feature dictionaries for each image\n        ",
          "code_snippet": "        return result\n    \n    def _extract_batch_features(self, batch_tensors: List[torch.Tensor], batch_indices: List[int]) -> List[Dict[str, float]]:\n        \"\"\"\n        Extract features from a batch of images using vectorized operations.\n        \n        Args:\n            batch_tensors: List of image tensors\n            batch_indices: List of corresponding indices\n            \n        Returns:\n            List of feature dictionaries for each image\n        \"\"\"\n        # Initialize features list\n        batch_features = []\n        \n        # Process each image in the batch\n        for i, tensor in enumerate(batch_tensors):\n            features = {}\n            idx = batch_indices[i]\n            \n            try:\n                # Convert tensor to numpy for analysis\n                if tensor.dim() == 3 and tensor.size(0) == 3:  # RGB image\n                    # Denormalize if needed\n                    image = tensor.permute(1, 2, 0).cpu().numpy()\n                elif tensor.dim() == 3 and tensor.size(0) == 1:  # Grayscale image\n                    image = tensor.squeeze(0).cpu().numpy()\n                else:\n                    image = tensor.cpu().numpy()\n                \n                # Check if image is grayscale or color\n                is_color = len(image.shape) == 3 and image.shape[2] == 3\n                \n                # Extract color/intensity features\n                if is_color:\n                    # Color image analysis\n                    mean_color = np.mean(image, axis=(0, 1))\n                    std_color = np.std(image, axis=(0, 1))\n                    \n                    features['color_mean_r'] = float(mean_color[0])\n                    features['color_mean_g'] = float(mean_color[1])\n                    features['color_mean_b'] = float(mean_color[2])\n                    features['color_std'] = float(np.mean(std_color))\n                    \n                    # Convert to grayscale for texture analysis\n                    gray = np.mean(image, axis=2)\n                else:\n                    # Grayscale image analysis\n                    gray = image\n                    features['intensity_mean'] = float(np.mean(gray))\n                    features['intensity_std'] = float(np.std(gray))\n                \n                # Edge and texture analysis using vectorized operations\n                if gray.size > 0:\n                    # Calculate gradients - vectorized operation\n                    gx = np.diff(gray, axis=1, prepend=gray[:, :1])\n                    gy = np.diff(gray, axis=0, prepend=gray[:1, :])\n                    \n                    # Calculate gradient magnitude - vectorized operation\n                    gradient_mag = np.sqrt(gx**2 + gy**2)\n                    \n                    # Edge density calculation - vectorized operations\n                    edge_threshold = np.percentile(gradient_mag, 80)\n                    edges = gradient_mag > edge_threshold\n                    edge_density = np.mean(edges)\n                    features['edge_density'] = float(edge_density)\n                    \n                    # Texture variance - vectorized operation\n                    texture_variance = np.var(gradient_mag)\n                    features['texture_variance'] = float(texture_variance)\n                    \n                    # Shape factor calculation - vectorized operations\n                    if np.max(gray) - np.min(gray) > 1e-6:\n                        normalized = (gray - np.min(gray)) / (np.max(gray) - np.min(gray))\n                        threshold = 0.5\n                        binary = normalized > threshold\n                        shape_factor = np.mean(binary)\n                        features['shape_factor'] = float(shape_factor)\n                    else:\n                        features['shape_factor'] = 0.5\n            \n            except Exception as e:\n                logger.warning(f\"Error extracting features for image {idx}: {str(e)}\")\n                # Provide default features\n                features = {\n                    'default_feature': 0.5,\n                    'error': 1.0\n                }\n            \n            batch_features.append(features)\n        \n        return batch_features\n    \n    def _determine_pattern_type(self, features: Dict[str, float]) -> str:\n        \"\"\"\n        Determine pattern type based on extracted features."
        },
        "_determine_pattern_type": {
          "start_line": 478,
          "end_line": 514,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "features"
            }
          ],
          "return_type": "str",
          "calls": [
            {
              "name": "features.get",
              "line": 495
            },
            {
              "name": "features.get",
              "line": 496
            },
            {
              "name": "features.get",
              "line": 497
            },
            {
              "name": "features.get",
              "line": 498
            },
            {
              "name": "features.get",
              "line": 499
            }
          ],
          "docstring": "\n        Determine pattern type based on extracted features.\n        \n        This uses real feature analysis to assign patterns, not predetermined rules.\n        \n        Args:\n            features: Feature dictionary for an image\n            \n        Returns:\n            Pattern type: 'structural', 'statistical', or 'temporal'\n        ",
          "code_snippet": "        return batch_features\n    \n    def _determine_pattern_type(self, features: Dict[str, float]) -> str:\n        \"\"\"\n        Determine pattern type based on extracted features.\n        \n        This uses real feature analysis to assign patterns, not predetermined rules.\n        \n        Args:\n            features: Feature dictionary for an image\n            \n        Returns:\n            Pattern type: 'structural', 'statistical', or 'temporal'\n        \"\"\"\n        # Check for error case\n        if 'error' in features and features['error'] > 0.5:\n            return 'statistical'  # Default for error cases\n        \n        # Extract key features with defaults if not present\n        edge_density = features.get('edge_density', 0.0)\n        texture_variance = features.get('texture_variance', 0.0)\n        shape_factor = features.get('shape_factor', 0.5)\n        color_std = features.get('color_std', 0.0)\n        intensity_std = features.get('intensity_std', 0.0)\n        \n        # Determine pattern type based on ACTUAL features\n        if edge_density > 0.3 or shape_factor > 0.6:\n            # Strong edges or shape patterns indicate structural patterns\n            pattern_type = \"structural\"\n        elif texture_variance > 0.2 or color_std > 0.15 or intensity_std > 0.3:\n            # High variance in texture, color, or intensity indicates statistical patterns\n            pattern_type = \"statistical\"\n        else:\n            # Default to temporal for patterns that don't fit the above categories\n            pattern_type = \"temporal\"\n        \n        return pattern_type\n    \n    def _calculate_pattern_complexity(self, features: Dict[str, float]) -> float:\n        \"\"\"\n        Calculate complexity score from pattern features."
        },
        "_calculate_pattern_complexity": {
          "start_line": 514,
          "end_line": 555,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "features"
            }
          ],
          "return_type": "float",
          "calls": [
            {
              "name": "np.mean",
              "line": 532
            },
            {
              "name": "features.get",
              "line": 536
            },
            {
              "name": "features.get",
              "line": 537
            },
            {
              "name": "features.get",
              "line": 538
            },
            {
              "name": "features.get",
              "line": 539
            },
            {
              "name": "features.get",
              "line": 540
            },
            {
              "name": "min",
              "line": 553
            },
            {
              "name": "np.var",
              "line": 533
            },
            {
              "name": "max",
              "line": 553
            },
            {
              "name": "features.items",
              "line": 525
            },
            {
              "name": "len",
              "line": 533
            },
            {
              "name": "isinstance",
              "line": 526
            }
          ],
          "docstring": "\n        Calculate complexity score from pattern features.\n        \n        Args:\n            features: Feature dictionary for an image\n            \n        Returns:\n            Complexity score (0.1 to 0.9 range)\n        ",
          "code_snippet": "        return pattern_type\n    \n    def _calculate_pattern_complexity(self, features: Dict[str, float]) -> float:\n        \"\"\"\n        Calculate complexity score from pattern features.\n        \n        Args:\n            features: Feature dictionary for an image\n            \n        Returns:\n            Complexity score (0.1 to 0.9 range)\n        \"\"\"\n        # Get numeric features, excluding error flags\n        numeric_features = [v for k, v in features.items() \n                           if isinstance(v, (int, float)) and k != 'error']\n        \n        if not numeric_features:\n            return 0.5  # Default complexity\n        \n        # Calculate complexity based on feature values and their variance\n        mean_value = np.mean(numeric_features)\n        feature_variance = np.var(numeric_features) if len(numeric_features) > 1 else 0.5\n        \n        # Extract key complexity indicators if available\n        edge_density = features.get('edge_density', 0.5)\n        texture_variance = features.get('texture_variance', 0.5)\n        shape_factor = features.get('shape_factor', 0.5)\n        color_std = features.get('color_std', 0.5)\n        intensity_std = features.get('intensity_std', 0.5)\n        \n        # Calculate weighted complexity\n        complexity = (\n            edge_density * 0.25 +\n            texture_variance * 0.25 +\n            shape_factor * 0.15 +\n            color_std * 0.15 +\n            intensity_std * 0.1 +\n            feature_variance * 0.1\n        )\n        \n        # Ensure the range is between 0.1 and 0.9\n        return min(0.9, max(0.1, complexity))\n    \n    def _calculate_pattern_complexity_stats(self, pattern_complexities: Dict[str, List[float]]) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Calculate complexity statistics for each pattern type."
        },
        "_calculate_pattern_complexity_stats": {
          "start_line": 555,
          "end_line": 592,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_complexities"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "pattern_complexities.items",
              "line": 567
            },
            {
              "name": "min",
              "line": 580
            },
            {
              "name": "max",
              "line": 581
            },
            {
              "name": "sum",
              "line": 579
            },
            {
              "name": "len",
              "line": 579
            },
            {
              "name": "len",
              "line": 587
            }
          ],
          "docstring": "\n        Calculate complexity statistics for each pattern type.\n        \n        Args:\n            pattern_complexities: Dictionary mapping pattern types to lists of complexity values\n            \n        Returns:\n            Dictionary of pattern types to complexity statistics\n        ",
          "code_snippet": "        return min(0.9, max(0.1, complexity))\n    \n    def _calculate_pattern_complexity_stats(self, pattern_complexities: Dict[str, List[float]]) -> Dict[str, Dict[str, Any]]:\n        \"\"\"\n        Calculate complexity statistics for each pattern type.\n        \n        Args:\n            pattern_complexities: Dictionary mapping pattern types to lists of complexity values\n            \n        Returns:\n            Dictionary of pattern types to complexity statistics\n        \"\"\"\n        complexity_stats = {}\n        \n        for pattern_type, complexities in pattern_complexities.items():\n            if not complexities:\n                # Default values if no patterns of this type\n                complexity_stats[pattern_type] = {\n                    'avg_complexity': 0.5,\n                    'min_complexity': 0.1,\n                    'max_complexity': 0.9,\n                    'pattern_count': 0\n                }\n                continue\n            \n            # Calculate statistics\n            avg_complexity = sum(complexities) / len(complexities)\n            min_complexity = min(complexities)\n            max_complexity = max(complexities)\n            \n            complexity_stats[pattern_type] = {\n                'avg_complexity': avg_complexity,\n                'min_complexity': min_complexity,\n                'max_complexity': max_complexity,\n                'pattern_count': len(complexities)\n            }\n        \n        return complexity_stats\n    \n    def _order_patterns_by_complexity(self, pattern_complexities: Dict[str, Dict[str, Any]]) -> Dict[str, List[str]]:\n        \"\"\"\n        Order patterns by complexity for risk-accuracy training."
        },
        "_order_patterns_by_complexity": {
          "start_line": 592,
          "end_line": 624,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_complexities"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "sorted",
              "line": 603
            },
            {
              "name": "max",
              "line": 612
            },
            {
              "name": "len",
              "line": 612
            },
            {
              "name": "pattern_complexities.items",
              "line": 604
            }
          ],
          "docstring": "\n        Order patterns by complexity for risk-accuracy training.\n        \n        Args:\n            pattern_complexities: Dictionary of pattern types to complexity statistics\n            \n        Returns:\n            Dictionary with ordered patterns and complexity groupings\n        ",
          "code_snippet": "        return complexity_stats\n    \n    def _order_patterns_by_complexity(self, pattern_complexities: Dict[str, Dict[str, Any]]) -> Dict[str, List[str]]:\n        \"\"\"\n        Order patterns by complexity for risk-accuracy training.\n        \n        Args:\n            pattern_complexities: Dictionary of pattern types to complexity statistics\n            \n        Returns:\n            Dictionary with ordered patterns and complexity groupings\n        \"\"\"\n        # Sort patterns by average complexity\n        sorted_patterns = sorted(\n            [(p, data['avg_complexity']) for p, data in pattern_complexities.items()],\n            key=lambda x: x[1]\n        )\n        \n        # Get pattern types sorted by complexity\n        pattern_types = [p for p, _ in sorted_patterns]\n        \n        # Group patterns into low, medium, and high complexity\n        third = max(1, len(pattern_types) // 3)\n        \n        low_complexity = pattern_types[:third]\n        medium_complexity = pattern_types[third:2*third]\n        high_complexity = pattern_types[2*third:]\n        \n        return {\n            'ordered_by_complexity': pattern_types,\n            'low_complexity': low_complexity,\n            'medium_complexity': medium_complexity,\n            'high_complexity': high_complexity\n        }\n    \n    def save_pattern_map(self, pattern_map: Dict[str, Any], dataset_name: str = \"dataset\") -> str:\n        \"\"\""
        },
        "save_pattern_map": {
          "start_line": 625,
          "end_line": 663,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_map"
            },
            {
              "name": "dataset_name",
              "type": "str"
            }
          ],
          "return_type": "str",
          "calls": [
            {
              "name": "os.path.join",
              "line": 638
            },
            {
              "name": "logger.info",
              "line": 654
            },
            {
              "name": "os.path.join",
              "line": 657
            },
            {
              "name": "isinstance",
              "line": 642
            },
            {
              "name": "TypeError",
              "line": 648
            },
            {
              "name": "open",
              "line": 651
            },
            {
              "name": "json.dump",
              "line": 652
            },
            {
              "name": "open",
              "line": 658
            },
            {
              "name": "f.write",
              "line": 659
            },
            {
              "name": "int",
              "line": 643
            },
            {
              "name": "isinstance",
              "line": 644
            },
            {
              "name": "float",
              "line": 645
            },
            {
              "name": "isinstance",
              "line": 646
            },
            {
              "name": "obj.tolist",
              "line": 647
            },
            {
              "name": "type",
              "line": 648
            }
          ],
          "docstring": "\n        Save pattern map to file and update latest path reference.\n        \n        Args:\n            pattern_map: The pattern map to save\n            dataset_name: Name of the dataset\n            \n        Returns:\n            Path to the saved pattern map\n        ",
          "code_snippet": "        }\n    \n    def save_pattern_map(self, pattern_map: Dict[str, Any], dataset_name: str = \"dataset\") -> str:\n        \"\"\"\n        Save pattern map to file and update latest path reference.\n        \n        Args:\n            pattern_map: The pattern map to save\n            dataset_name: Name of the dataset\n            \n        Returns:\n            Path to the saved pattern map\n        \"\"\"\n        # Create filename with timestamp and dataset name\n        filename = f\"pattern_map_{dataset_name}_{self.timestamp}.json\"\n        filepath = os.path.join(self.output_dir, filename)\n        \n        # Helper function to handle NumPy types in JSON serialization\n        def numpy_safe_encoder(obj):\n            if isinstance(obj, np.integer):\n                return int(obj)\n            elif isinstance(obj, np.floating):\n                return float(obj)\n            elif isinstance(obj, np.ndarray):\n                return obj.tolist()\n            raise TypeError(f\"Object of type {type(obj)} is not JSON serializable\")\n        \n        # Save to file\n        with open(filepath, 'w') as f:\n            json.dump(pattern_map, f, indent=2, default=numpy_safe_encoder)\n        \n        logger.info(f\"Pattern map saved to {filepath}\")\n        \n        # Update latest path reference\n        latest_path = os.path.join(self.output_dir, \"latest_pattern_map_path.txt\")\n        with open(latest_path, 'w') as f:\n            f.write(filepath)\n        \n        return filepath\n    \n    def create_visualizations(self, pattern_map: Dict[str, Any]) -> None:\n        \"\"\"\n        Create visualizations of the pattern map."
        },
        "create_visualizations": {
          "start_line": 663,
          "end_line": 813,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_map"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "os.path.join",
              "line": 675
            },
            {
              "name": "logger.info",
              "line": 735
            },
            {
              "name": "os.path.exists",
              "line": 671
            },
            {
              "name": "os.makedirs",
              "line": 672
            },
            {
              "name": "open",
              "line": 676
            },
            {
              "name": "f.write",
              "line": 677
            },
            {
              "name": "f.write",
              "line": 678
            },
            {
              "name": "f.write",
              "line": 695
            },
            {
              "name": "f.write",
              "line": 696
            },
            {
              "name": "f.write",
              "line": 697
            },
            {
              "name": "f.write",
              "line": 698
            },
            {
              "name": "f.write",
              "line": 699
            },
            {
              "name": "f.write",
              "line": 700
            },
            {
              "name": "os.path.join",
              "line": 742
            },
            {
              "name": "os.makedirs",
              "line": 743
            },
            {
              "name": "f.write",
              "line": 682
            },
            {
              "name": "f.write",
              "line": 683
            },
            {
              "name": "....items",
              "line": 684
            },
            {
              "name": "f.write",
              "line": 692
            },
            {
              "name": "f.write",
              "line": 704
            },
            {
              "name": "f.write",
              "line": 705
            },
            {
              "name": "distribution.items",
              "line": 709
            },
            {
              "name": "f.write",
              "line": 712
            },
            {
              "name": "f.write",
              "line": 716
            },
            {
              "name": "f.write",
              "line": 717
            },
            {
              "name": "....items",
              "line": 718
            },
            {
              "name": "f.write",
              "line": 727
            },
            {
              "name": "f.write",
              "line": 728
            },
            {
              "name": "f.write",
              "line": 731
            },
            {
              "name": "f.write",
              "line": 732
            },
            {
              "name": "f.write",
              "line": 733
            },
            {
              "name": "plt.figure",
              "line": 747
            },
            {
              "name": "list",
              "line": 748
            },
            {
              "name": "list",
              "line": 749
            },
            {
              "name": "plt.bar",
              "line": 754
            },
            {
              "name": "plt.title",
              "line": 762
            },
            {
              "name": "plt.ylabel",
              "line": 763
            },
            {
              "name": "plt.tight_layout",
              "line": 764
            },
            {
              "name": "os.path.join",
              "line": 767
            },
            {
              "name": "plt.savefig",
              "line": 768
            },
            {
              "name": "plt.close",
              "line": 769
            },
            {
              "name": "logger.info",
              "line": 771
            },
            {
              "name": "plt.figure",
              "line": 775
            },
            {
              "name": "....items",
              "line": 782
            },
            {
              "name": "np.arange",
              "line": 788
            },
            {
              "name": "plt.bar",
              "line": 791
            },
            {
              "name": "plt.bar",
              "line": 792
            },
            {
              "name": "plt.bar",
              "line": 793
            },
            {
              "name": "plt.xlabel",
              "line": 795
            },
            {
              "name": "plt.ylabel",
              "line": 796
            },
            {
              "name": "plt.title",
              "line": 797
            },
            {
              "name": "plt.xticks",
              "line": 798
            },
            {
              "name": "plt.ylim",
              "line": 799
            },
            {
              "name": "plt.legend",
              "line": 800
            },
            {
              "name": "plt.tight_layout",
              "line": 801
            },
            {
              "name": "os.path.join",
              "line": 804
            },
            {
              "name": "plt.savefig",
              "line": 805
            },
            {
              "name": "plt.close",
              "line": 806
            },
            {
              "name": "logger.info",
              "line": 808
            },
            {
              "name": "logger.warning",
              "line": 811
            },
            {
              "name": "isinstance",
              "line": 685
            },
            {
              "name": "sum",
              "line": 707
            },
            {
              "name": "f.write",
              "line": 711
            },
            {
              "name": "f.write",
              "line": 719
            },
            {
              "name": "f.write",
              "line": 720
            },
            {
              "name": "f.write",
              "line": 721
            },
            {
              "name": "f.write",
              "line": 722
            },
            {
              "name": "f.write",
              "line": 723
            },
            {
              "name": "....keys",
              "line": 748
            },
            {
              "name": "....values",
              "line": 749
            },
            {
              "name": "bar.get_height",
              "line": 758
            },
            {
              "name": "plt.text",
              "line": 759
            },
            {
              "name": "patterns.append",
              "line": 783
            },
            {
              "name": "avg_complexities.append",
              "line": 784
            },
            {
              "name": "min_complexities.append",
              "line": 785
            },
            {
              "name": "max_complexities.append",
              "line": 786
            },
            {
              "name": "len",
              "line": 788
            },
            {
              "name": "f.write",
              "line": 687
            },
            {
              "name": "value.items",
              "line": 688
            },
            {
              "name": "f.write",
              "line": 691
            },
            {
              "name": "distribution.values",
              "line": 707
            },
            {
              "name": "f.write",
              "line": 689
            },
            {
              "name": "....join",
              "line": 731
            },
            {
              "name": "....join",
              "line": 732
            },
            {
              "name": "....join",
              "line": 733
            },
            {
              "name": "bar.get_x",
              "line": 759
            },
            {
              "name": "str",
              "line": 811
            },
            {
              "name": "len",
              "line": 754
            },
            {
              "name": "bar.get_width",
              "line": 759
            }
          ],
          "docstring": "\n        Create visualizations of the pattern map.\n        \n        Args:\n            pattern_map: The pattern map to visualize\n        ",
          "code_snippet": "        return filepath\n    \n    def create_visualizations(self, pattern_map: Dict[str, Any]) -> None:\n        \"\"\"\n        Create visualizations of the pattern map.\n        \n        Args:\n            pattern_map: The pattern map to visualize\n        \"\"\"\n        # Only create visualizations directory if needed\n        if not os.path.exists(self.pattern_vis_dir):\n            os.makedirs(self.pattern_vis_dir, exist_ok=True)\n            \n        # Create summary text file\n        summary_path = os.path.join(self.pattern_vis_dir, 'pattern_map_summary.txt')\n        with open(summary_path, 'w') as f:\n            f.write(\"PATTERN MAP SUMMARY\\n\")\n            f.write(\"==================\\n\\n\")\n            \n            # Metadata\n            if 'metadata' in pattern_map:\n                f.write(\"METADATA\\n\")\n                f.write(\"--------\\n\")\n                for key, value in pattern_map['metadata'].items():\n                    if isinstance(value, dict):\n                        # For nested dictionaries like hardware info\n                        f.write(f\"{key}:\\n\")\n                        for subkey, subvalue in value.items():\n                            f.write(f\"  {subkey}: {subvalue}\\n\")\n                    else:\n                        f.write(f\"{key}: {value}\\n\")\n                f.write(\"\\n\")\n            \n            # Taxonomy explanation\n            f.write(\"TAXONOMY EXPLANATION\\n\")\n            f.write(\"-------------------\\n\")\n            f.write(\"STRUCTURAL: Spatial organization and relationships\\n\")\n            f.write(\"STATISTICAL: Distribution and variance patterns\\n\")\n            f.write(\"TEMPORAL: Time-related patterns (simplified)\\n\")\n            f.write(\"\\n\")\n            \n            # Pattern distribution\n            if 'pattern_distribution' in pattern_map:\n                f.write(\"PATTERN DISTRIBUTION\\n\")\n                f.write(\"-------------------\\n\")\n                distribution = pattern_map['pattern_distribution']\n                total = sum(distribution.values()) or 1  # Avoid division by zero\n                \n                for pattern_type, count in distribution.items():\n                    percentage = (count / total) * 100\n                    f.write(f\"{pattern_type}: {count} examples ({percentage:.1f}%)\\n\")\n                f.write(\"\\n\")\n            \n            # Pattern complexity\n            if 'pattern_complexities' in pattern_map:\n                f.write(\"PATTERN COMPLEXITY\\n\")\n                f.write(\"----------------\\n\")\n                for pattern_type, stats in pattern_map['pattern_complexities'].items():\n                    f.write(f\"{pattern_type}:\\n\")\n                    f.write(f\"  Count: {stats['pattern_count']}\\n\")\n                    f.write(f\"  Average complexity: {stats['avg_complexity']:.2f}\\n\")\n                    f.write(f\"  Complexity range: {stats['min_complexity']:.2f} - {stats['max_complexity']:.2f}\\n\")\n                    f.write(\"\\n\")\n            \n            # Complexity grouping\n            if 'patterns_by_complexity' in pattern_map:\n                f.write(\"COMPLEXITY GROUPING\\n\")\n                f.write(\"-----------------\\n\")\n                groups = pattern_map['patterns_by_complexity']\n                \n                f.write(f\"Low complexity: {', '.join(groups['low_complexity'])}\\n\")\n                f.write(f\"Medium complexity: {', '.join(groups['medium_complexity'])}\\n\")\n                f.write(f\"High complexity: {', '.join(groups['high_complexity'])}\\n\")\n        \n        logger.info(f\"Saved pattern map summary to {summary_path}\")\n        \n        # Create visualization plots if matplotlib is available\n        try:\n            import matplotlib.pyplot as plt\n            \n            # Create directory for plots\n            plots_dir = os.path.join(self.pattern_vis_dir, 'plots')\n            os.makedirs(plots_dir, exist_ok=True)\n            \n            # Plot 1: Pattern Distribution\n            if 'pattern_distribution' in pattern_map:\n                plt.figure(figsize=(10, 6))\n                patterns = list(pattern_map['pattern_distribution'].keys())\n                values = list(pattern_map['pattern_distribution'].values())\n                \n                # Use different colors for different pattern types\n                colors = ['#4287f5', '#f542a7', '#42f584']\n                \n                bars = plt.bar(patterns, values, color=colors[:len(patterns)])\n                \n                # Add value labels\n                for bar in bars:\n                    height = bar.get_height()\n                    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n                            f'{height}', ha='center', va='bottom')\n                \n                plt.title('Pattern Distribution')\n                plt.ylabel('Count')\n                plt.tight_layout()\n                \n                # Save the plot\n                dist_plot_path = os.path.join(plots_dir, 'pattern_distribution.png')\n                plt.savefig(dist_plot_path)\n                plt.close()\n                \n                logger.info(f\"Saved pattern distribution plot to {dist_plot_path}\")\n            \n            # Plot 2: Pattern Complexity Comparison\n            if 'pattern_complexities' in pattern_map:\n                plt.figure(figsize=(10, 6))\n                \n                patterns = []\n                avg_complexities = []\n                min_complexities = []\n                max_complexities = []\n                \n                for pattern, stats in pattern_map['pattern_complexities'].items():\n                    patterns.append(pattern)\n                    avg_complexities.append(stats['avg_complexity'])\n                    min_complexities.append(stats['min_complexity'])\n                    max_complexities.append(stats['max_complexity'])\n                \n                x = np.arange(len(patterns))\n                width = 0.25\n                \n                plt.bar(x - width, min_complexities, width, label='Min Complexity', color='#42c6f5')\n                plt.bar(x, avg_complexities, width, label='Avg Complexity', color='#4287f5')\n                plt.bar(x + width, max_complexities, width, label='Max Complexity', color='#425ef5')\n                \n                plt.xlabel('Pattern Type')\n                plt.ylabel('Complexity Score')\n                plt.title('Pattern Complexity Comparison')\n                plt.xticks(x, patterns)\n                plt.ylim(0, 1.0)\n                plt.legend()\n                plt.tight_layout()\n                \n                # Save the plot\n                complexity_plot_path = os.path.join(plots_dir, 'pattern_complexity.png')\n                plt.savefig(complexity_plot_path)\n                plt.close()\n                \n                logger.info(f\"Saved pattern complexity plot to {complexity_plot_path}\")\n            \n        except Exception as e:\n            logger.warning(f\"Could not create matplotlib visualizations: {str(e)}\")\n\n\ndef detect_dataset_type(dataset_path: str) -> str:\n    \"\"\""
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "\n    Pattern mapper that uses batch processing with real image analysis.\n    \n    This implementation maintains the accuracy of analyzing actual image features\n    while improving performance through batch processing and vectorized operations.\n    "
    }
  },
  "functions": {
    "detect_dataset_type": {
      "start_line": 814,
      "end_line": 861,
      "parameters": [
        {
          "name": "dataset_path",
          "type": "str"
        }
      ],
      "return_type": "str",
      "calls": [
        {
          "name": "os.path.isfile",
          "line": 829
        },
        {
          "name": "logger.error",
          "line": 858
        },
        {
          "name": "os.path.exists",
          "line": 825
        },
        {
          "name": "FileNotFoundError",
          "line": 826
        },
        {
          "name": "dataset_path.endswith",
          "line": 831
        },
        {
          "name": "os.path.isdir",
          "line": 845
        },
        {
          "name": "dataset_path.endswith",
          "line": 834
        },
        {
          "name": "_is_image_directory",
          "line": 847
        },
        {
          "name": "dataset_path.endswith",
          "line": 837
        },
        {
          "name": "_is_non_image_directory",
          "line": 850
        },
        {
          "name": "logger.warning",
          "line": 841
        },
        {
          "name": "logger.warning",
          "line": 854
        }
      ],
      "docstring": "\n    Detect whether the dataset contains images or non-image data.\n    \n    Args:\n        dataset_path: Path to dataset\n        \n    Returns:\n        str: 'image' or 'non_image'\n    ",
      "code_snippet": "\n\ndef detect_dataset_type(dataset_path: str) -> str:\n    \"\"\"\n    Detect whether the dataset contains images or non-image data.\n    \n    Args:\n        dataset_path: Path to dataset\n        \n    Returns:\n        str: 'image' or 'non_image'\n    \"\"\"\n    # Check if directory exists\n    if not os.path.exists(dataset_path):\n        raise FileNotFoundError(f\"Dataset path does not exist: {dataset_path}\")\n    \n    # If it's a file, check the file extension\n    if os.path.isfile(dataset_path):\n        # Common text/tabular data formats\n        if dataset_path.endswith(('.csv', '.tsv', '.txt', '.json', '.jsonl')):\n            return 'non_image'\n        # Common image formats\n        elif dataset_path.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff')):\n            return 'image'\n        # Archive formats that might contain either\n        elif dataset_path.endswith(('.zip', '.tar', '.gz', '.tgz')):\n            # Assume non-image for archives (will need to extract to be sure)\n            return 'non_image'\n        else:\n            logger.warning(f\"Unknown file type: {dataset_path}. Defaulting to non_image.\")\n            return 'non_image'\n    \n    # If it's a directory, check its contents\n    elif os.path.isdir(dataset_path):\n        # Check for common image dataset folder structures\n        if _is_image_directory(dataset_path):\n            return 'image'\n        # Check for common non-image dataset folder structures\n        elif _is_non_image_directory(dataset_path):\n            return 'non_image'\n        else:\n            # Default to non-image if can't determine\n            logger.warning(f\"Could not definitively determine dataset type for {dataset_path}. Defaulting to non_image.\")\n            return 'non_image'\n    \n    # Something went wrong\n    logger.error(f\"Unexpected path type: {dataset_path}\")\n    return 'non_image'\n\n\ndef _is_image_directory(directory: str) -> bool:\n    \"\"\""
    },
    "_is_image_directory": {
      "start_line": 862,
      "end_line": 909,
      "parameters": [
        {
          "name": "directory",
          "type": "str"
        }
      ],
      "return_type": "bool",
      "calls": [
        {
          "name": "os.walk",
          "line": 873
        },
        {
          "name": "os.path.exists",
          "line": 901
        },
        {
          "name": "os.path.exists",
          "line": 903
        },
        {
          "name": "os.path.join",
          "line": 901
        },
        {
          "name": "os.path.join",
          "line": 903
        },
        {
          "name": "dirs.clear",
          "line": 876
        },
        {
          "name": "len",
          "line": 881
        },
        {
          "name": "len",
          "line": 891
        },
        {
          "name": "root.count",
          "line": 875
        },
        {
          "name": "directory.count",
          "line": 875
        },
        {
          "name": "....endswith",
          "line": 880
        },
        {
          "name": "os.path.isdir",
          "line": 890
        },
        {
          "name": "os.path.join",
          "line": 894
        },
        {
          "name": "os.listdir",
          "line": 895
        },
        {
          "name": "d.lower",
          "line": 885
        },
        {
          "name": "os.path.join",
          "line": 890
        },
        {
          "name": "f.lower",
          "line": 880
        },
        {
          "name": "....endswith",
          "line": 896
        },
        {
          "name": "f.lower",
          "line": 896
        }
      ],
      "docstring": "\n    Check if a directory is likely to contain image data.\n    \n    Args:\n        directory: Directory path to check\n        \n    Returns:\n        bool: True if directory likely contains images, False otherwise\n    ",
      "code_snippet": "\n\ndef _is_image_directory(directory: str) -> bool:\n    \"\"\"\n    Check if a directory is likely to contain image data.\n    \n    Args:\n        directory: Directory path to check\n        \n    Returns:\n        bool: True if directory likely contains images, False otherwise\n    \"\"\"\n    # Look for common image dataset characteristics\n    for root, dirs, files in os.walk(directory, topdown=True, followlinks=False):\n        # Limit depth to prevent excessive scanning\n        if root.count(os.sep) - directory.count(os.sep) > 2:\n            dirs.clear()  # Don't descend further\n            continue\n        \n        # Check for common image file extensions\n        image_files = [f for f in files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'))]\n        if len(image_files) > 5:  # If we find several image files, assume it's an image dataset\n            return True\n        \n        # Check for common image dataset subdirectories\n        image_dirs = [d for d in dirs if d.lower() in ('images', 'imgs', 'photos', 'pictures')]\n        if image_dirs:\n            return True\n        \n        # Check for class directories in image classification datasets\n        class_dirs = [d for d in dirs if os.path.isdir(os.path.join(root, d))]\n        if len(class_dirs) > 2:  # Several class directories suggest an image classification dataset\n            # Check if there are image files in at least one class directory\n            for class_dir in class_dirs[:3]:  # Check first few class dirs\n                class_path = os.path.join(root, class_dir)\n                class_files = os.listdir(class_path)\n                image_files = [f for f in class_files if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'))]\n                if image_files:\n                    return True\n    \n    # Check for CIFAR-10/100 specific folders\n    if os.path.exists(os.path.join(directory, 'cifar-10-batches-py')):\n        return True\n    if os.path.exists(os.path.join(directory, 'cifar-100-python')):\n        return True\n    \n    # If we didn't find evidence of image data, assume it's not an image directory\n    return False\n\n\ndef _is_non_image_directory(directory: str) -> bool:\n    \"\"\""
    },
    "_is_non_image_directory": {
      "start_line": 910,
      "end_line": 946,
      "parameters": [
        {
          "name": "directory",
          "type": "str"
        }
      ],
      "return_type": "bool",
      "calls": [
        {
          "name": "os.walk",
          "line": 921
        },
        {
          "name": "any",
          "line": 938
        },
        {
          "name": "dirs.clear",
          "line": 924
        },
        {
          "name": "len",
          "line": 929
        },
        {
          "name": "os.path.exists",
          "line": 938
        },
        {
          "name": "root.count",
          "line": 923
        },
        {
          "name": "directory.count",
          "line": 923
        },
        {
          "name": "....endswith",
          "line": 928
        },
        {
          "name": "os.path.join",
          "line": 938
        },
        {
          "name": "d.lower",
          "line": 933
        },
        {
          "name": "f.lower",
          "line": 928
        }
      ],
      "docstring": "\n    Check if a directory is likely to contain non-image data.\n    \n    Args:\n        directory: Directory path to check\n        \n    Returns:\n        bool: True if directory likely contains non-image data, False otherwise\n    ",
      "code_snippet": "\n\ndef _is_non_image_directory(directory: str) -> bool:\n    \"\"\"\n    Check if a directory is likely to contain non-image data.\n    \n    Args:\n        directory: Directory path to check\n        \n    Returns:\n        bool: True if directory likely contains non-image data, False otherwise\n    \"\"\"\n    # Look for common non-image dataset characteristics\n    for root, dirs, files in os.walk(directory, topdown=True, followlinks=False):\n        # Limit depth to prevent excessive scanning\n        if root.count(os.sep) - directory.count(os.sep) > 2:\n            dirs.clear()  # Don't descend further\n            continue\n        \n        # Check for common text/tabular data files\n        text_files = [f for f in files if f.lower().endswith(('.csv', '.tsv', '.txt', '.json', '.jsonl'))]\n        if len(text_files) > 0:\n            return True\n        \n        # Check for common NLP dataset subdirectories\n        nlp_dirs = [d for d in dirs if d.lower() in ('text', 'corpus', 'documents', 'nlp')]\n        if nlp_dirs:\n            return True\n    \n    # Check for common non-image dataset files\n    if any(os.path.exists(os.path.join(directory, f)) for f in \n           ['train.csv', 'test.csv', 'data.csv', 'dataset.json']):\n        return True\n    \n    # If we didn't find evidence of non-image data, the detector should still make a decision\n    # based on the presence/absence of image data\n    return False\n\n\ndef check_existing_pattern_map(dataset_name: str) -> Optional[str]:\n    \"\"\""
    },
    "check_existing_pattern_map": {
      "start_line": 947,
      "end_line": 983,
      "parameters": [
        {
          "name": "dataset_name",
          "type": "str"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "os.path.join",
          "line": 958
        },
        {
          "name": "os.path.exists",
          "line": 960
        },
        {
          "name": "logger.info",
          "line": 980
        },
        {
          "name": "pattern_files.sort",
          "line": 975
        },
        {
          "name": "os.path.join",
          "line": 976
        },
        {
          "name": "logger.info",
          "line": 977
        },
        {
          "name": "open",
          "line": 961
        },
        {
          "name": "....strip",
          "line": 962
        },
        {
          "name": "os.listdir",
          "line": 970
        },
        {
          "name": "os.path.exists",
          "line": 965
        },
        {
          "name": "logger.info",
          "line": 966
        },
        {
          "name": "f.startswith",
          "line": 971
        },
        {
          "name": "f.endswith",
          "line": 971
        },
        {
          "name": "f.read",
          "line": 962
        },
        {
          "name": "dataset_name.lower",
          "line": 965
        },
        {
          "name": "latest_path.lower",
          "line": 965
        },
        {
          "name": "dataset_name.lower",
          "line": 971
        }
      ],
      "docstring": "\n    Check if a pattern map already exists for the dataset.\n    \n    Args:\n        dataset_name: Name of the dataset\n        \n    Returns:\n        Path to existing pattern map or None if not found\n    ",
      "code_snippet": "\n\ndef check_existing_pattern_map(dataset_name: str) -> Optional[str]:\n    \"\"\"\n    Check if a pattern map already exists for the dataset.\n    \n    Args:\n        dataset_name: Name of the dataset\n        \n    Returns:\n        Path to existing pattern map or None if not found\n    \"\"\"\n    # Try to load from latest pattern map reference\n    latest_path_file = os.path.join(PATTERN_MAPS_DIR, \"latest_pattern_map_path.txt\")\n    \n    if os.path.exists(latest_path_file):\n        with open(latest_path_file, 'r') as f:\n            latest_path = f.read().strip()\n            \n            # Check if this is for the requested dataset\n            if os.path.exists(latest_path) and dataset_name.lower() in latest_path.lower():\n                logger.info(f\"Found existing pattern map at {latest_path}\")\n                return latest_path\n    \n    # Check for pattern maps matching the dataset name\n    pattern_files = [f for f in os.listdir(PATTERN_MAPS_DIR) \n                    if f.startswith(f\"pattern_map_{dataset_name.lower()}\") and f.endswith(\".json\")]\n    \n    if pattern_files:\n        # Sort by timestamp (assuming the naming convention includes timestamp)\n        pattern_files.sort(reverse=True)\n        latest_pattern_file = os.path.join(PATTERN_MAPS_DIR, pattern_files[0])\n        logger.info(f\"Found existing pattern map at {latest_pattern_file}\")\n        return latest_pattern_file\n    \n    logger.info(f\"No existing pattern map found for {dataset_name}\")\n    return None\n\n\ndef load_pattern_map(pattern_map_path: str) -> Dict[str, Any]:\n    \"\"\""
    },
    "load_pattern_map": {
      "start_line": 984,
      "end_line": 1005,
      "parameters": [
        {
          "name": "pattern_map_path",
          "type": "str"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "os.path.exists",
          "line": 994
        },
        {
          "name": "FileNotFoundError",
          "line": 995
        },
        {
          "name": "open",
          "line": 998
        },
        {
          "name": "json.load",
          "line": 999
        },
        {
          "name": "logger.info",
          "line": 1000
        },
        {
          "name": "ValueError",
          "line": 1003
        }
      ],
      "docstring": "\n    Load a pattern map from file.\n    \n    Args:\n        pattern_map_path: Path to the pattern map file\n        \n    Returns:\n        Loaded pattern map\n    ",
      "code_snippet": "\n\ndef load_pattern_map(pattern_map_path: str) -> Dict[str, Any]:\n    \"\"\"\n    Load a pattern map from file.\n    \n    Args:\n        pattern_map_path: Path to the pattern map file\n        \n    Returns:\n        Loaded pattern map\n    \"\"\"\n    if not os.path.exists(pattern_map_path):\n        raise FileNotFoundError(f\"Pattern map not found at {pattern_map_path}\")\n    \n    try:\n        with open(pattern_map_path, 'r') as f:\n            pattern_map = json.load(f)\n            logger.info(f\"Loaded pattern map from {pattern_map_path}\")\n            return pattern_map\n    except json.JSONDecodeError:\n        raise ValueError(f\"Invalid JSON in pattern map file: {pattern_map_path}\")\n\n\ndef map_image_dataset(dataset_path: str, output_path: str, model_type=None, batch_size=None,\n                     test_mode: bool = False, **kwargs) -> Dict[str, Any]:"
    },
    "map_image_dataset": {
      "start_line": 1006,
      "end_line": 1088,
      "parameters": [
        {
          "name": "dataset_path",
          "type": "str"
        },
        {
          "name": "output_path",
          "type": "str"
        },
        {
          "name": "model_type"
        },
        {
          "name": "batch_size"
        },
        {
          "name": "test_mode",
          "type": "bool"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "logger.info",
          "line": 1023
        },
        {
          "name": "logger.info",
          "line": 1024
        },
        {
          "name": "BatchProcessedPatternMapper",
          "line": 1027
        },
        {
          "name": "mapper.load_dataset",
          "line": 1031
        },
        {
          "name": "mapper.create_pattern_map_batched",
          "line": 1066
        },
        {
          "name": "dataset_params.get",
          "line": 1044
        },
        {
          "name": "logger.info",
          "line": 1047
        },
        {
          "name": "create_model",
          "line": 1048
        },
        {
          "name": "mapper.run_hardware_diagnostics",
          "line": 1057
        },
        {
          "name": "mapper.run_hardware_diagnostics",
          "line": 1060
        },
        {
          "name": "mapper.save_pattern_map",
          "line": 1074
        },
        {
          "name": "mapper.create_visualizations",
          "line": 1077
        },
        {
          "name": "logger.error",
          "line": 1085
        },
        {
          "name": "dataset_path.lower",
          "line": 1044
        },
        {
          "name": "os.path.basename",
          "line": 1074
        },
        {
          "name": "str",
          "line": 1085
        }
      ],
      "docstring": "\n    Generate pattern map for image dataset using batch processing.\n    \n    Args:\n        dataset_path: Path to dataset\n        output_path: Output path for pattern map\n        model_type: Model type for hardware-aware batch sizing (optional)\n        batch_size: Batch size for processing (None for automatic)\n        test_mode: Whether to run in test mode (limited samples)\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Generated pattern map\n    ",
      "code_snippet": "\n\ndef map_image_dataset(dataset_path: str, output_path: str, model_type=None, batch_size=None,\n                     test_mode: bool = False, **kwargs) -> Dict[str, Any]:\n    \"\"\"\n    Generate pattern map for image dataset using batch processing.\n    \n    Args:\n        dataset_path: Path to dataset\n        output_path: Output path for pattern map\n        model_type: Model type for hardware-aware batch sizing (optional)\n        batch_size: Batch size for processing (None for automatic)\n        test_mode: Whether to run in test mode (limited samples)\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Generated pattern map\n    \"\"\"\n    # Log the mapping process\n    logger.info(f\"Mapping image dataset: {dataset_path}\")\n    logger.info(f\"Output will be saved to: {output_path}\")\n    \n    # Create batch-processed pattern mapper\n    mapper = BatchProcessedPatternMapper()\n    \n    try:\n        # Load dataset\n        trainset, testset = mapper.load_dataset(dataset_path)\n        \n        # Run hardware diagnostics for batch size boundaries\n        model = None\n        if model_type:\n            # Get dataset parameters\n            dataset_params = {\n                'cifar10': {'num_classes': 10, 'input_channels': 3, 'input_size': 32},\n                'cifar100': {'num_classes': 100, 'input_channels': 3, 'input_size': 32},\n                'mnist': {'num_classes': 10, 'input_channels': 1, 'input_size': 28},\n            }\n            \n            # Get parameters for the selected dataset\n            dataset_config = dataset_params.get(dataset_path.lower(), \n                                              {'num_classes': 10, 'input_channels': 3, 'input_size': 32})\n            \n            logger.info(f\"Creating model {model_type} for hardware-aware batch sizing\")\n            model = create_model(\n                model_type=model_type,\n                use_pretrained=False,  # No need for pretrained weights just for batch sizing\n                num_classes=dataset_config['num_classes'],\n                input_channels=dataset_config['input_channels'],\n                input_size=dataset_config['input_size']\n            )\n            \n            # Run model-aware hardware diagnostics\n            mapper.run_hardware_diagnostics(model)\n        else:\n            # Run hardware diagnostics without model\n            mapper.run_hardware_diagnostics()\n        \n        # Set sample limit for test mode\n        sample_limit = 100 if test_mode else None\n        \n        # Create pattern map using batch processing\n        pattern_map = mapper.create_pattern_map_batched(\n            dataset=trainset,\n            batch_size=batch_size,\n            sample_limit=sample_limit\n        )\n        \n        # Save the pattern map to the output path if not in test mode\n        if not test_mode and output_path:\n            filepath = mapper.save_pattern_map(pattern_map, os.path.basename(dataset_path))\n            \n            # Create visualizations\n            mapper.create_visualizations(pattern_map)\n            \n            # Store the output path in the pattern map for reference\n            pattern_map[\"output_path\"] = filepath\n        \n        return pattern_map\n    \n    except Exception as e:\n        logger.error(f\"Error generating pattern map for image dataset: {str(e)}\")\n        raise\n\n\ndef map_non_image_dataset(dataset_path: str, output_path: str, test_mode: bool = False, **kwargs) -> Dict[str, Any]:\n    \"\"\""
    },
    "map_non_image_dataset": {
      "start_line": 1089,
      "end_line": 1165,
      "parameters": [
        {
          "name": "dataset_path",
          "type": "str"
        },
        {
          "name": "output_path",
          "type": "str"
        },
        {
          "name": "test_mode",
          "type": "bool"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "logger.info",
          "line": 1104
        },
        {
          "name": "logger.info",
          "line": 1105
        },
        {
          "name": "get_dataset_path",
          "line": 1112
        },
        {
          "name": "logger.info",
          "line": 1127
        },
        {
          "name": "logger.info",
          "line": 1128
        },
        {
          "name": "logger.info",
          "line": 1129
        },
        {
          "name": "generate_pattern_map_for_non_image_dataset",
          "line": 1133
        },
        {
          "name": "logger.info",
          "line": 1156
        },
        {
          "name": "logger.info",
          "line": 1157
        },
        {
          "name": "....strftime",
          "line": 1142
        },
        {
          "name": "os.path.basename",
          "line": 1143
        },
        {
          "name": "open",
          "line": 1153
        },
        {
          "name": "json.dump",
          "line": 1154
        },
        {
          "name": "logger.error",
          "line": 1162
        },
        {
          "name": "datetime.now",
          "line": 1142
        },
        {
          "name": "len",
          "line": 1156
        },
        {
          "name": "pattern_map.get",
          "line": 1156
        },
        {
          "name": "str",
          "line": 1162
        }
      ],
      "docstring": "\n    Generate pattern map for non-image dataset.\n    \n    Args:\n        dataset_path: Path to dataset\n        output_path: Output path for pattern map\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Generated pattern map\n    ",
      "code_snippet": "\n\ndef map_non_image_dataset(dataset_path: str, output_path: str, test_mode: bool = False, **kwargs) -> Dict[str, Any]:\n    \"\"\"\n    Generate pattern map for non-image dataset.\n    \n    Args:\n        dataset_path: Path to dataset\n        output_path: Output path for pattern map\n        **kwargs: Additional parameters\n        \n    Returns:\n        dict: Generated pattern map\n    \"\"\"\n    from isekaizen.pattern.detection import generate_pattern_map_for_non_image_dataset\n    \n    # Log the mapping process\n    logger.info(f\"Mapping non-image dataset: {dataset_path}\")\n    logger.info(f\"Output will be saved to: {output_path}\")\n    \n    # Determine parameters automatically\n    # For test mode, just use a small subset for quick validation\n    sample_limit = 100 if test_mode else None\n    \n    # Auto-determine complexity factors based on dataset\n    dataset_info = get_dataset_path(dataset_path)\n    if dataset_info[\"complexity\"] == \"high\":\n        text_complexity_factor = 1.5\n        tabular_complexity_factor = 1.2\n    elif dataset_info[\"complexity\"] == \"medium\":\n        text_complexity_factor = 1.2\n        tabular_complexity_factor = 0.9\n    else:\n        text_complexity_factor = 1.0\n        tabular_complexity_factor = 0.7\n    \n    # No arbitrary max feature limits - process the full dataset\n    max_features = None  # No limit on features\n    \n    if not test_mode:\n        logger.info(f\"Using text complexity factor: {text_complexity_factor}\")\n        logger.info(f\"Using tabular complexity factor: {tabular_complexity_factor}\")\n        logger.info(f\"Maximum features: {max_features if max_features else 'No limit'}\")\n    \n    # Generate the pattern map\n    try:\n        pattern_map = generate_pattern_map_for_non_image_dataset(\n            dataset_path=dataset_path,\n            text_complexity_factor=text_complexity_factor,\n            tabular_complexity_factor=tabular_complexity_factor,\n            sample_limit=sample_limit\n        )\n        \n        # Add metadata to pattern map\n        pattern_map['metadata'] = {\n            'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n            'dataset': os.path.basename(dataset_path),\n            'data_type': 'non_image',\n            'mapping_params': {\n                'text_complexity_factor': text_complexity_factor,\n                'tabular_complexity_factor': tabular_complexity_factor,\n                'max_features': max_features\n            }\n        }\n        \n        # Save the pattern map to the output path\n        with open(output_path, 'w') as f:\n            json.dump(pattern_map, f, indent=2)\n        \n        logger.info(f\"Pattern map generated with {len(pattern_map.get('pattern_distribution', {}))} pattern types\")\n        logger.info(f\"Saved pattern map to: {output_path}\")\n        \n        return pattern_map\n    \n    except Exception as e:\n        logger.error(f\"Error generating pattern map for non-image dataset: {str(e)}\")\n        raise\n\n\ndef prepare_dataset_for_training(\n    dataset_name: str, "
    },
    "prepare_dataset_for_training": {
      "start_line": 1166,
      "end_line": 1325,
      "parameters": [
        {
          "name": "dataset_name",
          "type": "str"
        },
        {
          "name": "model_type",
          "type": "str"
        },
        {
          "name": "output_dir",
          "type": "str"
        },
        {
          "name": "skip_bias_test",
          "type": "bool"
        },
        {
          "name": "pretrained",
          "type": "bool"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "get_dataset_path",
          "line": 1187
        },
        {
          "name": "time.time",
          "line": 1196
        },
        {
          "name": "....strftime",
          "line": 1198
        },
        {
          "name": "logger.info",
          "line": 1200
        },
        {
          "name": "check_existing_pattern_map",
          "line": 1203
        },
        {
          "name": "logger.info",
          "line": 1302
        },
        {
          "name": "get_model_type_for_dataset",
          "line": 1191
        },
        {
          "name": "logger.info",
          "line": 1207
        },
        {
          "name": "os.path.join",
          "line": 1214
        },
        {
          "name": "map_image_dataset",
          "line": 1217
        },
        {
          "name": "load_pattern_map",
          "line": 1224
        },
        {
          "name": "logger.info",
          "line": 1228
        },
        {
          "name": "dataset_params.get",
          "line": 1238
        },
        {
          "name": "logger.info",
          "line": 1242
        },
        {
          "name": "BatchProcessedPatternMapper",
          "line": 1245
        },
        {
          "name": "mapper.load_dataset",
          "line": 1246
        },
        {
          "name": "test_pattern_bias",
          "line": 1248
        },
        {
          "name": "logger.info",
          "line": 1256
        },
        {
          "name": "logger.info",
          "line": 1267
        },
        {
          "name": "BatchProcessedPatternMapper",
          "line": 1270
        },
        {
          "name": "mapper.load_dataset",
          "line": 1271
        },
        {
          "name": "logger.info",
          "line": 1275
        },
        {
          "name": "create_pattern_biased_augmentations",
          "line": 1278
        },
        {
          "name": "os.makedirs",
          "line": 1287
        },
        {
          "name": "os.path.join",
          "line": 1291
        },
        {
          "name": "save_augmentation_data",
          "line": 1294
        },
        {
          "name": "logger.info",
          "line": 1295
        },
        {
          "name": "logger.info",
          "line": 1296
        },
        {
          "name": "logger.info",
          "line": 1298
        },
        {
          "name": "time.time",
          "line": 1301
        },
        {
          "name": "hasattr",
          "line": 1318
        },
        {
          "name": "logger.info",
          "line": 1193
        },
        {
          "name": "logger.info",
          "line": 1195
        },
        {
          "name": "datetime.now",
          "line": 1198
        },
        {
          "name": "os.path.exists",
          "line": 1210
        },
        {
          "name": "os.makedirs",
          "line": 1211
        },
        {
          "name": "dataset_name.lower",
          "line": 1238
        },
        {
          "name": "augmented_dataset.get_augmentation_info",
          "line": 1319
        },
        {
          "name": "torch.device",
          "line": 1253
        },
        {
          "name": "len",
          "line": 1262
        },
        {
          "name": "torch.device",
          "line": 1283
        },
        {
          "name": "torch.cuda.is_available",
          "line": 1253
        },
        {
          "name": "torch.cuda.is_available",
          "line": 1283
        }
      ],
      "docstring": "\n    One-step dataset preparation with pattern mapping, bias testing, and augmentation.\n    \n    Args:\n        dataset_name: Name of the dataset\n        model_type: Type of model to test\n        output_dir: Output directory for augmentation data\n        skip_bias_test: Skip bias testing (use equal augmentation for all patterns)\n        pretrained: Whether to use pretrained model weights\n        \n    Returns:\n        Dictionary with pattern map, bias scores, and augmented dataset\n    ",
      "code_snippet": "\n\ndef prepare_dataset_for_training(\n    dataset_name: str, \n    model_type: str = None, \n    output_dir: str = None,\n    skip_bias_test: bool = False,\n    pretrained: bool = False\n) -> Dict[str, Any]:\n    \"\"\"\n    One-step dataset preparation with pattern mapping, bias testing, and augmentation.\n    \n    Args:\n        dataset_name: Name of the dataset\n        model_type: Type of model to test\n        output_dir: Output directory for augmentation data\n        skip_bias_test: Skip bias testing (use equal augmentation for all patterns)\n        pretrained: Whether to use pretrained model weights\n        \n    Returns:\n        Dictionary with pattern map, bias scores, and augmented dataset\n    \"\"\"\n    # Get dataset info first\n    dataset_info = get_dataset_path(dataset_name)\n    \n    # If no model specified, recommend one based on dataset modality\n    if model_type is None:\n        model_type = get_model_type_for_dataset(dataset_info, model_type)\n        if model_type:\n            logger.info(f\"Using recommended model {model_type} for dataset {dataset_name}\")\n        else:\n            logger.info(f\"No specific model was selected for {dataset_name}\")\n    start_time = time.time()\n    output_dir = output_dir or METRICS_DIR\n    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n    \n    logger.info(f\"Preparing {dataset_name} dataset for {model_type or 'all'} models\")\n    \n    # 1. Check if pattern map exists\n    pattern_map_path = check_existing_pattern_map(dataset_name)\n    \n    if not pattern_map_path:\n        # 2. Pattern map doesn't exist - create it with batch processing\n        logger.info(\"Creating new pattern map with batch processing\")\n        \n        # Generate output path\n        if not os.path.exists(PATTERN_MAPS_DIR):\n            os.makedirs(PATTERN_MAPS_DIR, exist_ok=True)\n        \n        pattern_map_filename = f\"pattern_map_{dataset_name}_{timestamp}.json\"\n        pattern_map_path = os.path.join(PATTERN_MAPS_DIR, pattern_map_filename)\n        \n        # Create pattern map\n        pattern_map = map_image_dataset(\n            dataset_path=dataset_name,\n            output_path=pattern_map_path,\n            model_type=model_type\n        )\n    else:\n        # Load existing pattern map\n        pattern_map = load_pattern_map(pattern_map_path)\n    \n    # 3. Create model and run bias test if requested\n    if model_type and not skip_bias_test:\n        logger.info(f\"Creating model {model_type} for bias testing\")\n        \n        # Get dataset parameters\n        dataset_params = {\n            'cifar10': {'num_classes': 10, 'input_channels': 3, 'input_size': 32},\n            'cifar100': {'num_classes': 100, 'input_channels': 3, 'input_size': 32},\n            'mnist': {'num_classes': 10, 'input_channels': 1, 'input_size': 28},\n        }\n        \n        # Get parameters for the selected dataset\n        dataset_config = dataset_params.get(dataset_name.lower(), \n                                           {'num_classes': 10, 'input_channels': 3, 'input_size': 32})\n        \n        # Test model pattern bias\n        logger.info(\"Testing model pattern bias...\")\n        \n        # Create mapper to access datasets\n        mapper = BatchProcessedPatternMapper()\n        trainset, _ = mapper.load_dataset(dataset_name)\n        \n        bias_scores, bias_results = test_pattern_bias(\n            model_type=model_type,\n            pretrained=pretrained,\n            dataset=trainset,\n            pattern_map=pattern_map,\n            device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        )\n    else:\n        logger.info(\"Skipping bias testing (using equal bias for all patterns)\")\n        # Assume equal bias for all pattern types\n        if pattern_map and 'pattern_types' in pattern_map:\n            pattern_types = pattern_map['pattern_types']\n        else:\n            pattern_types = ['structural', 'statistical', 'temporal']\n        bias_scores = {pt: 1.0 / len(pattern_types) for pt in pattern_types}\n        bias_results = None\n    \n    # 4. Create pre-augmented dataset\n    if model_type:\n        logger.info(\"Creating pre-augmented dataset...\")\n        \n        # Create mapper to access datasets\n        mapper = BatchProcessedPatternMapper()\n        trainset, _ = mapper.load_dataset(dataset_name)\n        \n        # Fixed augmentation ratio set to 33%\n        augmentation_ratio = 0.33\n        logger.info(f\"Creating pre-pattern augmented dataset with fixed ratio of {augmentation_ratio:.2f} (33%)\")\n        \n        # Create augmented dataset\n        augmented_dataset = create_pattern_biased_augmentations(\n            dataset=trainset,\n            pattern_map=pattern_map,\n            bias_scores=bias_scores,\n            augmentation_ratio=augmentation_ratio,\n            device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        )\n        \n        # Always save augmentation info\n        os.makedirs(output_dir, exist_ok=True)\n        \n        # Create a descriptive filename including dataset and model info\n        model_info = f\"{model_type}{'-pretrained' if pretrained else ''}\"\n        augmentation_info_path = os.path.join(output_dir, f\"augmentation_info_{dataset_name}_{model_info}_{timestamp}.json\")\n        \n        # Save data, including the complete pattern map\n        save_augmentation_data(augmented_dataset, augmentation_info_path, pattern_map)\n        logger.info(f\"Saved augmentation info to {augmentation_info_path}\")\n        logger.info(f\"Included complete pattern map data for EVE optimizer and pattern tracker\")\n    else:\n        logger.info(\"Skipping augmentation (no model specified)\")\n        augmented_dataset = None\n    \n    elapsed_time = time.time() - start_time\n    logger.info(f\"Dataset preparation completed in {elapsed_time:.2f} seconds\")\n    \n    # Return all prepared data\n    result = {\n        \"pattern_map\": pattern_map,\n        \"pattern_map_path\": pattern_map_path,\n        \"bias_scores\": bias_scores\n    }\n    \n    if bias_results:\n        result[\"bias_results\"] = bias_results\n    \n    if augmented_dataset:\n        result[\"augmented_dataset\"] = augmented_dataset\n        \n        # Include augmentation info\n        if hasattr(augmented_dataset, 'get_augmentation_info'):\n            result[\"augmentation_info\"] = augmented_dataset.get_augmentation_info()\n    \n    result[\"elapsed_time\"] = elapsed_time\n    \n    return result\n\n\ndef map_dataset(dataset_path: str, output_path: Optional[str] = None, \n               force_type: Optional[str] = None, test_mode: bool = False, "
    },
    "map_dataset": {
      "start_line": 1326,
      "end_line": 1407,
      "parameters": [
        {
          "name": "dataset_path",
          "type": "str"
        },
        {
          "name": "output_path"
        },
        {
          "name": "force_type"
        },
        {
          "name": "test_mode",
          "type": "bool"
        },
        {
          "name": "model_type"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "get_dataset_path",
          "line": 1348
        },
        {
          "name": "logger.info",
          "line": 1366
        },
        {
          "name": "get_model_type_for_dataset",
          "line": 1352
        },
        {
          "name": "....strftime",
          "line": 1370
        },
        {
          "name": "os.path.basename",
          "line": 1371
        },
        {
          "name": "os.path.isdir",
          "line": 1372
        },
        {
          "name": "os.path.join",
          "line": 1377
        },
        {
          "name": "map_image_dataset",
          "line": 1381
        },
        {
          "name": "map_non_image_dataset",
          "line": 1389
        },
        {
          "name": "os.path.join",
          "line": 1398
        },
        {
          "name": "logger.info",
          "line": 1401
        },
        {
          "name": "logger.info",
          "line": 1354
        },
        {
          "name": "logger.info",
          "line": 1356
        },
        {
          "name": "detect_dataset_type",
          "line": 1364
        },
        {
          "name": "os.path.basename",
          "line": 1373
        },
        {
          "name": "open",
          "line": 1399
        },
        {
          "name": "f.write",
          "line": 1400
        },
        {
          "name": "logger.warning",
          "line": 1403
        },
        {
          "name": "datetime.now",
          "line": 1370
        },
        {
          "name": "os.path.normpath",
          "line": 1373
        },
        {
          "name": "os.path.abspath",
          "line": 1400
        },
        {
          "name": "str",
          "line": 1403
        }
      ],
      "docstring": "\n    Map a dataset to pattern types using the appropriate method.\n    \n    This function serves as the main entry point for pattern mapping,\n    automatically detecting the dataset type and applying the appropriate\n    mapping method.\n    \n    Args:\n        dataset_path: Path to the dataset\n        output_path: Output path for the pattern map (optional, will be generated if not provided)\n        force_type: Force dataset type ('image' or 'non_image') if not None\n        test_mode: Whether to run in test mode (limited samples)\n        model_type: Model type for hardware-aware batch sizing (optional)\n        **kwargs: Additional parameters for specific mapping methods\n        \n    Returns:\n        dict: Generated pattern map\n    ",
      "code_snippet": "\n\ndef map_dataset(dataset_path: str, output_path: Optional[str] = None, \n               force_type: Optional[str] = None, test_mode: bool = False, \n               model_type: Optional[str] = None, **kwargs) -> Dict[str, Any]:\n    \"\"\"\n    Map a dataset to pattern types using the appropriate method.\n    \n    This function serves as the main entry point for pattern mapping,\n    automatically detecting the dataset type and applying the appropriate\n    mapping method.\n    \n    Args:\n        dataset_path: Path to the dataset\n        output_path: Output path for the pattern map (optional, will be generated if not provided)\n        force_type: Force dataset type ('image' or 'non_image') if not None\n        test_mode: Whether to run in test mode (limited samples)\n        model_type: Model type for hardware-aware batch sizing (optional)\n        **kwargs: Additional parameters for specific mapping methods\n        \n    Returns:\n        dict: Generated pattern map\n    \"\"\"\n    # Get dataset info\n    dataset_info = get_dataset_path(dataset_path)\n    \n    # If no model specified, recommend one based on dataset modality\n    if model_type is None:\n        model_type = get_model_type_for_dataset(dataset_info, model_type)\n        if model_type:\n            logger.info(f\"Using recommended model {model_type} for dataset {dataset_path}\")\n        else:\n            logger.info(f\"No specific model was selected for {dataset_path}\")\n    \n    # Determine dataset type if not forced\n    dataset_type = force_type\n    if dataset_type is None:\n        if dataset_info[\"type\"] != \"auto\":\n            dataset_type = dataset_info[\"type\"]\n        else:\n            dataset_type = detect_dataset_type(dataset_path)\n    \n    logger.info(f\"Dataset type determined as: {dataset_type}\")\n    \n    # Generate output path if not provided\n    if output_path is None:\n        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n        base_name = os.path.basename(dataset_path)\n        if os.path.isdir(dataset_path):\n            base_name = os.path.basename(os.path.normpath(dataset_path))\n        output_filename = f\"pattern_map_{base_name}_{timestamp}.json\"\n        \n        # Use standardized pattern maps directory\n        output_path = os.path.join(PATTERN_MAPS_DIR, output_filename)\n    \n    # Map dataset based on type\n    if dataset_type == 'image':\n        pattern_map = map_image_dataset(\n            dataset_path=dataset_path, \n            output_path=output_path, \n            model_type=model_type,\n            test_mode=test_mode, \n            **kwargs\n        )\n    else:\n        pattern_map = map_non_image_dataset(\n            dataset_path=dataset_path, \n            output_path=output_path, \n            test_mode=test_mode, \n            **kwargs\n        )\n    \n    # Update latest map path reference\n    try:\n        latest_path_file = os.path.join(PATTERN_MAPS_DIR, \"latest_pattern_map_path.txt\")\n        with open(latest_path_file, 'w') as f:\n            f.write(os.path.abspath(output_path))\n        logger.info(f\"Updated latest pattern map reference to: {output_path}\")\n    except Exception as e:\n        logger.warning(f\"Could not update latest pattern map reference: {str(e)}\")\n    \n    return pattern_map\n\n\ndef get_model_type_for_dataset(dataset_info: Dict[str, Any], requested_model: Optional[str] = None) -> Optional[str]:\n    \"\"\""
    },
    "get_model_type_for_dataset": {
      "start_line": 1408,
      "end_line": 1434,
      "parameters": [
        {
          "name": "dataset_info"
        },
        {
          "name": "requested_model"
        }
      ],
      "return_type": "complex_type",
      "calls": [
        {
          "name": "dataset_info.get",
          "line": 1423
        },
        {
          "name": "dataset_info.get",
          "line": 1429
        }
      ],
      "docstring": "\n    Determine the appropriate model type for a dataset based on its modality.\n    \n    Args:\n        dataset_info: Dataset information dictionary\n        requested_model: The model type requested by the user (if any)\n        \n    Returns:\n        str: Recommended model type or None if no suitable model is found\n    ",
      "code_snippet": "\n\ndef get_model_type_for_dataset(dataset_info: Dict[str, Any], requested_model: Optional[str] = None) -> Optional[str]:\n    \"\"\"\n    Determine the appropriate model type for a dataset based on its modality.\n    \n    Args:\n        dataset_info: Dataset information dictionary\n        requested_model: The model type requested by the user (if any)\n        \n    Returns:\n        str: Recommended model type or None if no suitable model is found\n    \"\"\"\n    if requested_model:\n        return requested_model\n        \n    # Default models by modality\n    modality = dataset_info.get(\"modality\", \"\")\n    \n    if modality == \"text\":\n        return \"bert-base\"  # Default text model\n    elif modality == \"tabular\":\n        return \"tabnet\"     # Default tabular model\n    elif dataset_info.get(\"type\") == \"image\":\n        return \"resnet18\"   # Default image model\n    \n    return None  # No suitable model determined\n\n\ndef get_dataset_path(dataset_name: str) -> Dict[str, Any]:\n    \"\"\""
    },
    "get_dataset_path": {
      "start_line": 1435,
      "end_line": 1483,
      "parameters": [
        {
          "name": "dataset_name",
          "type": "str"
        }
      ],
      "return_type": "complex_type",
      "calls": [],
      "docstring": "\n    Map standard dataset names to dataset information.\n    \n    Args:\n        dataset_name: Name of the dataset\n        \n    Returns:\n        dict: Dataset information including type and source\n    ",
      "code_snippet": "\n\ndef get_dataset_path(dataset_name: str) -> Dict[str, Any]:\n    \"\"\"\n    Map standard dataset names to dataset information.\n    \n    Args:\n        dataset_name: Name of the dataset\n        \n    Returns:\n        dict: Dataset information including type and source\n    \"\"\"\n    dataset_registry = {\n        # Standard Image datasets\n        \"cifar10\": {\"type\": \"image\", \"source\": \"torchvision\", \"complexity\": \"low\"},\n        \"cifar100\": {\"type\": \"image\", \"source\": \"torchvision\", \"complexity\": \"medium\"},\n        \"mnist\": {\"type\": \"image\", \"source\": \"torchvision\", \"complexity\": \"low\"},\n        \n        # Challenging Image datasets\n        \"imagenet\": {\"type\": \"image\", \"source\": \"torchvision\", \"complexity\": \"high\"},\n        \"places365\": {\"type\": \"image\", \"source\": \"custom\", \"complexity\": \"high\"},\n        \"coco\": {\"type\": \"image\", \"source\": \"custom\", \"complexity\": \"high\"},\n        \n        # Standard Text datasets\n        \"20newsgroups\": {\"type\": \"non_image\", \"source\": \"sklearn\", \"complexity\": \"medium\", \"modality\": \"text\"},\n        \"imdb\": {\"type\": \"non_image\", \"source\": \"torchtext\", \"complexity\": \"medium\", \"modality\": \"text\"},\n        \"reuters\": {\"type\": \"non_image\", \"source\": \"sklearn\", \"complexity\": \"medium\", \"modality\": \"text\"},\n        \n        # Challenging Text datasets\n        \"wikitext\": {\"type\": \"non_image\", \"source\": \"torchtext\", \"complexity\": \"high\", \"modality\": \"text\"},\n        \"squad\": {\"type\": \"non_image\", \"source\": \"custom\", \"complexity\": \"high\", \"modality\": \"text\"},\n        \"glue\": {\"type\": \"non_image\", \"source\": \"custom\", \"complexity\": \"high\", \"modality\": \"text\"},\n        \n        # Standard Tabular datasets\n        \"iris\": {\"type\": \"non_image\", \"source\": \"sklearn\", \"complexity\": \"low\", \"modality\": \"tabular\"},\n        \"wine\": {\"type\": \"non_image\", \"source\": \"sklearn\", \"complexity\": \"low\", \"modality\": \"tabular\"},\n        \"digits\": {\"type\": \"non_image\", \"source\": \"sklearn\", \"complexity\": \"low\", \"modality\": \"tabular\"},\n        \n        # Challenging Tabular datasets\n        \"higgs\": {\"type\": \"non_image\", \"source\": \"custom\", \"complexity\": \"high\", \"modality\": \"tabular\"},\n        \"criteo\": {\"type\": \"non_image\", \"source\": \"custom\", \"complexity\": \"high\", \"modality\": \"tabular\"},\n        \"nyc-taxi\": {\"type\": \"non_image\", \"source\": \"custom\", \"complexity\": \"high\", \"modality\": \"tabular\"}\n    }\n    \n    if dataset_name in dataset_registry:\n        return dataset_registry[dataset_name]\n    else:\n        # Assume it's a file path\n        return {\"type\": \"auto\", \"source\": \"file\", \"path\": dataset_name}\n\n\ndef validate_pattern_map(pattern_map: Dict[str, Any]) -> bool:\n    \"\"\""
    },
    "validate_pattern_map": {
      "start_line": 1484,
      "end_line": 1519,
      "parameters": [
        {
          "name": "pattern_map"
        }
      ],
      "return_type": "bool",
      "calls": [
        {
          "name": "set",
          "line": 1501
        },
        {
          "name": "set",
          "line": 1502
        },
        {
          "name": "all",
          "line": 1496
        },
        {
          "name": "logger.error",
          "line": 1497
        },
        {
          "name": "....keys",
          "line": 1502
        },
        {
          "name": "detected_types.issubset",
          "line": 1504
        },
        {
          "name": "logger.error",
          "line": 1505
        },
        {
          "name": "len",
          "line": 1508
        },
        {
          "name": "logger.error",
          "line": 1509
        },
        {
          "name": "sum",
          "line": 1513
        },
        {
          "name": "logger.error",
          "line": 1514
        },
        {
          "name": "....values",
          "line": 1513
        }
      ],
      "docstring": "\n    Validate a pattern map to ensure it follows the expected format.\n    \n    Args:\n        pattern_map: Pattern map to validate\n        \n    Returns:\n        bool: True if valid, False otherwise\n    ",
      "code_snippet": "\n\ndef validate_pattern_map(pattern_map: Dict[str, Any]) -> bool:\n    \"\"\"\n    Validate a pattern map to ensure it follows the expected format.\n    \n    Args:\n        pattern_map: Pattern map to validate\n        \n    Returns:\n        bool: True if valid, False otherwise\n    \"\"\"\n    # Check for required keys\n    required_keys = [\"pattern_distribution\", \"metadata\"]\n    if not all(key in pattern_map for key in required_keys):\n        logger.error(f\"Pattern map missing required keys: {[k for k in required_keys if k not in pattern_map]}\")\n        return False\n    \n    # Validate pattern types\n    expected_types = set([\"structural\", \"statistical\", \"temporal\"])\n    detected_types = set(pattern_map[\"pattern_distribution\"].keys())\n    \n    if not detected_types.issubset(expected_types):\n        logger.error(f\"Pattern map contains invalid pattern types: {detected_types - expected_types}\")\n        return False\n        \n    if len(detected_types) < 1:\n        logger.error(f\"Pattern map contains no valid pattern types\")\n        return False\n    \n    # Ensure we have at least some patterns\n    if sum(pattern_map[\"pattern_distribution\"].values()) == 0:\n        logger.error(\"Pattern map contains no patterns\")\n        return False\n        \n    return True\n\n\ndef main():\n    \"\"\"Main entry point for the pattern mapper tool.\"\"\""
    },
    "main": {
      "start_line": 1520,
      "end_line": 1738,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "signal.signal",
          "line": 1571
        },
        {
          "name": "argparse.ArgumentParser",
          "line": 1573
        },
        {
          "name": "parser.add_argument",
          "line": 1580
        },
        {
          "name": "parser.add_argument",
          "line": 1582
        },
        {
          "name": "parser.add_argument",
          "line": 1584
        },
        {
          "name": "parser.add_argument",
          "line": 1586
        },
        {
          "name": "parser.add_argument",
          "line": 1590
        },
        {
          "name": "parser.add_argument",
          "line": 1600
        },
        {
          "name": "parser.add_argument",
          "line": 1604
        },
        {
          "name": "parser.add_argument",
          "line": 1608
        },
        {
          "name": "logger.info",
          "line": 1565
        },
        {
          "name": "print",
          "line": 1566
        },
        {
          "name": "sys.exit",
          "line": 1568
        },
        {
          "name": "parser.parse_args",
          "line": 1613
        },
        {
          "name": "get_dataset_path",
          "line": 1616
        },
        {
          "name": "logger.info",
          "line": 1626
        },
        {
          "name": "logger.info",
          "line": 1631
        },
        {
          "name": "prepare_dataset_for_training",
          "line": 1633
        },
        {
          "name": "print",
          "line": 1642
        },
        {
          "name": "print",
          "line": 1643
        },
        {
          "name": "print",
          "line": 1644
        },
        {
          "name": "print",
          "line": 1645
        },
        {
          "name": "print",
          "line": 1646
        },
        {
          "name": "....items",
          "line": 1647
        },
        {
          "name": "print",
          "line": 1664
        },
        {
          "name": "logger.info",
          "line": 1667
        },
        {
          "name": "map_dataset",
          "line": 1670
        },
        {
          "name": "logger.info",
          "line": 1684
        },
        {
          "name": "logger.info",
          "line": 1685
        },
        {
          "name": "....items",
          "line": 1686
        },
        {
          "name": "sys.stdout.isatty",
          "line": 1690
        },
        {
          "name": "logger.info",
          "line": 1701
        },
        {
          "name": "map_dataset",
          "line": 1702
        },
        {
          "name": "logger.info",
          "line": 1711
        },
        {
          "name": "pattern_map.get",
          "line": 1714
        },
        {
          "name": "print",
          "line": 1715
        },
        {
          "name": "pattern_distribution.items",
          "line": 1716
        },
        {
          "name": "print",
          "line": 1720
        },
        {
          "name": "logger.info",
          "line": 1726
        },
        {
          "name": "print",
          "line": 1727
        },
        {
          "name": "logger.error",
          "line": 1730
        },
        {
          "name": "logger.error",
          "line": 1732
        },
        {
          "name": "print",
          "line": 1733
        },
        {
          "name": "print",
          "line": 1734
        },
        {
          "name": "print",
          "line": 1735
        },
        {
          "name": "detect_dataset_type",
          "line": 1624
        },
        {
          "name": "print",
          "line": 1648
        },
        {
          "name": "print",
          "line": 1652
        },
        {
          "name": "....items",
          "line": 1653
        },
        {
          "name": "print",
          "line": 1659
        },
        {
          "name": "print",
          "line": 1660
        },
        {
          "name": "print",
          "line": 1661
        },
        {
          "name": "print",
          "line": 1662
        },
        {
          "name": "validate_pattern_map",
          "line": 1679
        },
        {
          "name": "logger.error",
          "line": 1680
        },
        {
          "name": "logger.info",
          "line": 1687
        },
        {
          "name": "print",
          "line": 1717
        },
        {
          "name": "pattern_map.get",
          "line": 1719
        },
        {
          "name": "traceback.format_exc",
          "line": 1732
        },
        {
          "name": "print",
          "line": 1654
        },
        {
          "name": "input",
          "line": 1692
        },
        {
          "name": "response.lower",
          "line": 1693
        },
        {
          "name": "logger.info",
          "line": 1694
        },
        {
          "name": "print",
          "line": 1697
        },
        {
          "name": "str",
          "line": 1730
        },
        {
          "name": "str",
          "line": 1733
        },
        {
          "name": "aug_info.get",
          "line": 1660
        },
        {
          "name": "aug_info.get",
          "line": 1661
        },
        {
          "name": "aug_info.get",
          "line": 1662
        },
        {
          "name": "aug_info.get",
          "line": 1662
        }
      ],
      "docstring": "Main entry point for the pattern mapper tool.",
      "code_snippet": "\n\ndef main():\n    \"\"\"Main entry point for the pattern mapper tool.\"\"\"\n    # Create a more helpful description with examples\n    description = \"\"\"isekaiZen Pattern Mapper - Tool to automatically categorize datasets into the 3-category pattern taxonomy.\"\"\"\n    \n    epilog = \"\"\"\nExamples:\n\n  # Map a standard image dataset\n  python -m isekaizen.tools.pattern_mapper --dataset cifar10\n  \n  # Create pattern map and prepare dataset for training with specific model\n  python -m isekaizen.tools.pattern_mapper --dataset cifar10 --model resnet18\n  \n  # Use pretrained model weights for bias testing\n  python -m isekaizen.tools.pattern_mapper --dataset cifar10 --model resnet18 --pretrained\n  \n  # Map a standard text dataset with BERT\n  python -m isekaizen.tools.pattern_mapper --dataset 20newsgroups --model bert-base\n  \n  # Map a standard tabular dataset with a tabular model\n  python -m isekaizen.tools.pattern_mapper --dataset iris --model tabnet\n  \n  # Map a custom dataset\n  python -m isekaizen.tools.pattern_mapper --dataset /path/to/custom/data\n  \n  # Force dataset type\n  python -m isekaizen.tools.pattern_mapper --dataset /path/to/custom/data --force-type image\n  \nSupported Standard Datasets:\n  * Image: cifar10, cifar100, mnist, imagenet, places365, coco\n  * Text: 20newsgroups, imdb, reuters, wikitext, squad, glue\n  * Tabular: iris, wine, digits, higgs, criteo, nyc-taxi\n  \nSupported Models:\n  * Image: resnet18, resnet34, resnet50, vgg16, mobilenet_v2, efficientnet_b0\n  * Text: bert-base, bert-large, distilbert, roberta-base, xlnet-base\n  * Tabular: tabnet, xgboost, lightgbm, catboost\n\"\"\"\n    \n    # Set up graceful shutdown for Ctrl+C\n    import signal\n    \n    # Signal handler for graceful shutdown\n    def signal_handler(sig, frame):\n        logger.info(\"\\nProcess interrupted by user. Shutting down gracefully...\")\n        print(\"\\nProcess interrupted. Exiting...\")\n        # The return from this handler will allow the program to exit naturally\n        sys.exit(0)\n    \n    # Register the signal handler for SIGINT (Ctrl+C)\n    signal.signal(signal.SIGINT, signal_handler)\n    \n    parser = argparse.ArgumentParser(\n        description=description, \n        epilog=epilog,\n        formatter_class=argparse.RawDescriptionHelpFormatter\n    )\n    \n    # Dataset options\n    parser.add_argument('--dataset', required=True, \n                      help='Dataset name or path to dataset')\n    parser.add_argument('--output', type=str, default=None,\n                      help='Output file path for pattern map (default: auto-generated)')\n    parser.add_argument('--output-dir', type=str, default=None,\n                      help='Directory for output files (default: auto-generated)')\n    parser.add_argument('--force-type', choices=['image', 'non_image'], \n                      help='Force dataset type (auto-detect if not specified)')\n    \n    # Model options\n    parser.add_argument('--model', type=str, default=None,\n                      choices=[\n                          # Image models\n                          'resnet18', 'resnet34', 'resnet50', 'vgg16', 'mobilenet_v2', 'efficientnet_b0',\n                          # Text models\n                          'bert-base', 'bert-large', 'distilbert', 'roberta-base', 'xlnet-base',\n                          # Tabular models\n                          'tabnet', 'xgboost', 'lightgbm', 'catboost'\n                      ],\n                      help='Model architecture for bias testing and dataset preparation')\n    parser.add_argument('--pretrained', action='store_true',\n                      help='Use pretrained model weights for bias testing')\n    \n    # Skip options\n    parser.add_argument('--skip-bias-test', action='store_true',\n                      help='Skip bias testing (use equal augmentation for all patterns)')\n    \n    # Additional output options\n    parser.add_argument('--visualize', action='store_true',\n                      help='Create additional visualization plots')\n    \n    try:\n        # Parse arguments\n        args = parser.parse_args()\n        \n        # Get dataset info\n        dataset_info = get_dataset_path(args.dataset)\n        \n        # Detect dataset type\n        dataset_type = args.force_type\n        if dataset_type is None:\n            if dataset_info[\"type\"] != \"auto\":\n                dataset_type = dataset_info[\"type\"]\n            else:\n                dataset_type = detect_dataset_type(args.dataset)\n        \n        logger.info(f\"Dataset: {args.dataset} (Type: {dataset_type})\")\n        \n        # If a model is specified, always prepare the dataset\n        if args.model:\n            # Run the full preparation pipeline\n            logger.info(\"Running full dataset preparation pipeline\")\n            \n            result = prepare_dataset_for_training(\n                dataset_name=args.dataset,\n                model_type=args.model,\n                output_dir=args.output_dir,\n                skip_bias_test=args.skip_bias_test,\n                pretrained=args.pretrained\n            )\n            \n            # Print summary\n            print(\"\\nDataset Preparation Summary:\")\n            print(f\"Dataset: {args.dataset}\")\n            print(f\"Model: {args.model}\")\n            print(f\"Pattern map path: {result['pattern_map_path']}\")\n            print(f\"Pattern distribution:\")\n            for pattern_type, count in result['pattern_map']['pattern_distribution'].items():\n                print(f\"  {pattern_type}: {count} examples\")\n                \n            # Show bias scores if available\n            if 'bias_scores' in result and result['bias_scores']:\n                print(f\"\\nPattern Bias Scores:\")\n                for pattern_type, score in result['bias_scores'].items():\n                    print(f\"  {pattern_type}: {score:.3f}\")\n            \n            # Show augmentation info if available\n            if 'augmentation_info' in result and result['augmentation_info']:\n                aug_info = result['augmentation_info']\n                print(f\"\\nAugmentation Summary:\")\n                print(f\"  Original samples: {aug_info.get('original_count', 0)}\")\n                print(f\"  Augmented samples: {aug_info.get('augmented_count', 0)}\")\n                print(f\"  Total dataset size: {aug_info.get('original_count', 0) + aug_info.get('augmented_count', 0)}\")\n            \n            print(f\"\\nTotal processing time: {result['elapsed_time']:.2f} seconds\")\n        else:\n            # First run a test on a small subset of the dataset\n            logger.info(\"Running test mapping on small subset...\")\n            \n            # Run test mapping on small subset\n            test_pattern_map = map_dataset(\n                dataset_path=args.dataset,\n                output_path=None,  # Don't save test map\n                force_type=dataset_type,\n                test_mode=True,\n                model_type=args.model\n            )\n            \n            # Validate test results\n            if not validate_pattern_map(test_pattern_map):\n                logger.error(\"Test mapping failed validation - please check dataset\")\n                return 1\n            \n            # Show test results\n            logger.info(\"Test mapping successful!\")\n            logger.info(\"Test pattern distribution:\")\n            for pattern_type, count in test_pattern_map[\"pattern_distribution\"].items():\n                logger.info(f\"  {pattern_type}: {count}\")\n            \n            # Ask user to proceed if interactive\n            if sys.stdout.isatty():\n                try:\n                    response = input(f\"\\nProceed with full dataset mapping? [Y/n]: \")\n                    if response.lower() == 'n':\n                        logger.info(\"Mapping cancelled by user.\")\n                        return 0\n                except (KeyboardInterrupt, EOFError):\n                    print(\"\\nOperation cancelled by user.\")\n                    return 0\n            \n            # Now run the full mapping\n            logger.info(\"Processing full dataset...\")\n            pattern_map = map_dataset(\n                dataset_path=args.dataset,\n                output_path=args.output,\n                force_type=dataset_type,\n                test_mode=False,\n                model_type=args.model\n            )\n            \n            # Log success\n            logger.info(\"Pattern mapping completed successfully\")\n            \n            # Print summary\n            pattern_distribution = pattern_map.get('pattern_distribution', {})\n            print(\"\\nPattern Distribution Summary:\")\n            for pattern_type, count in pattern_distribution.items():\n                print(f\"  {pattern_type}: {count} instances\")\n                \n            output_path = args.output if args.output else pattern_map.get(\"output_path\", \"unknown\")\n            print(f\"\\nPattern map saved to: {output_path}\")\n        \n        # Return success code\n        return 0\n            \n    except KeyboardInterrupt:\n        logger.info(\"\\nProcess interrupted by user. Shutting down gracefully...\")\n        print(\"\\nProcess interrupted. Exiting...\")\n        return 0\n    except Exception as e:\n        logger.error(f\"Error in pattern mapping: {str(e)}\")\n        import traceback\n        logger.error(traceback.format_exc())\n        print(f\"\\nError: {str(e)}\")\n        print(\"For detailed error information, check the log.\")\n        print(\"\\nExiting due to error...\")\n        return 1\n\n\ndef run_with_multiprocessing_support():\n    \"\"\"Run the main function with proper multiprocessing support.\"\"\""
    },
    "run_with_multiprocessing_support": {
      "start_line": 1739,
      "end_line": 1747,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "multiprocessing.freeze_support",
          "line": 1743
        },
        {
          "name": "main",
          "line": 1744
        }
      ],
      "docstring": "Run the main function with proper multiprocessing support.",
      "code_snippet": "\n\ndef run_with_multiprocessing_support():\n    \"\"\"Run the main function with proper multiprocessing support.\"\"\"\n    import sys\n    import multiprocessing\n    multiprocessing.freeze_support()  # Required for Windows multiprocessing\n    exit_code = main()\n    return exit_code\n\nif __name__ == \"__main__\":\n    # When run as a script directly\n    exit_code = run_with_multiprocessing_support()"
    }
  },
  "constants": {}
}