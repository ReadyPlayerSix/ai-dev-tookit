{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\semantic\\data_loading.py",
  "imports": [
    {
      "name": "os",
      "line": 5
    },
    {
      "name": "pickle",
      "line": 6
    },
    {
      "name": "logging",
      "line": 7
    },
    {
      "name": "compatibility.load_with_class_fixup",
      "line": 8
    }
  ],
  "classes": {},
  "functions": {
    "load_latest_augmented_dataset": {
      "start_line": 12,
      "end_line": 75,
      "parameters": [
        {
          "name": "dataset_name"
        },
        {
          "name": "factor"
        },
        {
          "name": "threshold"
        },
        {
          "name": "base_dir"
        }
      ],
      "return_type": null,
      "calls": [
        {
          "name": "load_with_class_fixup",
          "line": 63
        },
        {
          "name": "os.path.join",
          "line": 29
        },
        {
          "name": "os.path.exists",
          "line": 31
        },
        {
          "name": "os.path.join",
          "line": 48
        },
        {
          "name": "logger.info",
          "line": 55
        },
        {
          "name": "os.path.exists",
          "line": 58
        },
        {
          "name": "logger.warning",
          "line": 59
        },
        {
          "name": "hasattr",
          "line": 66
        },
        {
          "name": "logger.info",
          "line": 68
        },
        {
          "name": "logger.info",
          "line": 69
        },
        {
          "name": "logger.info",
          "line": 34
        },
        {
          "name": "logger.info",
          "line": 35
        },
        {
          "name": "os.path.join",
          "line": 38
        },
        {
          "name": "os.path.exists",
          "line": 49
        },
        {
          "name": "logger.warning",
          "line": 50
        },
        {
          "name": "open",
          "line": 53
        },
        {
          "name": "....strip",
          "line": 54
        },
        {
          "name": "open",
          "line": 32
        },
        {
          "name": "....strip",
          "line": 33
        },
        {
          "name": "os.path.exists",
          "line": 39
        },
        {
          "name": "os.path.islink",
          "line": 39
        },
        {
          "name": "os.readlink",
          "line": 40
        },
        {
          "name": "logger.info",
          "line": 41
        },
        {
          "name": "logger.info",
          "line": 42
        },
        {
          "name": "logger.warning",
          "line": 44
        },
        {
          "name": "f.read",
          "line": 54
        },
        {
          "name": "stats.get",
          "line": 68
        },
        {
          "name": "stats.get",
          "line": 69
        },
        {
          "name": "stats.get",
          "line": 70
        },
        {
          "name": "stats.get",
          "line": 71
        },
        {
          "name": "f.read",
          "line": 33
        }
      ],
      "docstring": "\n    Load the latest augmented dataset.\n    \n    Args:\n        dataset_name: Name of the dataset (e.g., \"cifar10\")\n        factor: Specific augmentation factor to load, if None, loads the latest dataset\n        threshold: Specific difficulty threshold to load, if None, loads the latest dataset\n        base_dir: Base directory where augmented datasets are stored\n        \n    Returns:\n        The augmented dataset or None if not found\n    ",
      "code_snippet": "logger = logging.getLogger(__name__)\n\ndef load_latest_augmented_dataset(dataset_name=\"cifar10\", factor=None, threshold=None, base_dir=\"data/augmented\"):\n    \"\"\"\n    Load the latest augmented dataset.\n    \n    Args:\n        dataset_name: Name of the dataset (e.g., \"cifar10\")\n        factor: Specific augmentation factor to load, if None, loads the latest dataset\n        threshold: Specific difficulty threshold to load, if None, loads the latest dataset\n        base_dir: Base directory where augmented datasets are stored\n        \n    Returns:\n        The augmented dataset or None if not found\n    \"\"\"\n    # Create full path pattern\n    if factor is not None and threshold is not None:\n        # Load the latest dataset with specific parameters\n        path_pattern = f\"{dataset_name}_f{factor}_t{threshold}_latest.pkl\"\n        ref_path = os.path.join(base_dir, path_pattern + '.txt')\n        \n        if os.path.exists(ref_path):\n            with open(ref_path, 'r') as f:\n                dataset_path = f.read().strip()\n            logger.info(f\"Loading augmented dataset with factor={factor}, threshold={threshold}\")\n            logger.info(f\"Dataset path: {dataset_path}\")\n        else:\n            # Check if there's a symlink version (for Unix systems)\n            symlink_path = os.path.join(base_dir, path_pattern)\n            if os.path.exists(symlink_path) and os.path.islink(symlink_path):\n                dataset_path = os.readlink(symlink_path)\n                logger.info(f\"Loading augmented dataset with factor={factor}, threshold={threshold}\")\n                logger.info(f\"Dataset path: {dataset_path}\")\n            else:\n                logger.warning(f\"No augmented dataset found with factor={factor}, threshold={threshold}\")\n                return None\n    else:\n        # Load the latest dataset overall\n        latest_path_file = os.path.join(base_dir, \"latest_augmented_path.txt\")\n        if not os.path.exists(latest_path_file):\n            logger.warning(f\"Latest augmented dataset path file not found: {latest_path_file}\")\n            return None\n            \n        with open(latest_path_file, 'r') as f:\n            dataset_path = f.read().strip()\n        logger.info(f\"Loading latest augmented dataset: {dataset_path}\")\n    \n    # Make sure the dataset file exists\n    if not os.path.exists(dataset_path):\n        logger.warning(f\"Augmented dataset file not found: {dataset_path}\")\n        return None\n    \n    # Load the dataset with compatibility support\n    augmented_dataset = load_with_class_fixup(dataset_path)\n    \n    # Log some info about the loaded dataset\n    if augmented_dataset and hasattr(augmented_dataset, 'augmentation_stats'):\n        stats = augmented_dataset.augmentation_stats\n        logger.info(f\"Loaded augmented dataset with {stats.get('augmented_size', 'unknown')} examples\")\n        logger.info(f\"Original size: {stats.get('original_size', 'unknown')}, \"\n                 f\"Factor: {stats.get('augmentation_factor', 'unknown')}, \"\n                 f\"Threshold: {stats.get('difficulty_threshold', 'unknown')}\")\n    \n    return augmented_dataset\n\ndef load_augmented_dataset(path=None, dataset_name=\"cifar10\", factor=None, threshold=None, base_dir=\"data/augmented\"):\n    \"\"\"\n    Load an augmented dataset either by specific path or by parameters."
    },
    "load_augmented_dataset": {
      "start_line": 75,
      "end_line": 111,
      "parameters": [
        {
          "name": "path"
        },
        {
          "name": "dataset_name"
        },
        {
          "name": "factor"
        },
        {
          "name": "threshold"
        },
        {
          "name": "base_dir"
        }
      ],
      "return_type": null,
      "calls": [
        {
          "name": "load_with_class_fixup",
          "line": 96
        },
        {
          "name": "load_latest_augmented_dataset",
          "line": 109
        },
        {
          "name": "os.path.exists",
          "line": 91
        },
        {
          "name": "logger.warning",
          "line": 92
        },
        {
          "name": "hasattr",
          "line": 99
        },
        {
          "name": "logger.info",
          "line": 101
        },
        {
          "name": "logger.info",
          "line": 102
        },
        {
          "name": "stats.get",
          "line": 101
        },
        {
          "name": "stats.get",
          "line": 102
        },
        {
          "name": "stats.get",
          "line": 103
        },
        {
          "name": "stats.get",
          "line": 104
        }
      ],
      "docstring": "\n    Load an augmented dataset either by specific path or by parameters.\n    \n    Args:\n        path: Direct path to the dataset file, if provided other params are ignored\n        dataset_name: Name of the dataset (e.g., \"cifar10\")\n        factor: Specific augmentation factor to load\n        threshold: Specific difficulty threshold to load\n        base_dir: Base directory where augmented datasets are stored\n        \n    Returns:\n        The augmented dataset or None if not found\n    ",
      "code_snippet": "    return augmented_dataset\n\ndef load_augmented_dataset(path=None, dataset_name=\"cifar10\", factor=None, threshold=None, base_dir=\"data/augmented\"):\n    \"\"\"\n    Load an augmented dataset either by specific path or by parameters.\n    \n    Args:\n        path: Direct path to the dataset file, if provided other params are ignored\n        dataset_name: Name of the dataset (e.g., \"cifar10\")\n        factor: Specific augmentation factor to load\n        threshold: Specific difficulty threshold to load\n        base_dir: Base directory where augmented datasets are stored\n        \n    Returns:\n        The augmented dataset or None if not found\n    \"\"\"\n    if path:\n        # Load directly from the specified path\n        if not os.path.exists(path):\n            logger.warning(f\"Augmented dataset file not found: {path}\")\n            return None\n            \n        # Use compatibility module for loading\n        augmented_dataset = load_with_class_fixup(path)\n        \n        # Log some info about the loaded dataset\n        if augmented_dataset and hasattr(augmented_dataset, 'augmentation_stats'):\n            stats = augmented_dataset.augmentation_stats\n            logger.info(f\"Loaded augmented dataset with {stats.get('augmented_size', 'unknown')} examples\")\n            logger.info(f\"Original size: {stats.get('original_size', 'unknown')}, \"\n                     f\"Factor: {stats.get('augmentation_factor', 'unknown')}, \"\n                     f\"Threshold: {stats.get('difficulty_threshold', 'unknown')}\")\n        \n        return augmented_dataset\n    else:\n        # Use the latest dataset loading function\n        return load_latest_augmented_dataset(dataset_name, factor, threshold, base_dir)"
    }
  },
  "constants": {}
}