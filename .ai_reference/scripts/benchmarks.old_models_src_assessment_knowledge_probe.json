{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\benchmarks.old\\models\\src\\assessment\\knowledge_probe.py",
  "imports": [
    {
      "name": "datetime.datetime",
      "line": 4
    },
    {
      "name": "cortex.coordinator.CortexCoordinator",
      "line": 5
    },
    {
      "name": "cortex.coordinator.ProcessingConfig",
      "line": 5
    },
    {
      "name": "typing.Dict",
      "line": 6
    },
    {
      "name": "typing.List",
      "line": 6
    },
    {
      "name": "typing.Any",
      "line": 6
    },
    {
      "name": "datetime.datetime",
      "line": 7
    },
    {
      "name": "numpy",
      "line": 8
    }
  ],
  "classes": {
    "KnowledgeProbe": {
      "start_line": 10,
      "end_line": 17,
      "methods": {
        "__init__": {
          "start_line": 13,
          "end_line": 17,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "coordinator"
            }
          ],
          "return_type": null,
          "calls": [],
          "code_snippet": "    \"\"\"Tool for probing current knowledge state of the Neural Network Cortex System\"\"\"\n    \n    def __init__(self, coordinator):\n        self.coordinator = coordinator\n        self.semantic_registry = coordinator.semantic_registry\n\ndef run_knowledge_probe():\n    # Initialize your coordinator\n    config = ProcessingConfig("
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "Tool for probing current knowledge state of the Neural Network Cortex System"
    }
  },
  "functions": {
    "run_knowledge_probe": {
      "start_line": 17,
      "end_line": 84,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "ProcessingConfig",
          "line": 19
        },
        {
          "name": "CortexCoordinator",
          "line": 25
        },
        {
          "name": "KnowledgeProbe",
          "line": 28
        },
        {
          "name": "probe.generate_knowledge_report",
          "line": 58
        },
        {
          "name": "print",
          "line": 61
        },
        {
          "name": "print",
          "line": 62
        },
        {
          "name": "print",
          "line": 63
        },
        {
          "name": "....items",
          "line": 64
        },
        {
          "name": "print",
          "line": 67
        },
        {
          "name": "....items",
          "line": 68
        },
        {
          "name": "print",
          "line": 71
        },
        {
          "name": "print",
          "line": 73
        },
        {
          "name": "print",
          "line": 74
        },
        {
          "name": "print",
          "line": 75
        },
        {
          "name": "print",
          "line": 77
        },
        {
          "name": "print",
          "line": 79
        },
        {
          "name": "print",
          "line": 80
        },
        {
          "name": "coordinator.process_input",
          "line": 55
        },
        {
          "name": "print",
          "line": 65
        },
        {
          "name": "print",
          "line": 69
        }
      ],
      "code_snippet": "        self.semantic_registry = coordinator.semantic_registry\n\ndef run_knowledge_probe():\n    # Initialize your coordinator\n    config = ProcessingConfig(\n        use_semantic_core=True,\n        enable_rpg=True,\n        batch_processing=True,\n        track_metrics=True\n    )\n    coordinator = CortexCoordinator(config)\n    \n    # Initialize the probe\n    probe = KnowledgeProbe(coordinator)\n    \n    # First, let's feed some test patterns\n    test_inputs = [\n        # Visual input\n        {\n            \"domain\": \"visual\",\n            \"data\": {\n                \"bbox\": [10, 20, 100, 200],\n                \"confidence\": 0.85,\n                \"width\": 640,\n                \"height\": 480\n            }\n        },\n        # Text input\n        {\n            \"domain\": \"linguistic\",\n            \"data\": {\n                \"sentence_data\": \"The quick brown fox jumps over the lazy dog\",\n                \"grammar_score\": 0.95,\n                \"confidence\": 0.88\n            }\n        }\n    ]\n    \n    # Process test inputs\n    for input_data in test_inputs:\n        coordinator.process_input(input_data[\"domain\"], input_data[\"data\"])\n    \n    # Now let's probe the system's knowledge\n    report = probe.generate_knowledge_report()\n    \n    # Print key findings\n    print(\"\\n=== Knowledge State Report ===\")\n    print(f\"Timestamp: {report['timestamp']}\")\n    print(\"\\nDomain Distribution:\")\n    for domain, count in report['domain_distribution'].items():\n        print(f\"  {domain}: {count} patterns\")\n    \n    print(\"\\nComplexity Stats:\")\n    for metric, value in report['complexity_stats'].items():\n        print(f\"  {metric}: {value:.2f}\")\n    \n    print(\"\\nPattern Preservation:\")\n    preservation = report['pattern_preservation']\n    print(f\"  Average Preservation: {preservation['avg_preservation']:.2%}\")\n    print(f\"  High Confidence Patterns: {preservation['high_confidence_patterns']}\")\n    print(f\"  Total Patterns: {preservation['total_patterns']}\")\n    \n    print(\"\\nRisk Awareness:\")\n    risk = report['risk_awareness']\n    print(f\"  Risk Queue Size: {risk['risk_queue_size']}\")\n    print(f\"  Risk Patterns Processed: {risk['risk_patterns_processed']}\")\n    \n    return report\n\nif __name__ == \"__main__\":\n    report = run_knowledge_probe()"
    }
  },
  "constants": {}
}