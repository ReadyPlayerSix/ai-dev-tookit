{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\utils\\training_utils\\worker_calculation.py",
  "imports": [
    {
      "name": "logging",
      "line": 11
    },
    {
      "name": "math",
      "line": 12
    },
    {
      "name": "torch",
      "line": 13
    },
    {
      "name": "multiprocessing",
      "line": 36
    },
    {
      "name": "psutil",
      "line": 37
    }
  ],
  "classes": {},
  "functions": {
    "calculate_optimal_workers": {
      "start_line": 18,
      "end_line": 76,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "multiprocessing.cpu_count",
          "line": 40
        },
        {
          "name": "math.ceil",
          "line": 53
        },
        {
          "name": "torch.cuda.is_available",
          "line": 56
        },
        {
          "name": "min",
          "line": 65
        },
        {
          "name": "max",
          "line": 66
        },
        {
          "name": "logger.info",
          "line": 68
        },
        {
          "name": "psutil.cpu_percent",
          "line": 43
        },
        {
          "name": "torch.cuda.device_count",
          "line": 58
        },
        {
          "name": "min",
          "line": 59
        },
        {
          "name": "max",
          "line": 65
        },
        {
          "name": "min",
          "line": 66
        },
        {
          "name": "....format",
          "line": 68
        },
        {
          "name": "logger.warning",
          "line": 73
        },
        {
          "name": "psutil.virtual_memory",
          "line": 46
        },
        {
          "name": "max",
          "line": 59
        },
        {
          "name": "....format",
          "line": 73
        },
        {
          "name": "str",
          "line": 73
        }
      ],
      "docstring": "\n    Calculate the optimal number of workers based on system capabilities.\n    \n    Following isekaiZen mathematical foundation, this function integrates\n    cognitive efficiency principles to determine the optimal number of\n    DataLoader workers that balances performance and stability.\n    \n    The function considers:\n    - Number of available CPU cores\n    - Current system load\n    - Memory usage\n    - GPU availability\n    \n    Returns:\n        int: Optimal number of workers\n    ",
      "code_snippet": "logger = logging.getLogger(__name__)\n\ndef calculate_optimal_workers():\n    \"\"\"\n    Calculate the optimal number of workers based on system capabilities.\n    \n    Following isekaiZen mathematical foundation, this function integrates\n    cognitive efficiency principles to determine the optimal number of\n    DataLoader workers that balances performance and stability.\n    \n    The function considers:\n    - Number of available CPU cores\n    - Current system load\n    - Memory usage\n    - GPU availability\n    \n    Returns:\n        int: Optimal number of workers\n    \"\"\"\n    try:\n        import multiprocessing\n        import psutil\n        \n        # Get number of CPU cores\n        cpu_count = multiprocessing.cpu_count()\n        \n        # Get current system load\n        system_load = psutil.cpu_percent(interval=0.1) / 100.0\n        \n        # Get memory usage as a factor\n        memory_usage = psutil.virtual_memory().percent / 100.0\n        \n        # Calculate resource factor using polynomial function\n        # This follows the cognitive efficiency function patterns from the isekaiZen mathematical foundation\n        resource_factor = (1 - system_load) * (1 - 0.8 * memory_usage)\n        \n        # Calculate base workers using the parallel processing penalty formula pattern\n        base_workers = math.ceil(cpu_count * resource_factor)\n        \n        # Add GPU factor if available\n        if torch.cuda.is_available():\n            # When using GPU, we need fewer workers to avoid bottlenecks\n            gpu_count = torch.cuda.device_count()\n            workers = min(base_workers, max(1, 2 * gpu_count))\n        else:\n            # For CPU-only, use calculated base workers\n            workers = base_workers\n        \n        # Apply bounds based on system capabilities\n        workers = min(workers, max(1, cpu_count - 1))  # Leave at least one core free\n        workers = max(1, min(workers, 4))  # Cap at 4 workers for stability\n        \n        logger.info(\"Calculated optimal DataLoader workers: {} (from {} cores, load: {:.2f})\".format(\n            workers, cpu_count, system_load))\n        return workers\n        \n    except Exception as e:\n        logger.warning(\"Error calculating optimal workers: {}. Using 0 workers for safety.\".format(str(e)))\n        return 0  # Safe fallback"
    }
  },
  "constants": {}
}