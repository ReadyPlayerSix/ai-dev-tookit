{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\hardware\\analyzer.py",
  "imports": [
    {
      "name": "torch",
      "line": 5
    },
    {
      "name": "logging",
      "line": 6
    },
    {
      "name": "gc",
      "line": 7
    },
    {
      "name": "typing.Dict",
      "line": 8
    },
    {
      "name": "typing.Any",
      "line": 8
    },
    {
      "name": "typing.Optional",
      "line": 8
    },
    {
      "name": "torch.distributed.ReduceOp",
      "line": 13
    },
    {
      "name": "psutil",
      "line": 120
    },
    {
      "name": "platform",
      "line": 204
    },
    {
      "name": "multiprocessing",
      "line": 205
    }
  ],
  "classes": {
    "HardwareAnalyzer": {
      "start_line": 17,
      "end_line": 221,
      "methods": {
        "__init__": {
          "start_line": 25,
          "end_line": 48,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "device"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "torch.cuda.is_available",
              "line": 33
            },
            {
              "name": "logger.info",
              "line": 34
            },
            {
              "name": "logger.info",
              "line": 46
            },
            {
              "name": "torch.cuda.device_count",
              "line": 38
            },
            {
              "name": "logger.info",
              "line": 39
            },
            {
              "name": "range",
              "line": 40
            },
            {
              "name": "torch.device",
              "line": 44
            },
            {
              "name": "torch.cuda.get_device_properties",
              "line": 41
            },
            {
              "name": "logger.info",
              "line": 42
            }
          ],
          "docstring": "\n        Initialize with specified device or auto-detect.\n        \n        Args:\n            device: Target device to analyze (default: auto-detect CUDA if available, else CPU)\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(self, device: Optional[torch.device] = None):\n        \"\"\"\n        Initialize with specified device or auto-detect.\n        \n        Args:\n            device: Target device to analyze (default: auto-detect CUDA if available, else CPU)\n        \"\"\"\n        # Force CUDA detection before device creation\n        cuda_available = torch.cuda.is_available()\n        logger.info(f\"CUDA available: {cuda_available}\")\n        \n        if cuda_available:\n            # Log CUDA devices for diagnostics\n            device_count = torch.cuda.device_count()\n            logger.info(f\"Found {device_count} CUDA device(s)\")\n            for i in range(device_count):\n                props = torch.cuda.get_device_properties(i)\n                logger.info(f\"  Device {i}: {props.name}, {props.total_memory/1e9:.1f} GB memory\")\n        \n        self.device = device or torch.device('cuda' if cuda_available else 'cpu')\n        self.is_gpu = self.device.type == 'cuda'\n        logger.info(f\"Hardware analyzer initialized for device: {self.device}\")\n        \n    def cleanup_memory(self):\n        \"\"\"Memory cleanup without excessive overhead.\"\"\"\n        if not self.is_gpu:"
        },
        "cleanup_memory": {
          "start_line": 48,
          "end_line": 92,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.get_memory_stats",
              "line": 54
            },
            {
              "name": "torch.cuda.empty_cache",
              "line": 57
            },
            {
              "name": "torch.cuda.reset_peak_memory_stats",
              "line": 58
            },
            {
              "name": "gc.collect",
              "line": 71
            },
            {
              "name": "torch.cuda.empty_cache",
              "line": 72
            },
            {
              "name": "self.get_memory_stats",
              "line": 75
            },
            {
              "name": "self.get_memory_stats",
              "line": 81
            },
            {
              "name": "logger.info",
              "line": 84
            },
            {
              "name": "logger.info",
              "line": 85
            },
            {
              "name": "logger.info",
              "line": 86
            },
            {
              "name": "logger.info",
              "line": 87
            },
            {
              "name": "logger.info",
              "line": 88
            },
            {
              "name": "self.get_memory_stats",
              "line": 51
            },
            {
              "name": "gc.get_objects",
              "line": 62
            },
            {
              "name": "logger.warning",
              "line": 77
            },
            {
              "name": "torch.cuda.empty_cache",
              "line": 78
            },
            {
              "name": "gc.collect",
              "line": 79
            },
            {
              "name": "isinstance",
              "line": 64
            },
            {
              "name": "hasattr",
              "line": 65
            },
            {
              "name": "obj.zero_grad",
              "line": 66
            }
          ],
          "docstring": "Memory cleanup without excessive overhead.",
          "code_snippet": "        logger.info(f\"Hardware analyzer initialized for device: {self.device}\")\n        \n    def cleanup_memory(self):\n        \"\"\"Memory cleanup without excessive overhead.\"\"\"\n        if not self.is_gpu:\n            return self.get_memory_stats()\n            \n        # Get initial stats\n        initial_stats = self.get_memory_stats()\n        \n        # Basic cleanup\n        torch.cuda.empty_cache()\n        torch.cuda.reset_peak_memory_stats(self.device)\n        \n        # Clear model gradients only if we have high allocated memory\n        if initial_stats['allocated'] > initial_stats['total'] * 0.5:  # Over 50% allocated\n            for obj in gc.get_objects():\n                try:\n                    if isinstance(obj, torch.nn.Module):\n                        if hasattr(obj, 'zero_grad'):\n                            obj.zero_grad(set_to_none=True)\n                except Exception:\n                    continue\n        \n        # Single thorough cleanup\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        # Check if we need emergency cleanup\n        stats = self.get_memory_stats()\n        if stats['reserved'] > stats['total']:\n            logger.warning(\"Memory state requires cleanup - performing minimal reset\")\n            torch.cuda.empty_cache()\n            gc.collect()\n        \n        final_stats = self.get_memory_stats()\n        \n        # Log memory state after cleanup\n        logger.info(f\"Memory cleaned. Stats (GB):\")\n        logger.info(f\"  Total: {final_stats['total']/1e9:.2f}\")\n        logger.info(f\"  Reserved: {final_stats['reserved']/1e9:.2f}\")\n        logger.info(f\"  Allocated: {final_stats['allocated']/1e9:.2f}\")\n        logger.info(f\"  Free: {final_stats['free']/1e9:.2f}\")\n        \n        return final_stats\n\n    def get_memory_stats(self) -> Dict[str, int]:\n        \"\"\"Get current memory statistics.\"\"\"\n        if not self.is_gpu:"
        },
        "get_memory_stats": {
          "start_line": 92,
          "end_line": 116,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "torch.cuda.memory_reserved",
              "line": 103
            },
            {
              "name": "torch.cuda.memory_allocated",
              "line": 104
            },
            {
              "name": "torch.cuda.get_device_properties",
              "line": 102
            }
          ],
          "docstring": "Get current memory statistics.",
          "code_snippet": "        return final_stats\n\n    def get_memory_stats(self) -> Dict[str, int]:\n        \"\"\"Get current memory statistics.\"\"\"\n        if not self.is_gpu:\n            return {\n                'total': 0,\n                'reserved': 0,\n                'allocated': 0,\n                'free': 0\n            }\n            \n        total = torch.cuda.get_device_properties(self.device).total_memory\n        reserved = torch.cuda.memory_reserved(self.device)\n        allocated = torch.cuda.memory_allocated(self.device)\n        free = reserved - allocated  # Free memory in the current reservation\n        \n        if total > reserved:\n            free += (total - reserved)  # Add unreserved memory\n            \n        return {\n            'total': total,\n            'reserved': reserved,\n            'allocated': allocated,\n            'free': free\n        }\n\n    def _analyze_cpu_memory(self) -> Dict[str, int]:\n        \"\"\"Analyze CPU memory.\"\"\""
        },
        "_analyze_cpu_memory": {
          "start_line": 117,
          "end_line": 137,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "psutil.virtual_memory",
              "line": 121
            }
          ],
          "docstring": "Analyze CPU memory.",
          "code_snippet": "        }\n\n    def _analyze_cpu_memory(self) -> Dict[str, int]:\n        \"\"\"Analyze CPU memory.\"\"\"\n        try:\n            import psutil\n            vm = psutil.virtual_memory()\n            return {\n                'total_memory': vm.total,\n                'free_memory': vm.available,\n                'reserved_memory': 0,\n                'allocated_memory': vm.used\n            }\n        except ImportError:\n            # Conservative default if psutil not available\n            default_total = 8 * (1024**3)  # 8GB\n            return {\n                'total_memory': default_total,\n                'free_memory': default_total // 2,\n                'reserved_memory': 0,\n                'allocated_memory': default_total // 2\n            }\n\n    def analyze_memory(self) -> Dict[str, int]:\n        \"\"\""
        },
        "analyze_memory": {
          "start_line": 138,
          "end_line": 166,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "self.cleanup_memory",
              "line": 149
            },
            {
              "name": "int",
              "line": 155
            },
            {
              "name": "self._analyze_cpu_memory",
              "line": 146
            },
            {
              "name": "logger.warning",
              "line": 157
            }
          ],
          "docstring": "\n        Get available memory for training.\n        \n        Returns:\n            Dictionary with memory information in bytes\n        ",
          "code_snippet": "            }\n\n    def analyze_memory(self) -> Dict[str, int]:\n        \"\"\"\n        Get available memory for training.\n        \n        Returns:\n            Dictionary with memory information in bytes\n        \"\"\"\n        if not self.is_gpu:\n            return self._analyze_cpu_memory()\n            \n        # Clean up first\n        stats = self.cleanup_memory()\n        \n        # Calculate safe free memory\n        safe_free = stats['free']\n        \n        # Ensure minimum free memory (5% of total)\n        min_free = int(stats['total'] * 0.05)\n        if safe_free < min_free:\n            logger.warning(f\"Low memory condition. Free: {safe_free/(1024**3):.2f}GB\")\n            safe_free = min_free\n            \n        return {\n            'total_memory': stats['total'],\n            'free_memory': safe_free,\n            'reserved_memory': stats['reserved'],\n            'allocated_memory': stats['allocated']\n        }\n    \n    def get_memory_safety_factor(self) -> float:\n        \"\"\""
        },
        "get_memory_safety_factor": {
          "start_line": 167,
          "end_line": 181,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "float",
          "calls": [],
          "docstring": "\n        Get safety factor based on device type and system load.\n        \n        Returns:\n            Safety factor as a float between 0 and 1\n        ",
          "code_snippet": "        }\n    \n    def get_memory_safety_factor(self) -> float:\n        \"\"\"\n        Get safety factor based on device type and system load.\n        \n        Returns:\n            Safety factor as a float between 0 and 1\n        \"\"\"\n        if self.is_gpu:\n            # GPU memory is more constrained, but we can still use most of it\n            return 0.92  # Use 92% of available memory at most\n        else:\n            # CPU can use more of available memory\n            return 0.85  # Use 85% of available memory at most\n            \n    def get_compute_capabilities(self) -> Dict[str, Any]:\n        \"\"\"\n        Get compute capabilities of the current device."
        },
        "get_compute_capabilities": {
          "start_line": 181,
          "end_line": 221,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "torch.cuda.get_device_properties",
              "line": 192
            },
            {
              "name": "capabilities.update",
              "line": 193
            },
            {
              "name": "logger.debug",
              "line": 200
            },
            {
              "name": "capabilities.update",
              "line": 206
            },
            {
              "name": "logger.debug",
              "line": 211
            },
            {
              "name": "capabilities.update",
              "line": 214
            },
            {
              "name": "platform.processor",
              "line": 207
            },
            {
              "name": "multiprocessing.cpu_count",
              "line": 208
            },
            {
              "name": "platform.platform",
              "line": 209
            }
          ],
          "docstring": "\n        Get compute capabilities of the current device.\n        \n        Returns:\n            Dictionary with compute capability information\n        ",
          "code_snippet": "            return 0.85  # Use 85% of available memory at most\n            \n    def get_compute_capabilities(self) -> Dict[str, Any]:\n        \"\"\"\n        Get compute capabilities of the current device.\n        \n        Returns:\n            Dictionary with compute capability information\n        \"\"\"\n        capabilities = {'device_type': self.device.type}\n        \n        if self.is_gpu:\n            # Get GPU compute capabilities\n            properties = torch.cuda.get_device_properties(self.device)\n            capabilities.update({\n                'name': properties.name,\n                'compute_capability': f\"{properties.major}.{properties.minor}\",\n                'multi_processor_count': properties.multi_processor_count,\n                'total_memory': properties.total_memory,\n                'is_integrated': properties.is_integrated\n            })\n            logger.debug(f\"GPU capabilities: {properties.name}, Compute: {properties.major}.{properties.minor}\")\n        else:\n            # Get CPU information\n            try:\n                import platform\n                import multiprocessing\n                capabilities.update({\n                    'name': platform.processor(),\n                    'cores': multiprocessing.cpu_count(),\n                    'platform': platform.platform()\n                })\n                logger.debug(f\"CPU capabilities: {capabilities['cores']} cores, {capabilities['name']}\")\n            except ImportError:\n                # Basic fallback\n                capabilities.update({\n                    'name': 'Unknown CPU',\n                    'cores': 1\n                })\n                \n        return capabilities"
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "\n    Analyzes hardware capabilities to determine memory constraints and other hardware properties.\n    \n    This class is used by optimizers to obtain consistent hardware information for \n    automatic batch size boundary detection.\n    "
    }
  },
  "functions": {},
  "constants": {}
}