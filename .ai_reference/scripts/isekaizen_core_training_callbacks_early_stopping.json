{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\core\\training\\callbacks\\early_stopping.py",
  "imports": [
    {
      "name": "logging",
      "line": 11
    },
    {
      "name": "numpy",
      "line": 12
    },
    {
      "name": "typing.Dict",
      "line": 13
    },
    {
      "name": "typing.Any",
      "line": 13
    },
    {
      "name": "typing.List",
      "line": 13
    },
    {
      "name": "typing.Optional",
      "line": 13
    }
  ],
  "classes": {
    "EarlyStoppingCallback": {
      "start_line": 17,
      "end_line": 113,
      "methods": {
        "__init__": {
          "start_line": 32,
          "end_line": 63,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "monitor",
              "type": "str"
            },
            {
              "name": "min_delta",
              "type": "float"
            },
            {
              "name": "patience",
              "type": "int"
            },
            {
              "name": "mode",
              "type": "str"
            },
            {
              "name": "verbose",
              "type": "bool"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logger.debug",
              "line": 61
            }
          ],
          "docstring": "\n        Initialize the early stopping callback.\n        \n        Args:\n            monitor: Metric to monitor ('val_loss' or 'val_acc')\n            min_delta: Minimum change to qualify as improvement\n            patience: Number of epochs with no improvement to stop\n            mode: 'min' for metrics like loss, 'max' for metrics like accuracy\n            verbose: Whether to log messages when stopping\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(\n        self,\n        monitor: str = 'val_loss',\n        min_delta: float = 0.001,\n        patience: int = 5,\n        mode: str = 'min',\n        verbose: bool = True\n    ):\n        \"\"\"\n        Initialize the early stopping callback.\n        \n        Args:\n            monitor: Metric to monitor ('val_loss' or 'val_acc')\n            min_delta: Minimum change to qualify as improvement\n            patience: Number of epochs with no improvement to stop\n            mode: 'min' for metrics like loss, 'max' for metrics like accuracy\n            verbose: Whether to log messages when stopping\n        \"\"\"\n        self.monitor = monitor\n        self.min_delta = min_delta\n        self.patience = patience\n        self.mode = mode\n        self.verbose = verbose\n        \n        # Set initial best value based on mode\n        self.best_value = np.inf if mode == 'min' else -np.inf\n        self.wait_count = 0\n        self.stopped_epoch = 0\n        \n        logger.debug(f\"EarlyStoppingCallback initialized: monitoring {monitor}, patience={patience}\")\n    \n    def __call__(\n        self, \n        epoch: int, "
        },
        "__call__": {
          "start_line": 63,
          "end_line": 113,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "epoch",
              "type": "int"
            },
            {
              "name": "history"
            },
            {
              "name": "model",
              "type": "Any"
            },
            {
              "name": "optimizer",
              "type": "Any"
            }
          ],
          "return_type": "bool",
          "calls": [
            {
              "name": "logger.info",
              "line": 107
            }
          ],
          "docstring": "\n        Check if training should be stopped based on monitoring criteria.\n        \n        Args:\n            epoch: Current epoch number (0-indexed)\n            history: Training history with metrics\n            model: Current model\n            optimizer: Current optimizer\n            \n        Returns:\n            bool: True if training should stop, False otherwise\n        ",
          "code_snippet": "        logger.debug(f\"EarlyStoppingCallback initialized: monitoring {monitor}, patience={patience}\")\n    \n    def __call__(\n        self, \n        epoch: int, \n        history: Dict[str, List[Any]], \n        model: Any, \n        optimizer: Any\n    ) -> bool:\n        \"\"\"\n        Check if training should be stopped based on monitoring criteria.\n        \n        Args:\n            epoch: Current epoch number (0-indexed)\n            history: Training history with metrics\n            model: Current model\n            optimizer: Current optimizer\n            \n        Returns:\n            bool: True if training should stop, False otherwise\n        \"\"\"\n        # Check if we have the monitored metric\n        if self.monitor not in history or not history[self.monitor]:\n            return False\n        \n        # Get current value\n        current = history[self.monitor][-1]\n        \n        # Check if improved\n        if self.mode == 'min':\n            improved = current < (self.best_value - self.min_delta)\n        else:\n            improved = current > (self.best_value + self.min_delta)\n        \n        if improved:\n            # Reset counter and update best value\n            self.best_value = current\n            self.wait_count = 0\n            return False\n        else:\n            # Increment counter\n            self.wait_count += 1\n            if self.wait_count >= self.patience:\n                # Time to stop\n                self.stopped_epoch = epoch\n                if self.verbose:\n                    logger.info(f\"Early stopping triggered after epoch {epoch+1}: \"\n                              f\"no improvement in {self.monitor} for {self.patience} epochs\")\n                return True\n            \n            return False"
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "\n    Early stopping callback that monitors validation metrics and\n    stops training when performance stops improving.\n    \n    Attributes:\n        monitor: Metric to monitor ('val_loss' or 'val_acc')\n        min_delta: Minimum change to qualify as improvement\n        patience: Number of epochs with no improvement to stop\n        mode: 'min' for metrics like loss, 'max' for metrics like accuracy\n        best_value: Best value of the monitored metric\n        wait_count: Number of epochs with no improvement\n        stopped_epoch: Epoch at which training was stopped\n    "
    }
  },
  "functions": {},
  "constants": {}
}