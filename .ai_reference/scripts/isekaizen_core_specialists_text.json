{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\core\\specialists\\text.py",
  "imports": [
    {
      "name": "dataclasses.dataclass",
      "line": 4
    },
    {
      "name": "typing.Dict",
      "line": 5
    },
    {
      "name": "typing.List",
      "line": 5
    },
    {
      "name": "typing.Any",
      "line": 5
    },
    {
      "name": "typing.Optional",
      "line": 5
    },
    {
      "name": "torch",
      "line": 6
    },
    {
      "name": "numpy",
      "line": 7
    },
    {
      "name": "isekaizen.core.specialists.base.BaseSpecialist",
      "line": 10
    },
    {
      "name": "isekaizen.utils.types.DomainType",
      "line": 11
    },
    {
      "name": "transformers.DistilBertTokenizer",
      "line": 29
    },
    {
      "name": "transformers.DistilBertForSequenceClassification",
      "line": 29
    }
  ],
  "classes": {
    "TextPattern": {
      "start_line": 14,
      "end_line": 21,
      "methods": {},
      "class_variables": [],
      "bases": [],
      "docstring": "Represents a linguistic semantic pattern"
    },
    "TextSpecialist": {
      "start_line": 21,
      "end_line": 206,
      "methods": {
        "__init__": {
          "start_line": 22,
          "end_line": 63,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "resource_manager"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "....__init__",
              "line": 23
            },
            {
              "name": "DistilBertTokenizer.from_pretrained",
              "line": 33
            },
            {
              "name": "....to",
              "line": 34
            },
            {
              "name": "super",
              "line": 23
            },
            {
              "name": "DistilBertForSequenceClassification.from_pretrained",
              "line": 34
            }
          ],
          "code_snippet": "\nclass TextSpecialist(BaseSpecialist):\n    def __init__(self, resource_manager=None):\n        super().__init__(DomainType.LINGUISTIC, resource_manager)\n        self.memory_requirement = 100\n        \n        # Initialize with basic text processing\n        # Try to import transformers for advanced processing\n        try:\n            from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n            \n            # Initialize DistilBERT\n            self.model_name = \"distilbert-base-uncased\"\n            self.tokenizer = DistilBertTokenizer.from_pretrained(self.model_name)\n            self.model = DistilBertForSequenceClassification.from_pretrained(\n                self.model_name\n            ).to(self.device)\n            \n            self.has_transformers = True\n            self.transformers_initialized = True\n            \n        except (ImportError, Exception) as e:\n            self.has_transformers = False\n            self.transformers_initialized = False\n            \n        # Initialize patterns\n        self.linguistic_patterns = {\n            \"structural_pattern\": {\n                \"min_complexity_score\": 0.6,\n                \"min_coherence_score\": 0.7\n            },\n            \"syntactic_pattern\": {\n                \"min_structure_score\": 0.6,\n                \"min_grammar_complexity\": 0.5\n            }\n        }\n        \n        # Metrics tracking\n        self.translation_metrics = {\n            \"patterns_identified\": 0,\n            \"high_confidence_patterns\": 0,\n            \"pattern_preservation_score\": 0.0\n        }\n\n    def _calculate_linguistic_metrics(self, text: str) -> Dict[str, float]:\n        \"\"\"Calculate pure linguistic characteristics\"\"\""
        },
        "_calculate_linguistic_metrics": {
          "start_line": 64,
          "end_line": 86,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "text",
              "type": "str"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "text.split",
              "line": 66
            },
            {
              "name": "len",
              "line": 67
            },
            {
              "name": "len",
              "line": 70
            },
            {
              "name": "min",
              "line": 73
            },
            {
              "name": "np.mean",
              "line": 68
            },
            {
              "name": "sum",
              "line": 71
            },
            {
              "name": "max",
              "line": 71
            },
            {
              "name": "len",
              "line": 68
            },
            {
              "name": "len",
              "line": 71
            }
          ],
          "docstring": "Calculate pure linguistic characteristics",
          "code_snippet": "        }\n\n    def _calculate_linguistic_metrics(self, text: str) -> Dict[str, float]:\n        \"\"\"Calculate pure linguistic characteristics\"\"\"\n        words = text.split()\n        word_count = len(words)\n        avg_word_length = np.mean([len(word) for word in words]) if words else 0\n        \n        sentence_length = len(text)\n        word_complexity = sum(1 for word in words if len(word) > 6) / max(1, word_count)\n        \n        structure_score = min(1.0, (word_count * avg_word_length) / 100)\n        \n        return {\n            \"structural_metrics\": {\n                \"word_count\": word_count,\n                \"avg_word_length\": avg_word_length,\n                \"sentence_length\": sentence_length,\n                \"structure_score\": structure_score\n            },\n            \"complexity_metrics\": {\n                \"word_complexity\": word_complexity,\n                \"relative_complexity\": structure_score * word_complexity\n            }\n        }\n\n    def _identify_patterns(self, text: str) -> Optional[TextPattern]:"
        },
        "_identify_patterns": {
          "start_line": 88,
          "end_line": 125,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "text",
              "type": "str"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "self._calculate_linguistic_metrics",
              "line": 90
            },
            {
              "name": "TextPattern",
              "line": 95
            },
            {
              "name": "TextPattern",
              "line": 110
            }
          ],
          "docstring": "Identify pure linguistic patterns",
          "code_snippet": "        }\n\n    def _identify_patterns(self, text: str) -> Optional[TextPattern]:\n        \"\"\"Identify pure linguistic patterns\"\"\"\n        metrics = self._calculate_linguistic_metrics(text)\n        \n        if (metrics['structural_metrics']['structure_score'] >= \n            self.linguistic_patterns[\"structural_pattern\"][\"min_complexity_score\"]):\n            \n            return TextPattern(\n                pattern_type=\"structural_pattern\",\n                linguistic_features={\n                    \"complexity\": metrics['structural_metrics']['structure_score'],\n                    \"text_structure\": {\n                        \"word_count\": metrics['structural_metrics']['word_count'],\n                        \"avg_length\": metrics['structural_metrics']['avg_word_length']\n                    }\n                },\n                confidence=metrics['structural_metrics']['structure_score']\n            )\n        \n        elif (metrics['complexity_metrics']['relative_complexity'] >= \n              self.linguistic_patterns[\"syntactic_pattern\"][\"min_structure_score\"]):\n            \n            return TextPattern(\n                pattern_type=\"syntactic_pattern\",\n                linguistic_features={\n                    \"complexity\": metrics['complexity_metrics']['relative_complexity'],\n                    \"word_complexity\": metrics['complexity_metrics']['word_complexity'],\n                    \"text_structure\": {\n                        \"word_count\": metrics['structural_metrics']['word_count'],\n                        \"avg_length\": metrics['structural_metrics']['avg_word_length']\n                    }\n                },\n                confidence=metrics['complexity_metrics']['relative_complexity']\n            )\n            \n        return None\n\n    def process_input(self, input_data: Any) -> Dict[str, Any]:\n        \"\"\"Process text and identify patterns\"\"\"\n        # Try to allocate resources if resource manager is available"
        },
        "process_input": {
          "start_line": 125,
          "end_line": 206,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "input_data",
              "type": "Any"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "isinstance",
              "line": 140
            },
            {
              "name": "self._identify_patterns",
              "line": 154
            },
            {
              "name": "self.resource_manager.allocate_resources",
              "line": 128
            },
            {
              "name": "self.update_metrics",
              "line": 162
            },
            {
              "name": "self.update_metrics",
              "line": 183
            },
            {
              "name": "self.update_metrics",
              "line": 192
            },
            {
              "name": "self.resource_manager.release_resources",
              "line": 202
            },
            {
              "name": "str",
              "line": 129
            },
            {
              "name": "str",
              "line": 145
            },
            {
              "name": "str",
              "line": 195
            },
            {
              "name": "str",
              "line": 203
            }
          ],
          "docstring": "Process text and identify patterns",
          "code_snippet": "        return None\n\n    def process_input(self, input_data: Any) -> Dict[str, Any]:\n        \"\"\"Process text and identify patterns\"\"\"\n        # Try to allocate resources if resource manager is available\n        if self.resource_manager and not self.resource_manager.allocate_resources(\n            str(self.domain), \n            self.memory_requirement\n        ):\n            return {\n                \"success\": False,\n                \"error\": \"Failed to allocate resources\",\n                \"domain\": self.domain\n            }\n        \n        try:\n            # Process text\n            if isinstance(input_data, str):\n                text = input_data\n            else:\n                # Try to convert to string\n                try:\n                    text = str(input_data)\n                except:\n                    return {\n                        \"success\": False,\n                        \"error\": \"Input data cannot be converted to text\",\n                        \"domain\": self.domain\n                    }\n            \n            # Identify patterns\n            pattern = self._identify_patterns(text)\n            \n            if pattern:\n                self.translation_metrics[\"patterns_identified\"] += 1\n                if pattern.confidence >= 0.85:\n                    self.translation_metrics[\"high_confidence_patterns\"] += 1\n                    \n                # Update general metrics\n                self.update_metrics(True, pattern.confidence)\n                \n                # Update pattern preservation score\n                if self.translation_metrics[\"patterns_identified\"] > 0:\n                    self.translation_metrics[\"pattern_preservation_score\"] = (\n                        self.translation_metrics[\"high_confidence_patterns\"] / \n                        self.translation_metrics[\"patterns_identified\"]\n                    )\n                \n                return {\n                    \"success\": True,\n                    \"pattern\": {\n                        \"pattern_type\": pattern.pattern_type,\n                        \"confidence\": pattern.confidence,\n                        \"features\": pattern.linguistic_features\n                    },\n                    \"metrics\": self.metrics,\n                    \"domain\": self.domain\n                }\n            else:\n                # No pattern identified\n                self.update_metrics(False)\n                return {\n                    \"success\": False,\n                    \"error\": \"No pattern identified\",\n                    \"domain\": self.domain\n                }\n                \n        except Exception as e:\n            # Update failure metrics\n            self.update_metrics(False)\n            return {\n                \"success\": False,\n                \"error\": str(e),\n                \"domain\": self.domain\n            }\n            \n        finally:\n            # Release resources if using resource manager\n            if self.resource_manager:\n                self.resource_manager.release_resources(\n                    str(self.domain),\n                    self.memory_requirement\n                )"
        }
      },
      "class_variables": [],
      "bases": [
        "BaseSpecialist"
      ]
    }
  },
  "functions": {},
  "constants": {}
}