{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\benchmarks.old\\scripts\\training_benchmark.py",
  "imports": [
    {
      "name": "torch",
      "line": 2
    },
    {
      "name": "torch.nn",
      "line": 3
    },
    {
      "name": "torch.optim",
      "line": 4
    },
    {
      "name": "time",
      "line": 5
    }
  ],
  "classes": {
    "SimpleModel": {
      "start_line": 9,
      "end_line": 26,
      "methods": {
        "__init__": {
          "start_line": 11,
          "end_line": 22,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "....__init__",
              "line": 12
            },
            {
              "name": "nn.Sequential",
              "line": 13
            },
            {
              "name": "nn.Linear",
              "line": 14
            },
            {
              "name": "nn.ReLU",
              "line": 15
            },
            {
              "name": "nn.Linear",
              "line": 16
            },
            {
              "name": "nn.ReLU",
              "line": 17
            },
            {
              "name": "nn.Linear",
              "line": 18
            },
            {
              "name": "nn.ReLU",
              "line": 19
            },
            {
              "name": "nn.Linear",
              "line": 20
            },
            {
              "name": "super",
              "line": 12
            }
          ],
          "code_snippet": "class SimpleModel(nn.Module):\n\n    def __init__(self):\n        super(SimpleModel, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(784, 512),  # Input layer (MNIST image size: 28x28 = 784)\n            nn.ReLU(),\n            nn.Linear(512, 256),  # Hidden layer\n            nn.ReLU(),\n            nn.Linear(256, 128),  # Hidden layer\n            nn.ReLU(),\n            nn.Linear(128, 10)  # Output layer (10 classes for digits 0-9)\n        )\n\n    def forward(self, x):\n        return self.layers(x)"
        },
        "forward": {
          "start_line": 23,
          "end_line": 26,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "x"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.layers",
              "line": 24
            }
          ],
          "code_snippet": "        )\n\n    def forward(self, x):\n        return self.layers(x)\n\n\ndef run_benchmark():\n    # Check if GPU is available"
        }
      },
      "class_variables": [],
      "bases": [
        "..."
      ]
    }
  },
  "functions": {
    "run_benchmark": {
      "start_line": 27,
      "end_line": 113,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "print",
          "line": 30
        },
        {
          "name": "....to",
          "line": 33
        },
        {
          "name": "print",
          "line": 34
        },
        {
          "name": "nn.CrossEntropyLoss",
          "line": 37
        },
        {
          "name": "optim.Adam",
          "line": 38
        },
        {
          "name": "print",
          "line": 106
        },
        {
          "name": "print",
          "line": 107
        },
        {
          "name": "print",
          "line": 108
        },
        {
          "name": "torch.cuda.is_available",
          "line": 29
        },
        {
          "name": "model.parameters",
          "line": 38
        },
        {
          "name": "print",
          "line": 47
        },
        {
          "name": "torch.randn",
          "line": 50
        },
        {
          "name": "torch.randint",
          "line": 51
        },
        {
          "name": "print",
          "line": 54
        },
        {
          "name": "range",
          "line": 55
        },
        {
          "name": "print",
          "line": 66
        },
        {
          "name": "time.time",
          "line": 68
        },
        {
          "name": "range",
          "line": 70
        },
        {
          "name": "time.time",
          "line": 83
        },
        {
          "name": "print",
          "line": 90
        },
        {
          "name": "print",
          "line": 93
        },
        {
          "name": "print",
          "line": 94
        },
        {
          "name": "print",
          "line": 110
        },
        {
          "name": "SimpleModel",
          "line": 33
        },
        {
          "name": "optimizer.zero_grad",
          "line": 56
        },
        {
          "name": "model",
          "line": 57
        },
        {
          "name": "criterion",
          "line": 58
        },
        {
          "name": "loss.backward",
          "line": 59
        },
        {
          "name": "optimizer.step",
          "line": 60
        },
        {
          "name": "torch.cuda.synchronize",
          "line": 63
        },
        {
          "name": "optimizer.zero_grad",
          "line": 72
        },
        {
          "name": "model",
          "line": 73
        },
        {
          "name": "criterion",
          "line": 74
        },
        {
          "name": "loss.backward",
          "line": 77
        },
        {
          "name": "optimizer.step",
          "line": 78
        },
        {
          "name": "print",
          "line": 98
        },
        {
          "name": "torch.cuda.synchronize",
          "line": 81
        },
        {
          "name": "torch.cuda.memory_allocated",
          "line": 97
        }
      ],
      "code_snippet": "\n\ndef run_benchmark():\n    # Check if GPU is available\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    print(f\"Running training benchmark on: {device}\")\n\n    # Create the model and move it to the appropriate device\n    model = SimpleModel().to(device)\n    print(f\"Model architecture:\\n{model}\")\n\n    # Define loss function and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # Create synthetic training data (simulating MNIST)\n    batch_sizes = [32, 64, 128, 256]\n    input_dim = 784  # Flattened 28x28 images\n\n    results = {}\n\n    for batch_size in batch_sizes:\n        print(f\"\\nTesting with batch size: {batch_size}\")\n\n        # Generate random training data\n        inputs = torch.randn(batch_size, input_dim, device=device)\n        labels = torch.randint(0, 10, (batch_size, ), device=device)\n\n        # Warmup\n        print(\"Warming up...\")\n        for _ in range(5):\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n        if device == \"cuda\":\n            torch.cuda.synchronize()\n\n        # Benchmark training speed\n        print(\"Running timed training iterations...\")\n        iterations = 50\n        start_time = time.time()\n\n        for _ in range(iterations):\n            # Forward pass\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            # Backward pass and optimize\n            loss.backward()\n            optimizer.step()\n\n            if device == \"cuda\":\n                torch.cuda.synchronize()\n\n        end_time = time.time()\n\n        # Calculate metrics\n        total_time = end_time - start_time\n        time_per_batch = total_time / iterations\n        samples_per_second = batch_size / time_per_batch\n\n        print(\n            f\"Total time for {iterations} iterations: {total_time:.2f} seconds\"\n        )\n        print(f\"Time per batch: {time_per_batch*1000:.2f} ms\")\n        print(f\"Training throughput: {samples_per_second:.1f} samples/second\")\n\n        if device == \"cuda\":\n            memory_allocated = torch.cuda.memory_allocated() / 1e6  # MB\n            print(f\"GPU memory used: {memory_allocated:.2f} MB\")\n\n        results[batch_size] = {\n            'time_per_batch': time_per_batch,\n            'samples_per_second': samples_per_second\n        }\n\n    # Print summary\n    print(\"\\n===== SUMMARY =====\")\n    print(\"Batch Size | Time per Batch (ms) | Samples per Second\")\n    print(\"-\" * 60)\n    for batch_size in batch_sizes:\n        print(\n            f\"{batch_size:^10} | {results[batch_size]['time_per_batch']*1000:^18.2f} | {results[batch_size]['samples_per_second']:^18.1f}\"\n        )\n\n\nif __name__ == \"__main__\":"
    }
  },
  "constants": {}
}