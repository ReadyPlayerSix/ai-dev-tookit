{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\benchmarks.old\\examples\\run_eve_optimizer.py",
  "imports": [
    {
      "name": "os",
      "line": 13
    },
    {
      "name": "sys",
      "line": 14
    },
    {
      "name": "argparse",
      "line": 15
    },
    {
      "name": "torch",
      "line": 16
    },
    {
      "name": "torch.nn",
      "line": 17
    },
    {
      "name": "torch.optim",
      "line": 18
    },
    {
      "name": "torchvision",
      "line": 19
    },
    {
      "name": "torchvision.transforms",
      "line": 20
    },
    {
      "name": "torchvision.models",
      "line": 21
    },
    {
      "name": "logging",
      "line": 22
    },
    {
      "name": "datetime.datetime",
      "line": 23
    },
    {
      "name": "isekaizen.pattern.tracking.PatternRecognitionTracker",
      "line": 29
    },
    {
      "name": "isekaizen.pattern.detection.PatternRecognitionService",
      "line": 30
    },
    {
      "name": "isekaizen.pattern.data_loading.load_latest_pattern_map",
      "line": 31
    },
    {
      "name": "isekaizen.optimizers.EVENaturalWeights",
      "line": 32
    },
    {
      "name": "json",
      "line": 183
    }
  ],
  "classes": {},
  "functions": {
    "load_cifar10": {
      "start_line": 38,
      "end_line": 62,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "transforms.Compose",
          "line": 41
        },
        {
          "name": "transforms.Compose",
          "line": 48
        },
        {
          "name": "torchvision.datasets.CIFAR10",
          "line": 54
        },
        {
          "name": "torchvision.datasets.CIFAR10",
          "line": 57
        },
        {
          "name": "transforms.RandomCrop",
          "line": 42
        },
        {
          "name": "transforms.RandomHorizontalFlip",
          "line": 43
        },
        {
          "name": "transforms.ToTensor",
          "line": 44
        },
        {
          "name": "transforms.Normalize",
          "line": 45
        },
        {
          "name": "transforms.ToTensor",
          "line": 49
        },
        {
          "name": "transforms.Normalize",
          "line": 50
        }
      ],
      "docstring": "Load CIFAR-10 dataset.",
      "code_snippet": "logger = logging.getLogger(__name__)\n\ndef load_cifar10():\n    \"\"\"Load CIFAR-10 dataset.\"\"\"\n    # Define transformations\n    transform_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    \n    transform_test = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n    ])\n    \n    # Load datasets\n    train_dataset = torchvision.datasets.CIFAR10(\n        root='./data', train=True, download=True, transform=transform_train)\n    \n    test_dataset = torchvision.datasets.CIFAR10(\n        root='./data', train=False, download=True, transform=transform_test)\n    \n    return train_dataset, test_dataset\n\ndef create_model():\n    \"\"\"Create a simple model for CIFAR-10.\"\"\"\n    model = models.resnet18(pretrained=False)"
    },
    "create_model": {
      "start_line": 62,
      "end_line": 70,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "models.resnet18",
          "line": 64
        },
        {
          "name": "nn.Conv2d",
          "line": 65
        },
        {
          "name": "nn.Identity",
          "line": 66
        },
        {
          "name": "nn.Linear",
          "line": 67
        }
      ],
      "docstring": "Create a simple model for CIFAR-10.",
      "code_snippet": "    return train_dataset, test_dataset\n\ndef create_model():\n    \"\"\"Create a simple model for CIFAR-10.\"\"\"\n    model = models.resnet18(pretrained=False)\n    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n    model.maxpool = nn.Identity()  # Remove maxpool for CIFAR-10's small images\n    model.fc = nn.Linear(model.fc.in_features, 10)\n    return model\n\ndef train_epoch(model, train_loader, optimizer, criterion, epoch, device, pattern_service):\n    \"\"\"Train for one epoch with proper pattern states.\"\"\"\n    model.train()"
    },
    "train_epoch": {
      "start_line": 70,
      "end_line": 120,
      "parameters": [
        {
          "name": "model"
        },
        {
          "name": "train_loader"
        },
        {
          "name": "optimizer"
        },
        {
          "name": "criterion"
        },
        {
          "name": "epoch"
        },
        {
          "name": "device"
        },
        {
          "name": "pattern_service"
        }
      ],
      "return_type": null,
      "calls": [
        {
          "name": "model.train",
          "line": 72
        },
        {
          "name": "enumerate",
          "line": 77
        },
        {
          "name": "logger.info",
          "line": 116
        },
        {
          "name": "inputs.size",
          "line": 82
        },
        {
          "name": "pattern_service.get_batch_pattern_states",
          "line": 87
        },
        {
          "name": "model",
          "line": 90
        },
        {
          "name": "criterion",
          "line": 91
        },
        {
          "name": "optimizer.zero_grad",
          "line": 94
        },
        {
          "name": "loss.backward",
          "line": 95
        },
        {
          "name": "optimizer.step",
          "line": 98
        },
        {
          "name": "outputs.max",
          "line": 101
        },
        {
          "name": "targets.size",
          "line": 102
        },
        {
          "name": "....item",
          "line": 103
        },
        {
          "name": "loss.item",
          "line": 105
        },
        {
          "name": "len",
          "line": 114
        },
        {
          "name": "inputs.to",
          "line": 79
        },
        {
          "name": "targets.to",
          "line": 79
        },
        {
          "name": "logger.info",
          "line": 109
        },
        {
          "name": "range",
          "line": 84
        },
        {
          "name": "....sum",
          "line": 103
        },
        {
          "name": "predicted.eq",
          "line": 103
        },
        {
          "name": "loss.item",
          "line": 109
        },
        {
          "name": "targets.size",
          "line": 110
        }
      ],
      "docstring": "Train for one epoch with proper pattern states.",
      "code_snippet": "    return model\n\ndef train_epoch(model, train_loader, optimizer, criterion, epoch, device, pattern_service):\n    \"\"\"Train for one epoch with proper pattern states.\"\"\"\n    model.train()\n    correct = 0\n    total = 0\n    running_loss = 0.0\n    \n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        # Move data to device\n        inputs, targets = inputs.to(device), targets.to(device)\n        \n        # Get batch indices for pattern recognition\n        batch_size = inputs.size(0)\n        start_idx = batch_idx * batch_size\n        batch_indices = [i for i in range(start_idx, start_idx + batch_size)]\n        \n        # Get pattern states for this batch - CRITICAL for EVE\n        pattern_states = pattern_service.get_batch_pattern_states(batch_indices)\n        \n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, targets)\n        \n        # Backward pass and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        \n        # Pass pattern states to optimizer step - CRITICAL for EVE\n        optimizer.step(pattern_states=pattern_states)\n        \n        # Calculate accuracy\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        batch_correct = predicted.eq(targets).sum().item()\n        correct += batch_correct\n        running_loss += loss.item()\n        \n        # Print progress\n        if batch_idx % 50 == 0:\n            logger.info(f'Epoch: {epoch+1} | Batch: {batch_idx} | Loss: {loss.item():.4f} | '\n                      f'Acc: {100. * batch_correct / targets.size(0):.2f}%')\n    \n    # Calculate epoch statistics\n    accuracy = 100. * correct / total\n    epoch_loss = running_loss / len(train_loader)\n    \n    logger.info(f'Epoch {epoch+1} Summary - Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')\n    \n    return accuracy, epoch_loss\n\ndef validate(model, test_loader, criterion, device):\n    \"\"\"Validate the model.\"\"\"\n    model.eval()"
    },
    "validate": {
      "start_line": 120,
      "end_line": 146,
      "parameters": [
        {
          "name": "model"
        },
        {
          "name": "test_loader"
        },
        {
          "name": "criterion"
        },
        {
          "name": "device"
        }
      ],
      "return_type": null,
      "calls": [
        {
          "name": "model.eval",
          "line": 122
        },
        {
          "name": "logger.info",
          "line": 142
        },
        {
          "name": "torch.no_grad",
          "line": 127
        },
        {
          "name": "len",
          "line": 140
        },
        {
          "name": "model",
          "line": 131
        },
        {
          "name": "criterion",
          "line": 132
        },
        {
          "name": "outputs.max",
          "line": 134
        },
        {
          "name": "targets.size",
          "line": 135
        },
        {
          "name": "....item",
          "line": 136
        },
        {
          "name": "loss.item",
          "line": 137
        },
        {
          "name": "inputs.to",
          "line": 129
        },
        {
          "name": "targets.to",
          "line": 129
        },
        {
          "name": "....sum",
          "line": 136
        },
        {
          "name": "predicted.eq",
          "line": 136
        }
      ],
      "docstring": "Validate the model.",
      "code_snippet": "    return accuracy, epoch_loss\n\ndef validate(model, test_loader, criterion, device):\n    \"\"\"Validate the model.\"\"\"\n    model.eval()\n    correct = 0\n    total = 0\n    running_loss = 0.0\n    \n    with torch.no_grad():\n        for inputs, targets in test_loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            \n            outputs = model(inputs)\n            loss = criterion(outputs, targets)\n            \n            _, predicted = outputs.max(1)\n            total += targets.size(0)\n            correct += predicted.eq(targets).sum().item()\n            running_loss += loss.item()\n    \n    accuracy = 100. * correct / total\n    test_loss = running_loss / len(test_loader)\n    \n    logger.info(f'Validation - Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')\n    \n    return accuracy, test_loss\n\ndef main():\n    \"\"\"Run EVE optimizer demo.\"\"\"\n    # Parse arguments"
    },
    "main": {
      "start_line": 146,
      "end_line": 253,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "argparse.ArgumentParser",
          "line": 149
        },
        {
          "name": "parser.add_argument",
          "line": 150
        },
        {
          "name": "parser.add_argument",
          "line": 151
        },
        {
          "name": "parser.add_argument",
          "line": 152
        },
        {
          "name": "parser.add_argument",
          "line": 153
        },
        {
          "name": "parser.add_argument",
          "line": 154
        },
        {
          "name": "parser.add_argument",
          "line": 155
        },
        {
          "name": "parser.parse_args",
          "line": 156
        },
        {
          "name": "torch.device",
          "line": 160
        },
        {
          "name": "logger.info",
          "line": 161
        },
        {
          "name": "torch.manual_seed",
          "line": 164
        },
        {
          "name": "logger.info",
          "line": 169
        },
        {
          "name": "load_cifar10",
          "line": 170
        },
        {
          "name": "torch.utils.data.DataLoader",
          "line": 173
        },
        {
          "name": "torch.utils.data.DataLoader",
          "line": 176
        },
        {
          "name": "logger.info",
          "line": 180
        },
        {
          "name": "logger.info",
          "line": 197
        },
        {
          "name": "create_model",
          "line": 198
        },
        {
          "name": "model.to",
          "line": 199
        },
        {
          "name": "nn.CrossEntropyLoss",
          "line": 202
        },
        {
          "name": "logger.info",
          "line": 205
        },
        {
          "name": "PatternRecognitionTracker",
          "line": 206
        },
        {
          "name": "pattern_tracker.initialize_from_pattern_map",
          "line": 207
        },
        {
          "name": "PatternRecognitionService",
          "line": 209
        },
        {
          "name": "logger.info",
          "line": 212
        },
        {
          "name": "EVENaturalWeights",
          "line": 213
        },
        {
          "name": "logger.info",
          "line": 220
        },
        {
          "name": "range",
          "line": 221
        },
        {
          "name": "logger.info",
          "line": 241
        },
        {
          "name": "validate",
          "line": 242
        },
        {
          "name": "os.path.join",
          "line": 245
        },
        {
          "name": "os.makedirs",
          "line": 246
        },
        {
          "name": "os.path.join",
          "line": 247
        },
        {
          "name": "torch.save",
          "line": 248
        },
        {
          "name": "logger.info",
          "line": 249
        },
        {
          "name": "logger.info",
          "line": 251
        },
        {
          "name": "torch.cuda.is_available",
          "line": 159
        },
        {
          "name": "torch.cuda.manual_seed",
          "line": 166
        },
        {
          "name": "load_latest_pattern_map",
          "line": 186
        },
        {
          "name": "logger.warning",
          "line": 189
        },
        {
          "name": "model.parameters",
          "line": 214
        },
        {
          "name": "train_epoch",
          "line": 223
        },
        {
          "name": "validate",
          "line": 227
        },
        {
          "name": "optimizer.update_accuracy_metrics",
          "line": 230
        },
        {
          "name": "optimizer.get_pattern_weights",
          "line": 233
        },
        {
          "name": "logger.info",
          "line": 234
        },
        {
          "name": "optimizer.pattern_tracker.get_pattern_risks",
          "line": 237
        },
        {
          "name": "logger.info",
          "line": 238
        },
        {
          "name": "model.state_dict",
          "line": 248
        },
        {
          "name": "open",
          "line": 182
        },
        {
          "name": "json.load",
          "line": 184
        },
        {
          "name": "len",
          "line": 192
        },
        {
          "name": "....strftime",
          "line": 247
        },
        {
          "name": "datetime.now",
          "line": 247
        }
      ],
      "docstring": "Run EVE optimizer demo.",
      "code_snippet": "    return accuracy, test_loss\n\ndef main():\n    \"\"\"Run EVE optimizer demo.\"\"\"\n    # Parse arguments\n    parser = argparse.ArgumentParser(description=\"EVE Optimizer Demo\")\n    parser.add_argument(\"--epochs\", type=int, default=10, help=\"Number of training epochs\")\n    parser.add_argument(\"--pattern-map\", type=str, default=None, help=\"Path to pattern map JSON file\")\n    parser.add_argument(\"--batch-size\", type=int, default=128, help=\"Training batch size\")\n    parser.add_argument(\"--lr\", type=float, default=0.001, help=\"Learning rate\")\n    parser.add_argument(\"--no-cuda\", action=\"store_true\", help=\"Disable CUDA\")\n    parser.add_argument(\"--seed\", type=int, default=1, help=\"Random seed\")\n    args = parser.parse_args()\n    \n    # Set device\n    use_cuda = not args.no_cuda and torch.cuda.is_available()\n    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n    logger.info(f\"Using device: {device}\")\n    \n    # Set random seed\n    torch.manual_seed(args.seed)\n    if use_cuda:\n        torch.cuda.manual_seed(args.seed)\n    \n    # Load dataset\n    logger.info(\"Loading CIFAR-10 dataset...\")\n    train_dataset, test_dataset = load_cifar10()\n    \n    # Create data loaders\n    train_loader = torch.utils.data.DataLoader(\n        train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=2)\n    \n    test_loader = torch.utils.data.DataLoader(\n        test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=2)\n    \n    # Load pattern map\n    logger.info(\"Loading pattern map...\")\n    if args.pattern_map:\n        with open(args.pattern_map, 'r') as f:\n            import json\n            pattern_map = json.load(f)\n    else:\n        pattern_map = load_latest_pattern_map()\n    \n    if not pattern_map:\n        logger.warning(\"No pattern map found! Pattern-specific optimization will be limited.\")\n        pattern_map = {\n            \"pattern_distribution\": {\n                \"default\": len(train_dataset)\n            }\n        }\n    \n    # Create model\n    logger.info(\"Creating model...\")\n    model = create_model()\n    model = model.to(device)\n    \n    # Create criterion\n    criterion = nn.CrossEntropyLoss()\n    \n    # Initialize pattern tracking components\n    logger.info(\"Initializing pattern tracking...\")\n    pattern_tracker = PatternRecognitionTracker()\n    pattern_tracker.initialize_from_pattern_map(pattern_map)\n    \n    pattern_service = PatternRecognitionService(pattern_map, train_dataset)\n    \n    # Create optimizer with initialized pattern tracker\n    logger.info(\"Creating EVE optimizer with pattern tracker...\")\n    optimizer = EVENaturalWeights(\n        model.parameters(),\n        lr=args.lr,\n        pattern_tracker=pattern_tracker  # Pass initialized tracker\n    )\n    \n    # Training loop\n    logger.info(\"=== Starting Training with EVE Optimizer ===\")\n    for epoch in range(args.epochs):\n        # Train for one epoch\n        train_acc, train_loss = train_epoch(\n            model, train_loader, optimizer, criterion, epoch, device, pattern_service)\n        \n        # Validate\n        test_acc, test_loss = validate(model, test_loader, criterion, device)\n        \n        # Update optimizer with accuracy metrics\n        optimizer.update_accuracy_metrics(train_acc, test_acc)\n        \n        # Log pattern weights\n        pattern_weights = optimizer.get_pattern_weights()\n        logger.info(f\"Pattern weights: {pattern_weights}\")\n        \n        # Get pattern risks\n        pattern_risks = optimizer.pattern_tracker.get_pattern_risks()\n        logger.info(f\"Pattern risks: {pattern_risks}\")\n    \n    # Final evaluation\n    logger.info(\"=== Final Evaluation ===\")\n    final_acc, _ = validate(model, test_loader, criterion, device)\n    \n    # Save model\n    output_dir = os.path.join(\"examples\", \"output\")\n    os.makedirs(output_dir, exist_ok=True)\n    model_path = os.path.join(output_dir, f\"eve_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pth\")\n    torch.save(model.state_dict(), model_path)\n    logger.info(f\"Model saved to {model_path}\")\n    \n    logger.info(f\"Training complete! Final accuracy: {final_acc:.2f}%\")\n\nif __name__ == \"__main__\":\n    main()"
    }
  },
  "constants": {}
}