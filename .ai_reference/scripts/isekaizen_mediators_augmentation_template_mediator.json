{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\mediators\\augmentation\\template_mediator.py",
  "imports": [
    {
      "name": "torch",
      "line": 8
    },
    {
      "name": "logging",
      "line": 9
    },
    {
      "name": "time",
      "line": 10
    },
    {
      "name": "typing.Dict",
      "line": 11
    },
    {
      "name": "typing.List",
      "line": 11
    },
    {
      "name": "typing.Any",
      "line": 11
    },
    {
      "name": "typing.Optional",
      "line": 11
    },
    {
      "name": "typing.Tuple",
      "line": 11
    },
    {
      "name": "typing.Set",
      "line": 11
    },
    {
      "name": "PIL.Image",
      "line": 12
    },
    {
      "name": "torchvision.transforms",
      "line": 13
    },
    {
      "name": "isekaizen.mediators.base.Mediator",
      "line": 15
    },
    {
      "name": "random",
      "line": 210
    },
    {
      "name": "sys",
      "line": 565
    },
    {
      "name": "random",
      "line": 177
    },
    {
      "name": "PIL.ImageFilter",
      "line": 514
    },
    {
      "name": "random",
      "line": 206
    }
  ],
  "classes": {
    "AugmentationMediator": {
      "start_line": 19,
      "end_line": 587,
      "methods": {
        "__init__": {
          "start_line": 25,
          "end_line": 70,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "dataset"
            },
            {
              "name": "pattern_map"
            },
            {
              "name": "device"
            },
            {
              "name": "cache_size_limit"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._extract_pattern_types",
              "line": 52
            },
            {
              "name": "self.initialize",
              "line": 66
            },
            {
              "name": "logger.info",
              "line": 68
            },
            {
              "name": "torch.device",
              "line": 37
            },
            {
              "name": "torch.cuda.is_available",
              "line": 37
            },
            {
              "name": "len",
              "line": 68
            }
          ],
          "docstring": "\n        Initialize the augmentation mediator.\n        \n        Args:\n            dataset: The dataset to augment\n            pattern_map: Pattern map containing pattern information\n            device: Computation device (CPU/GPU)\n            cache_size_limit: Maximum number of augmentations to cache\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(self, dataset, pattern_map=None, device=None, cache_size_limit=1000):\n        \"\"\"\n        Initialize the augmentation mediator.\n        \n        Args:\n            dataset: The dataset to augment\n            pattern_map: Pattern map containing pattern information\n            device: Computation device (CPU/GPU)\n            cache_size_limit: Maximum number of augmentations to cache\n        \"\"\"\n        self.dataset = dataset\n        self.pattern_map = pattern_map\n        self.device = device or torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.cache_size_limit = cache_size_limit\n        \n        # Template storage by pattern and percentage\n        # {pattern_type: {percentage: [templates]}}\n        self.augmentation_templates = {}\n        \n        # Cache for generated augmentations\n        # {cache_key: [augmentations]}\n        self.augmentation_cache = {}\n        \n        # Cache usage tracking for LRU implementation\n        self.cache_usage = {}\n        \n        # Pattern types from map\n        self.pattern_types = self._extract_pattern_types()\n        \n        # Metrics tracking\n        self.metrics = {\n            \"cache_hits\": 0,\n            \"cache_misses\": 0,\n            \"total_templates\": 0,\n            \"total_augmentations_generated\": 0,\n            \"memory_usage\": {},\n            \"generation_times\": {},\n            \"template_counts\": {}\n        }\n        \n        # Initialize templates\n        self.initialize()\n        \n        logger.info(f\"AugmentationMediator initialized with {len(self.pattern_types)} pattern types\")\n        \n    def initialize(self):\n        \"\"\"Initialize templates for all pattern types.\"\"\"\n        # Skip initialization if dataset is not available yet"
        },
        "initialize": {
          "start_line": 70,
          "end_line": 89,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "time.time",
              "line": 77
            },
            {
              "name": "sum",
              "line": 83
            },
            {
              "name": "hasattr",
              "line": 84
            },
            {
              "name": "logger.info",
              "line": 87
            },
            {
              "name": "logger.info",
              "line": 74
            },
            {
              "name": "self._generate_templates_for_pattern",
              "line": 81
            },
            {
              "name": "len",
              "line": 83
            },
            {
              "name": "....values",
              "line": 83
            },
            {
              "name": "time.time",
              "line": 87
            }
          ],
          "docstring": "Initialize templates for all pattern types.",
          "code_snippet": "        logger.info(f\"AugmentationMediator initialized with {len(self.pattern_types)} pattern types\")\n        \n    def initialize(self):\n        \"\"\"Initialize templates for all pattern types.\"\"\"\n        # Skip initialization if dataset is not available yet\n        if self.dataset is None:\n            logger.info(\"Skipping template initialization - dataset not available yet\")\n            return\n            \n        start_time = time.time()\n        \n        for pattern_type in self.pattern_types:\n            # Create templates at standard percentages (0.01, 0.02, 0.05, 0.10)\n            self._generate_templates_for_pattern(pattern_type)\n            \n        total_templates = sum(len(templates) for pattern_type in self.augmentation_templates for templates in self.augmentation_templates[pattern_type].values())\n        if hasattr(self, 'metrics'):  # Ensure metrics is initialized\n            self.metrics[\"total_templates\"] = total_templates\n        \n        logger.info(f\"Generated {total_templates} augmentation templates in {time.time() - start_time:.2f}s\")\n    \n    def _extract_pattern_types(self) -> List[str]:\n        \"\"\"Extract pattern types from pattern map.\"\"\"\n        if not self.pattern_map:"
        },
        "_extract_pattern_types": {
          "start_line": 89,
          "end_line": 105,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "list",
              "line": 96
            },
            {
              "name": "....keys",
              "line": 96
            }
          ],
          "docstring": "Extract pattern types from pattern map.",
          "code_snippet": "        logger.info(f\"Generated {total_templates} augmentation templates in {time.time() - start_time:.2f}s\")\n    \n    def _extract_pattern_types(self) -> List[str]:\n        \"\"\"Extract pattern types from pattern map.\"\"\"\n        if not self.pattern_map:\n            return [\"structural\", \"statistical\", \"temporal\"]\n            \n        # First check standardized format\n        if 'pattern_distribution' in self.pattern_map:\n            return list(self.pattern_map['pattern_distribution'].keys())\n        \n        # Try alternative formats\n        if 'pattern_types' in self.pattern_map:\n            return self.pattern_map['pattern_types']\n        \n        # Default pattern types\n        return [\"structural\", \"statistical\", \"temporal\"]\n    \n    def _generate_templates_for_pattern(self, pattern_type: str) -> None:\n        \"\"\"\n        Generate augmentation templates for a specific pattern type."
        },
        "_generate_templates_for_pattern": {
          "start_line": 105,
          "end_line": 159,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_type",
              "type": "str"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._find_examples_for_pattern",
              "line": 118
            },
            {
              "name": "logger.warning",
              "line": 114
            },
            {
              "name": "logger.warning",
              "line": 121
            },
            {
              "name": "max",
              "line": 133
            },
            {
              "name": "min",
              "line": 136
            },
            {
              "name": "range",
              "line": 140
            },
            {
              "name": "logger.info",
              "line": 157
            },
            {
              "name": "len",
              "line": 132
            },
            {
              "name": "int",
              "line": 133
            },
            {
              "name": "len",
              "line": 136
            },
            {
              "name": "self._create_template_for_example",
              "line": 144
            },
            {
              "name": "len",
              "line": 155
            },
            {
              "name": "templates.append",
              "line": 146
            },
            {
              "name": "len",
              "line": 141
            },
            {
              "name": "len",
              "line": 157
            }
          ],
          "docstring": "\n        Generate augmentation templates for a specific pattern type.\n        \n        Args:\n            pattern_type: The pattern type to generate templates for\n        ",
          "code_snippet": "        return [\"structural\", \"statistical\", \"temporal\"]\n    \n    def _generate_templates_for_pattern(self, pattern_type: str) -> None:\n        \"\"\"\n        Generate augmentation templates for a specific pattern type.\n        \n        Args:\n            pattern_type: The pattern type to generate templates for\n        \"\"\"\n        # Skip if dataset is not available\n        if self.dataset is None:\n            logger.warning(f\"Cannot generate templates for {pattern_type} - dataset not available\")\n            return\n            \n        # Find examples for this pattern type\n        pattern_examples = self._find_examples_for_pattern(pattern_type, count=100)\n        \n        if not pattern_examples:\n            logger.warning(f\"No examples found for pattern {pattern_type}, skipping template generation\")\n            return\n            \n        # Initialize template storage\n        if pattern_type not in self.augmentation_templates:\n            self.augmentation_templates[pattern_type] = {}\n        \n        # Generate templates for standard percentages\n        for percentage in [0.01, 0.02, 0.05, 0.1]:\n            # Calculate examples needed for this percentage\n            # Ensure dataset is not None before checking its length\n            dataset_size = len(self.dataset) if self.dataset is not None else 1000  # Default size if dataset is None\n            examples_count = max(10, int(dataset_size * percentage * 0.1))  # 10% of total needed\n            \n            # Limit to available examples\n            examples_to_use = min(examples_count, len(pattern_examples))\n            \n            # Generate templates\n            templates = []\n            for i in range(examples_to_use):\n                example_idx = pattern_examples[i % len(pattern_examples)]\n                \n                # Create template based on pattern type\n                template = self._create_template_for_example(pattern_type, example_idx)\n                if template:\n                    templates.append(template)\n            \n            # Store templates\n            self.augmentation_templates[pattern_type][percentage] = templates\n            \n            # Update metrics\n            if self.metrics is not None:  # Extra safety check\n                if pattern_type not in self.metrics[\"template_counts\"]:\n                    self.metrics[\"template_counts\"][pattern_type] = {}\n                self.metrics[\"template_counts\"][pattern_type][percentage] = len(templates)\n            \n            logger.info(f\"Generated {len(templates)} templates for {pattern_type} at {percentage:.2%}\")\n    \n    def _find_examples_for_pattern(self, pattern_type: str, count: int = 100) -> List[int]:\n        \"\"\"\n        Find examples for a specific pattern type."
        },
        "_find_examples_for_pattern": {
          "start_line": 159,
          "end_line": 213,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_type",
              "type": "str"
            },
            {
              "name": "count",
              "type": "int"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "random.sample",
              "line": 211
            },
            {
              "name": "logger.warning",
              "line": 172
            },
            {
              "name": "random.sample",
              "line": 178
            },
            {
              "name": "assignments.items",
              "line": 185
            },
            {
              "name": "range",
              "line": 211
            },
            {
              "name": "min",
              "line": 211
            },
            {
              "name": "range",
              "line": 178
            },
            {
              "name": "min",
              "line": 178
            },
            {
              "name": "random.sample",
              "line": 207
            },
            {
              "name": "len",
              "line": 211
            },
            {
              "name": "len",
              "line": 211
            },
            {
              "name": "len",
              "line": 178
            },
            {
              "name": "len",
              "line": 178
            },
            {
              "name": "assignment.get",
              "line": 186
            },
            {
              "name": "range",
              "line": 207
            },
            {
              "name": "min",
              "line": 207
            },
            {
              "name": "int",
              "line": 188
            },
            {
              "name": "examples.append",
              "line": 189
            },
            {
              "name": "len",
              "line": 207
            },
            {
              "name": "len",
              "line": 207
            },
            {
              "name": "len",
              "line": 190
            }
          ],
          "docstring": "\n        Find examples for a specific pattern type.\n        \n        Args:\n            pattern_type: Pattern type to find examples for\n            count: Maximum number of examples to find\n            \n        Returns:\n            List of example indices\n        ",
          "code_snippet": "            logger.info(f\"Generated {len(templates)} templates for {pattern_type} at {percentage:.2%}\")\n    \n    def _find_examples_for_pattern(self, pattern_type: str, count: int = 100) -> List[int]:\n        \"\"\"\n        Find examples for a specific pattern type.\n        \n        Args:\n            pattern_type: Pattern type to find examples for\n            count: Maximum number of examples to find\n            \n        Returns:\n            List of example indices\n        \"\"\"\n        # Ensure dataset is available\n        if self.dataset is None:\n            logger.warning(f\"Cannot find examples for {pattern_type} - dataset not available\")\n            return []\n            \n        if not self.pattern_map:\n            # Without pattern map, just return random indices\n            import random\n            return random.sample(range(len(self.dataset)), min(count, len(self.dataset)))\n        \n        # Try to find examples from pattern assignments\n        if 'pattern_assignments' in self.pattern_map:\n            assignments = self.pattern_map['pattern_assignments']\n            examples = []\n            \n            for idx_str, assignment in assignments.items():\n                if assignment.get('pattern_type') == pattern_type:\n                    try:\n                        idx = int(idx_str)\n                        examples.append(idx)\n                        if len(examples) >= count:\n                            break\n                    except ValueError:\n                        continue\n            \n            if examples:\n                return examples\n        \n        # If no examples found or no assignments, use distribution to estimate\n        if 'pattern_distribution' in self.pattern_map:\n            distribution = self.pattern_map['pattern_distribution']\n            if pattern_type in distribution:\n                # Estimate indices based on distribution percentage\n                pattern_percentage = distribution[pattern_type]\n                \n                # Generate synthetic indices\n                import random\n                return random.sample(range(len(self.dataset)), min(count, len(self.dataset)))\n        \n        # Fallback to random selection\n        import random\n        return random.sample(range(len(self.dataset)), min(count, len(self.dataset)))\n    \n    def _create_template_for_example(self, pattern_type: str, example_idx: int) -> Optional[Dict]:\n        \"\"\"\n        Create an augmentation template for a specific example."
        },
        "_create_template_for_example": {
          "start_line": 213,
          "end_line": 263,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_type",
              "type": "str"
            },
            {
              "name": "example_idx",
              "type": "int"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "logger.error",
              "line": 260
            },
            {
              "name": "isinstance",
              "line": 231
            },
            {
              "name": "label.item",
              "line": 231
            },
            {
              "name": "round",
              "line": 239
            },
            {
              "name": "bool",
              "line": 240
            },
            {
              "name": "round",
              "line": 241
            },
            {
              "name": "round",
              "line": 242
            },
            {
              "name": "float",
              "line": 239
            },
            {
              "name": "float",
              "line": 241
            },
            {
              "name": "float",
              "line": 242
            },
            {
              "name": "round",
              "line": 246
            },
            {
              "name": "round",
              "line": 247
            },
            {
              "name": "round",
              "line": 248
            },
            {
              "name": "round",
              "line": 249
            },
            {
              "name": "torch.rand",
              "line": 240
            },
            {
              "name": "float",
              "line": 246
            },
            {
              "name": "float",
              "line": 247
            },
            {
              "name": "float",
              "line": 248
            },
            {
              "name": "float",
              "line": 249
            },
            {
              "name": "round",
              "line": 253
            },
            {
              "name": "round",
              "line": 254
            },
            {
              "name": "round",
              "line": 255
            },
            {
              "name": "str",
              "line": 260
            },
            {
              "name": "torch.rand",
              "line": 241
            },
            {
              "name": "float",
              "line": 253
            },
            {
              "name": "float",
              "line": 254
            },
            {
              "name": "float",
              "line": 255
            },
            {
              "name": "torch.rand",
              "line": 239
            },
            {
              "name": "torch.rand",
              "line": 242
            },
            {
              "name": "torch.rand",
              "line": 246
            },
            {
              "name": "torch.rand",
              "line": 247
            },
            {
              "name": "torch.rand",
              "line": 248
            },
            {
              "name": "torch.rand",
              "line": 249
            },
            {
              "name": "torch.rand",
              "line": 254
            },
            {
              "name": "torch.rand",
              "line": 255
            },
            {
              "name": "torch.rand",
              "line": 253
            }
          ],
          "docstring": "\n        Create an augmentation template for a specific example.\n        \n        Args:\n            pattern_type: Type of pattern\n            example_idx: Index of the example\n            \n        Returns:\n            Template dictionary or None if creation failed\n        ",
          "code_snippet": "        return random.sample(range(len(self.dataset)), min(count, len(self.dataset)))\n    \n    def _create_template_for_example(self, pattern_type: str, example_idx: int) -> Optional[Dict]:\n        \"\"\"\n        Create an augmentation template for a specific example.\n        \n        Args:\n            pattern_type: Type of pattern\n            example_idx: Index of the example\n            \n        Returns:\n            Template dictionary or None if creation failed\n        \"\"\"\n        try:\n            # Get the example\n            example, label = self.dataset[example_idx]\n            \n            # Base template\n            template = {\n                \"example_idx\": example_idx,\n                \"label\": label.item() if isinstance(label, torch.Tensor) else label,\n                \"transforms\": {},\n                \"pattern_type\": pattern_type\n            }\n            \n            # Add pattern-specific transforms\n            if pattern_type == \"structural\":\n                template[\"transforms\"] = {\n                    \"rotation\": round(float(torch.rand(1) * 30 - 15), 1),  # -15 to 15 degrees\n                    \"flip\": bool(torch.rand(1) > 0.5),\n                    \"perspective\": round(float(torch.rand(1) * 0.3), 2),  # 0 to 0.3\n                    \"scale\": round(float(0.9 + torch.rand(1) * 0.2), 2)  # 0.9 to 1.1\n                }\n            elif pattern_type == \"statistical\":\n                template[\"transforms\"] = {\n                    \"brightness\": round(float(0.8 + torch.rand(1) * 0.4), 2),  # 0.8 to 1.2\n                    \"contrast\": round(float(0.8 + torch.rand(1) * 0.4), 2),  # 0.8 to 1.2\n                    \"saturation\": round(float(0.8 + torch.rand(1) * 0.4), 2),  # 0.8 to 1.2\n                    \"hue\": round(float(torch.rand(1) * 0.2 - 0.1), 2)  # -0.1 to 0.1\n                }\n            elif pattern_type == \"temporal\":\n                template[\"transforms\"] = {\n                    \"blur\": round(float(0.5 + torch.rand(1) * 1.5), 2),  # 0.5 to 2.0\n                    \"translate_x\": round(float(torch.rand(1) * 0.1), 2),  # 0 to 0.1\n                    \"translate_y\": round(float(torch.rand(1) * 0.1), 2),  # 0 to 0.1\n                }\n            \n            return template\n        except Exception as e:\n            logger.error(f\"Error creating template for example {example_idx}: {str(e)}\")\n            return None\n    \n    def get_augmentations(self, pattern_type: str, percentage: float, count: Optional[int] = None) -> List[Tuple[torch.Tensor, int]]:\n        \"\"\"\n        Get augmented examples for a specific pattern type and percentage."
        },
        "get_augmentations": {
          "start_line": 263,
          "end_line": 367,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_type",
              "type": "str"
            },
            {
              "name": "percentage",
              "type": "float"
            },
            {
              "name": "count"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "time.time",
              "line": 295
            },
            {
              "name": "list",
              "line": 302
            },
            {
              "name": "self._find_percentage_combinations",
              "line": 308
            },
            {
              "name": "hasattr",
              "line": 345
            },
            {
              "name": "logger.info",
              "line": 364
            },
            {
              "name": "logger.warning",
              "line": 277
            },
            {
              "name": "time.time",
              "line": 286
            },
            {
              "name": "hasattr",
              "line": 289
            },
            {
              "name": "logger.warning",
              "line": 299
            },
            {
              "name": "....keys",
              "line": 302
            },
            {
              "name": "logger.warning",
              "line": 304
            },
            {
              "name": "int",
              "line": 314
            },
            {
              "name": "min",
              "line": 325
            },
            {
              "name": "range",
              "line": 330
            },
            {
              "name": "time.time",
              "line": 344
            },
            {
              "name": "len",
              "line": 347
            },
            {
              "name": "len",
              "line": 351
            },
            {
              "name": "time.time",
              "line": 353
            },
            {
              "name": "min",
              "line": 356
            },
            {
              "name": "time.time",
              "line": 362
            },
            {
              "name": "len",
              "line": 313
            },
            {
              "name": "self._apply_template",
              "line": 335
            },
            {
              "name": "self.cache_usage.keys",
              "line": 356
            },
            {
              "name": "len",
              "line": 325
            },
            {
              "name": "augmentations.append",
              "line": 337
            },
            {
              "name": "len",
              "line": 364
            },
            {
              "name": "len",
              "line": 332
            },
            {
              "name": "len",
              "line": 340
            }
          ],
          "docstring": "\n        Get augmented examples for a specific pattern type and percentage.\n        \n        Args:\n            pattern_type: Type of pattern to augment\n            percentage: Percentage to augment (e.g., 0.01 = 1%)\n            count: Optional count limit\n            \n        Returns:\n            List of augmented examples as (tensor, label) tuples\n        ",
          "code_snippet": "            return None\n    \n    def get_augmentations(self, pattern_type: str, percentage: float, count: Optional[int] = None) -> List[Tuple[torch.Tensor, int]]:\n        \"\"\"\n        Get augmented examples for a specific pattern type and percentage.\n        \n        Args:\n            pattern_type: Type of pattern to augment\n            percentage: Percentage to augment (e.g., 0.01 = 1%)\n            count: Optional count limit\n            \n        Returns:\n            List of augmented examples as (tensor, label) tuples\n        \"\"\"\n        # Check if dataset is available\n        if self.dataset is None:\n            logger.warning(f\"Cannot get augmentations - dataset not available\")\n            return []\n            \n        # Create cache key\n        cache_key = f\"{pattern_type}_{percentage}_{count if count else 'all'}\"\n        \n        # Check cache first\n        if cache_key in self.augmentation_cache:\n            # Update usage timestamp\n            self.cache_usage[cache_key] = time.time()\n            \n            # Update metrics\n            if hasattr(self, 'metrics'):\n                self.metrics[\"cache_hits\"] += 1\n            \n            return self.augmentation_cache[cache_key]\n        \n        # Start timing\n        start_time = time.time()\n        \n        # Find closest percentage in available templates\n        if pattern_type not in self.augmentation_templates:\n            logger.warning(f\"No templates available for pattern type {pattern_type}\")\n            return []\n            \n        available_percentages = list(self.augmentation_templates[pattern_type].keys())\n        if not available_percentages:\n            logger.warning(f\"No percentage templates available for {pattern_type}\")\n            return []\n            \n        # Find percentages to combine\n        combinations = self._find_percentage_combinations(percentage, available_percentages)\n        \n        # Calculate how many examples to generate\n        if count is None:\n            # Calculate based on dataset size and percentage\n            dataset_size = len(self.dataset) if self.dataset is not None else 1000  # Default size\n            count = int(dataset_size * percentage)\n        \n        # Generate augmentations\n        augmentations = []\n        for template_percentage, template_count in combinations:\n            # Get templates for this percentage\n            templates = self.augmentation_templates[pattern_type][template_percentage]\n            if not templates:\n                continue\n                \n            # Calculate how many examples to generate from these templates\n            examples_to_generate = min(template_count, count - len(augmentations))\n            if examples_to_generate <= 0:\n                break\n                \n            # Generate examples\n            for i in range(examples_to_generate):\n                # Select a template\n                template = templates[i % len(templates)]\n                \n                # Generate augmentation\n                augmented = self._apply_template(template)\n                if augmented:\n                    augmentations.append(augmented)\n                    \n                    # Check if we've generated enough\n                    if len(augmentations) >= count:\n                        break\n        \n        # Update metrics\n        generation_time = time.time() - start_time\n        if hasattr(self, 'metrics'):\n            self.metrics[\"cache_misses\"] += 1\n            self.metrics[\"total_augmentations_generated\"] += len(augmentations)\n            self.metrics[\"generation_times\"][cache_key] = generation_time\n        \n        # Cache the result if within limits\n        if len(self.augmentation_cache) < self.cache_size_limit:\n            self.augmentation_cache[cache_key] = augmentations\n            self.cache_usage[cache_key] = time.time()\n        else:\n            # LRU cache management - remove least recently used\n            oldest_key = min(self.cache_usage.keys(), key=lambda k: self.cache_usage[k])\n            del self.augmentation_cache[oldest_key]\n            del self.cache_usage[oldest_key]\n            \n            # Add new item\n            self.augmentation_cache[cache_key] = augmentations\n            self.cache_usage[cache_key] = time.time()\n        \n        logger.info(f\"Generated {len(augmentations)} augmentations for {pattern_type} at {percentage:.2%} in {generation_time:.2f}s\")\n        return augmentations\n    \n    def _find_percentage_combinations(self, target: float, available: List[float]) -> List[Tuple[float, int]]:\n        \"\"\"\n        Find combinations of available percentages to achieve target percentage."
        },
        "_find_percentage_combinations": {
          "start_line": 367,
          "end_line": 406,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "target",
              "type": "float"
            },
            {
              "name": "available"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "sorted",
              "line": 379
            },
            {
              "name": "max",
              "line": 396
            },
            {
              "name": "int",
              "line": 397
            },
            {
              "name": "int",
              "line": 391
            },
            {
              "name": "result.append",
              "line": 399
            },
            {
              "name": "result.append",
              "line": 393
            }
          ],
          "docstring": "\n        Find combinations of available percentages to achieve target percentage.\n        \n        Args:\n            target: Target percentage\n            available: Available percentage templates\n            \n        Returns:\n            List of (percentage, count) tuples\n        ",
          "code_snippet": "        return augmentations\n    \n    def _find_percentage_combinations(self, target: float, available: List[float]) -> List[Tuple[float, int]]:\n        \"\"\"\n        Find combinations of available percentages to achieve target percentage.\n        \n        Args:\n            target: Target percentage\n            available: Available percentage templates\n            \n        Returns:\n            List of (percentage, count) tuples\n        \"\"\"\n        # Sort available percentages\n        available = sorted(available)\n        \n        # Simple algorithm - use largest percentage that fits, then recursively handle remainder\n        result = []\n        remaining = target\n        \n        while remaining > 0 and available:\n            # Find largest percentage that fits\n            usable = [p for p in available if p <= remaining]\n            if not usable:\n                # Use smallest available\n                percentage = available[0]\n                count = int(remaining / percentage)\n                if count > 0:\n                    result.append((percentage, count))\n                break\n            \n            percentage = max(usable)\n            count = int(remaining / percentage)\n            if count > 0:\n                result.append((percentage, count))\n                remaining -= percentage * count\n            else:\n                break\n        \n        return result\n    \n    def _apply_template(self, template: Dict) -> Optional[Tuple[torch.Tensor, int]]:\n        \"\"\"\n        Apply an augmentation template to generate an example."
        },
        "_apply_template": {
          "start_line": 406,
          "end_line": 459,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "template",
              "type": "Dict"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "isinstance",
              "line": 425
            },
            {
              "name": "isinstance",
              "line": 442
            },
            {
              "name": "self._apply_structural_transforms",
              "line": 432
            },
            {
              "name": "logger.error",
              "line": 456
            },
            {
              "name": "transforms.ToPILImage",
              "line": 426
            },
            {
              "name": "example.cpu",
              "line": 426
            },
            {
              "name": "self._apply_statistical_transforms",
              "line": 434
            },
            {
              "name": "transforms.ToTensor",
              "line": 443
            },
            {
              "name": "tensor.to",
              "line": 451
            },
            {
              "name": "self._apply_temporal_transforms",
              "line": 436
            },
            {
              "name": "example.min",
              "line": 445
            },
            {
              "name": "transforms.Normalize",
              "line": 447
            },
            {
              "name": "str",
              "line": 456
            }
          ],
          "docstring": "\n        Apply an augmentation template to generate an example.\n        \n        Args:\n            template: The template to apply\n            \n        Returns:\n            Tuple of (tensor, label) or None if application failed\n        ",
          "code_snippet": "        return result\n    \n    def _apply_template(self, template: Dict) -> Optional[Tuple[torch.Tensor, int]]:\n        \"\"\"\n        Apply an augmentation template to generate an example.\n        \n        Args:\n            template: The template to apply\n            \n        Returns:\n            Tuple of (tensor, label) or None if application failed\n        \"\"\"\n        try:\n            # Get the base example\n            example_idx = template[\"example_idx\"]\n            example, _ = self.dataset[example_idx]\n            label = template[\"label\"]\n            transforms_dict = template[\"transforms\"]\n            pattern_type = template[\"pattern_type\"]\n            \n            # Convert tensor to PIL image for transformations\n            if isinstance(example, torch.Tensor):\n                image = transforms.ToPILImage()(example.cpu())\n            else:\n                image = example\n            \n            # Apply transformations based on pattern type and transforms dict\n            if pattern_type == \"structural\":\n                transformed = self._apply_structural_transforms(image, transforms_dict)\n            elif pattern_type == \"statistical\":\n                transformed = self._apply_statistical_transforms(image, transforms_dict)\n            elif pattern_type == \"temporal\":\n                transformed = self._apply_temporal_transforms(image, transforms_dict)\n            else:\n                # Unknown pattern type\n                return None\n            \n            # Convert back to tensor\n            if isinstance(example, torch.Tensor):\n                tensor = transforms.ToTensor()(transformed)\n                # Apply same normalization if present in original\n                if example.shape[0] == 3 and example.min() < 0:\n                    # Assume this was normalized with standard transforms\n                    tensor = transforms.Normalize(\n                        (0.4914, 0.4822, 0.4465), \n                        (0.2023, 0.1994, 0.2010)\n                    )(tensor)\n                return tensor.to(self.device), label\n            else:\n                return transformed, label\n                \n        except Exception as e:\n            logger.error(f\"Error applying template: {str(e)}\")\n            return None\n    \n    def _apply_structural_transforms(self, image, transforms_dict):\n        \"\"\"Apply structural transforms to an image.\"\"\"\n        # Build transform"
        },
        "_apply_structural_transforms": {
          "start_line": 459,
          "end_line": 492,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "image"
            },
            {
              "name": "transforms_dict"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "transform_list.append",
              "line": 465
            },
            {
              "name": "transform_list.append",
              "line": 471
            },
            {
              "name": "transform_list.append",
              "line": 474
            },
            {
              "name": "transform_list.append",
              "line": 480
            },
            {
              "name": "transforms.Compose",
              "line": 487
            },
            {
              "name": "composed",
              "line": 488
            },
            {
              "name": "transforms.RandomRotation",
              "line": 465
            },
            {
              "name": "transforms.RandomHorizontalFlip",
              "line": 471
            },
            {
              "name": "transforms.RandomPerspective",
              "line": 474
            },
            {
              "name": "transforms.RandomAffine",
              "line": 480
            }
          ],
          "docstring": "Apply structural transforms to an image.",
          "code_snippet": "            return None\n    \n    def _apply_structural_transforms(self, image, transforms_dict):\n        \"\"\"Apply structural transforms to an image.\"\"\"\n        # Build transform\n        transform_list = []\n        \n        if 'rotation' in transforms_dict:\n            transform_list.append(transforms.RandomRotation([\n                transforms_dict['rotation'], \n                transforms_dict['rotation']\n            ]))\n            \n        if 'flip' in transforms_dict and transforms_dict['flip']:\n            transform_list.append(transforms.RandomHorizontalFlip(p=1.0))\n            \n        if 'perspective' in transforms_dict:\n            transform_list.append(transforms.RandomPerspective(\n                distortion_scale=transforms_dict['perspective'], \n                p=1.0\n            ))\n            \n        if 'scale' in transforms_dict:\n            transform_list.append(transforms.RandomAffine(\n                degrees=0, \n                scale=(transforms_dict['scale'], transforms_dict['scale'])\n            ))\n            \n        # Apply transforms\n        if transform_list:\n            composed = transforms.Compose(transform_list)\n            return composed(image)\n        else:\n            return image\n    \n    def _apply_statistical_transforms(self, image, transforms_dict):\n        \"\"\"Apply statistical transforms to an image.\"\"\"\n        # Extract values"
        },
        "_apply_statistical_transforms": {
          "start_line": 492,
          "end_line": 510,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "image"
            },
            {
              "name": "transforms_dict"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "transforms_dict.get",
              "line": 495
            },
            {
              "name": "transforms_dict.get",
              "line": 496
            },
            {
              "name": "transforms_dict.get",
              "line": 497
            },
            {
              "name": "transforms_dict.get",
              "line": 498
            },
            {
              "name": "transforms.ColorJitter",
              "line": 501
            },
            {
              "name": "transform",
              "line": 508
            }
          ],
          "docstring": "Apply statistical transforms to an image.",
          "code_snippet": "            return image\n    \n    def _apply_statistical_transforms(self, image, transforms_dict):\n        \"\"\"Apply statistical transforms to an image.\"\"\"\n        # Extract values\n        brightness = transforms_dict.get('brightness', 1.0)\n        contrast = transforms_dict.get('contrast', 1.0)\n        saturation = transforms_dict.get('saturation', 1.0)\n        hue = transforms_dict.get('hue', 0.0)\n        \n        # Build transform\n        transform = transforms.ColorJitter(\n            brightness=(brightness, brightness),\n            contrast=(contrast, contrast),\n            saturation=(saturation, saturation),\n            hue=(hue, hue)\n        )\n        \n        return transform(image)\n    \n    def _apply_temporal_transforms(self, image, transforms_dict):\n        \"\"\"Apply temporal transforms to an image.\"\"\"\n        # Apply blur if specified"
        },
        "_apply_temporal_transforms": {
          "start_line": 510,
          "end_line": 531,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "image"
            },
            {
              "name": "transforms_dict"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "transforms_dict.get",
              "line": 519
            },
            {
              "name": "transforms_dict.get",
              "line": 520
            },
            {
              "name": "image.filter",
              "line": 516
            },
            {
              "name": "transforms.RandomAffine",
              "line": 523
            },
            {
              "name": "transform",
              "line": 527
            },
            {
              "name": "ImageFilter.GaussianBlur",
              "line": 516
            }
          ],
          "docstring": "Apply temporal transforms to an image.",
          "code_snippet": "        return transform(image)\n    \n    def _apply_temporal_transforms(self, image, transforms_dict):\n        \"\"\"Apply temporal transforms to an image.\"\"\"\n        # Apply blur if specified\n        if 'blur' in transforms_dict:\n            from PIL import ImageFilter\n            blur_radius = transforms_dict['blur']\n            image = image.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n            \n        # Apply translation\n        translate_x = transforms_dict.get('translate_x', 0.0)\n        translate_y = transforms_dict.get('translate_y', 0.0)\n        \n        if translate_x > 0 or translate_y > 0:\n            transform = transforms.RandomAffine(\n                degrees=0,\n                translate=(translate_x, translate_y)\n            )\n            image = transform(image)\n            \n        return image\n    \n    def clear_cache(self):\n        \"\"\"Clear the augmentation cache to free memory.\"\"\"\n        self.augmentation_cache.clear()"
        },
        "clear_cache": {
          "start_line": 531,
          "end_line": 538,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.augmentation_cache.clear",
              "line": 533
            },
            {
              "name": "self.cache_usage.clear",
              "line": 534
            },
            {
              "name": "logger.info",
              "line": 536
            }
          ],
          "docstring": "Clear the augmentation cache to free memory.",
          "code_snippet": "        return image\n    \n    def clear_cache(self):\n        \"\"\"Clear the augmentation cache to free memory.\"\"\"\n        self.augmentation_cache.clear()\n        self.cache_usage.clear()\n        \n        logger.info(\"Augmentation cache cleared\")\n    \n    def get_metrics(self):\n        \"\"\"Get current metrics from the mediator.\"\"\"\n        # Ensure metrics is initialized"
        },
        "get_metrics": {
          "start_line": 538,
          "end_line": 563,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "dict",
              "line": 557
            },
            {
              "name": "len",
              "line": 559
            },
            {
              "name": "max",
              "line": 554
            },
            {
              "name": "hasattr",
              "line": 541
            }
          ],
          "docstring": "Get current metrics from the mediator.",
          "code_snippet": "        logger.info(\"Augmentation cache cleared\")\n    \n    def get_metrics(self):\n        \"\"\"Get current metrics from the mediator.\"\"\"\n        # Ensure metrics is initialized\n        if not hasattr(self, 'metrics') or self.metrics is None:\n            # Return empty default metrics\n            return {\n                \"cache_hits\": 0,\n                \"cache_misses\": 0,\n                \"total_templates\": 0,\n                \"total_augmentations_generated\": 0,\n                \"cache_hit_rate\": 0.0,\n                \"cache_size\": 0\n            }\n            \n        # Calculate cache hit rate\n        total_requests = self.metrics[\"cache_hits\"] + self.metrics[\"cache_misses\"]\n        hit_rate = self.metrics[\"cache_hits\"] / max(1, total_requests)\n        \n        # Add derived metrics\n        metrics = dict(self.metrics)\n        metrics[\"cache_hit_rate\"] = hit_rate\n        metrics[\"cache_size\"] = len(self.augmentation_cache)\n        \n        return metrics\n    \n    def _estimate_memory_usage(self):\n        \"\"\"Estimate memory usage of cached augmentations.\"\"\"\n        import sys"
        },
        "_estimate_memory_usage": {
          "start_line": 563,
          "end_line": 587,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "list",
              "line": 571
            },
            {
              "name": "self.augmentation_cache.items",
              "line": 571
            },
            {
              "name": "isinstance",
              "line": 574
            },
            {
              "name": "len",
              "line": 583
            },
            {
              "name": "....element_size",
              "line": 576
            },
            {
              "name": "....nelement",
              "line": 576
            },
            {
              "name": "len",
              "line": 577
            }
          ],
          "docstring": "Estimate memory usage of cached augmentations.",
          "code_snippet": "        return metrics\n    \n    def _estimate_memory_usage(self):\n        \"\"\"Estimate memory usage of cached augmentations.\"\"\"\n        import sys\n        \n        total_size = 0\n        sample_count = 0\n        \n        # Sample a few augmentations for size estimation\n        for key, augmentations in list(self.augmentation_cache.items())[:5]:\n            if augmentations:\n                # Get size of first augmentation\n                if isinstance(augmentations[0][0], torch.Tensor):\n                    # Use tensor size in bytes\n                    tensor_size = augmentations[0][0].element_size() * augmentations[0][0].nelement()\n                    total_size += tensor_size * len(augmentations)\n                    sample_count += 1\n        \n        # Calculate average if we have samples\n        if sample_count > 0:\n            avg_size = total_size / sample_count\n            return avg_size * len(self.augmentation_cache)\n        else:\n            return 0"
        }
      },
      "class_variables": [],
      "bases": [
        "Mediator"
      ],
      "docstring": "\n    Mediator component that manages template-based data augmentation,\n    providing efficient caching and template management.\n    "
    }
  },
  "functions": {},
  "constants": {}
}