{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\utils\\training_utils.py",
  "imports": [
    {
      "name": "torch",
      "line": 10
    },
    {
      "name": "logging",
      "line": 11
    },
    {
      "name": "multiprocessing",
      "line": 12
    },
    {
      "name": "psutil",
      "line": 13
    },
    {
      "name": "math",
      "line": 14
    }
  ],
  "classes": {},
  "functions": {
    "get_fibonacci_check_intervals": {
      "start_line": 18,
      "end_line": 49,
      "parameters": [
        {
          "name": "total_epochs"
        }
      ],
      "return_type": null,
      "calls": [
        {
          "name": "range",
          "line": 38
        },
        {
          "name": "fib_sequence.append",
          "line": 31
        },
        {
          "name": "intervals.append",
          "line": 44
        },
        {
          "name": "len",
          "line": 40
        }
      ],
      "docstring": "\n    Pre-calculate Fibonacci-based check intervals for the entire training.\n    \n    Args:\n        total_epochs: Total number of training epochs\n        \n    Returns:\n        List of check intervals for each epoch\n    ",
      "code_snippet": "logger = logging.getLogger(__name__)\n\ndef get_fibonacci_check_intervals(total_epochs):\n    \"\"\"\n    Pre-calculate Fibonacci-based check intervals for the entire training.\n    \n    Args:\n        total_epochs: Total number of training epochs\n        \n    Returns:\n        List of check intervals for each epoch\n    \"\"\"\n    # Generate Fibonacci sequence\n    fib_sequence = [1, 1]\n    while fib_sequence[-1] < total_epochs // 2:  # Generate enough Fibonacci numbers\n        fib_sequence.append(fib_sequence[-1] + fib_sequence[-2])\n    \n    # Create interval mapping for each epoch\n    intervals = []\n    current_fib_index = 0\n    epoch_counter = 0\n    \n    for epoch in range(total_epochs):\n        # Move to next Fibonacci number if we've used current one enough times\n        if epoch_counter >= fib_sequence[current_fib_index] and current_fib_index < len(fib_sequence) - 1:\n            current_fib_index += 1\n            epoch_counter = 0\n        \n        intervals.append(fib_sequence[current_fib_index])\n        epoch_counter += 1\n    \n    return intervals\n\ndef calculate_optimal_workers():\n    \"\"\"\n    Calculate the optimal number of workers based on system capabilities."
    },
    "calculate_optimal_workers": {
      "start_line": 49,
      "end_line": 104,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "multiprocessing.cpu_count",
          "line": 62
        },
        {
          "name": "math.ceil",
          "line": 82
        },
        {
          "name": "torch.cuda.is_available",
          "line": 85
        },
        {
          "name": "min",
          "line": 94
        },
        {
          "name": "max",
          "line": 95
        },
        {
          "name": "logger.info",
          "line": 97
        },
        {
          "name": "torch.cuda.device_count",
          "line": 87
        },
        {
          "name": "min",
          "line": 88
        },
        {
          "name": "max",
          "line": 94
        },
        {
          "name": "min",
          "line": 95
        },
        {
          "name": "logger.warning",
          "line": 101
        },
        {
          "name": "psutil.cpu_percent",
          "line": 67
        },
        {
          "name": "max",
          "line": 88
        },
        {
          "name": "psutil.virtual_memory",
          "line": 74
        },
        {
          "name": "str",
          "line": 101
        }
      ],
      "docstring": "\n    Calculate the optimal number of workers based on system capabilities.\n    \n    Following isekaiZen mathematical foundation, this function integrates\n    cognitive efficiency principles to determine the optimal number of\n    DataLoader workers that balances performance and stability.\n    \n    Returns:\n        Integer number of workers\n    ",
      "code_snippet": "    return intervals\n\ndef calculate_optimal_workers():\n    \"\"\"\n    Calculate the optimal number of workers based on system capabilities.\n    \n    Following isekaiZen mathematical foundation, this function integrates\n    cognitive efficiency principles to determine the optimal number of\n    DataLoader workers that balances performance and stability.\n    \n    Returns:\n        Integer number of workers\n    \"\"\"\n    try:\n        # Get number of CPU cores\n        cpu_count = multiprocessing.cpu_count()\n        \n        # Get current system load\n        system_load = 0.5  # Default value\n        try:\n            system_load = psutil.cpu_percent(interval=0.1) / 100.0\n        except:\n            pass\n        \n        # Get memory usage as a factor\n        memory_usage = 0.5  # Default value\n        try:\n            memory_usage = psutil.virtual_memory().percent / 100.0\n        except:\n            pass\n        \n        # Calculate resource factor using polynomial function\n        resource_factor = (1 - system_load) * (1 - 0.8 * memory_usage)\n        \n        # Calculate base workers using the parallel processing penalty formula pattern\n        base_workers = math.ceil(cpu_count * resource_factor)\n        \n        # Add GPU factor if available\n        if torch.cuda.is_available():\n            # When using GPU, we need fewer workers to avoid bottlenecks\n            gpu_count = torch.cuda.device_count()\n            workers = min(base_workers, max(1, 2 * gpu_count))\n        else:\n            # For CPU-only, use calculated base workers\n            workers = base_workers\n        \n        # Apply bounds based on system capabilities\n        workers = min(workers, max(1, cpu_count - 1))  # Leave at least one core free\n        workers = max(1, min(workers, 4))  # Cap at 4 workers for stability\n        \n        logger.info(f\"Calculated optimal DataLoader workers: {workers} (from {cpu_count} cores, load: {system_load:.2f})\")\n        return workers\n        \n    except Exception as e:\n        logger.warning(f\"Error calculating optimal workers: {str(e)}. Using 0 workers for safety.\")\n        return 0  # Safe fallback"
    }
  },
  "constants": {}
}