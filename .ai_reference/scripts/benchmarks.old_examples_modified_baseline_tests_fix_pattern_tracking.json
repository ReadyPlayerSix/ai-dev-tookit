{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\benchmarks.old\\examples\\modified\\baseline_tests\\fix_pattern_tracking.py",
  "imports": [
    {
      "name": "os",
      "line": 7
    },
    {
      "name": "sys",
      "line": 8
    },
    {
      "name": "logging",
      "line": 9
    },
    {
      "name": "isekaizen.core.optimizer.pattern_risk_accuracy_tracker.PatternRiskAccuracyTracker",
      "line": 14
    },
    {
      "name": "isekaizen.pattern.tracking.PatternRecognitionTracker",
      "line": 15
    },
    {
      "name": "isekaizen.utils.pattern_map_utils.translate_pattern_map_to_standard_format",
      "line": 16
    },
    {
      "name": "isekaizen.optimizers.eve.EVENaturalWeights",
      "line": 17
    }
  ],
  "classes": {},
  "functions": {
    "patch_pattern_risk_accuracy_tracker": {
      "start_line": 23,
      "end_line": 106,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "logger.info",
          "line": 104
        },
        {
          "name": "original_init",
          "line": 35
        },
        {
          "name": "str",
          "line": 64
        },
        {
          "name": "logger.info",
          "line": 42
        },
        {
          "name": "hasattr",
          "line": 72
        },
        {
          "name": "distribution.items",
          "line": 50
        },
        {
          "name": "list",
          "line": 80
        },
        {
          "name": "sum",
          "line": 82
        },
        {
          "name": "range",
          "line": 51
        },
        {
          "name": "distribution.keys",
          "line": 80
        },
        {
          "name": "enumerate",
          "line": 89
        },
        {
          "name": "idx_str.isdigit",
          "line": 86
        },
        {
          "name": "int",
          "line": 86
        },
        {
          "name": "zip",
          "line": 89
        },
        {
          "name": "str",
          "line": 52
        },
        {
          "name": "hash",
          "line": 86
        },
        {
          "name": "len",
          "line": 95
        }
      ],
      "docstring": "\n    Fix pattern type lookup in PatternRiskAccuracyTracker to properly assign examples to patterns.\n    ",
      "code_snippet": "logger = logging.getLogger(__name__)\n\ndef patch_pattern_risk_accuracy_tracker():\n    \"\"\"\n    Fix pattern type lookup in PatternRiskAccuracyTracker to properly assign examples to patterns.\n    \"\"\"\n    # Store original methods\n    original_get_pattern_type = PatternRiskAccuracyTracker._get_pattern_type\n    original_init = PatternRiskAccuracyTracker.__init__\n    \n    # New initialization method that properly creates pattern assignments\n    def new_init(self, pattern_map=None):\n        \"\"\"Enhanced initialization with proper pattern assignment creation.\"\"\"\n        # Call original init\n        original_init(self, pattern_map)\n        \n        # Create pattern assignments if they don't exist in the standardized map\n        if (pattern_map and 'format_version' in pattern_map and \n            'pattern_assignments' not in pattern_map and \n            'pattern_distribution' in pattern_map):\n            \n            logger.info(\"Creating pattern assignments from distribution for PatternRiskAccuracyTracker\")\n            \n            # Create a deterministic mapping\n            self.synthetic_pattern_assignments = {}\n            distribution = pattern_map['pattern_distribution']\n            \n            if distribution:\n                idx = 0\n                for pattern_type, count in distribution.items():\n                    for i in range(count):\n                        self.synthetic_pattern_assignments[str(idx)] = {\n                            'pattern_type': pattern_type,\n                            'idx_offset': i  # Keep track of offset within pattern type\n                        }\n                        idx += 1\n    \n    # New pattern type lookup method with better mapping\n    def new_get_pattern_type(self, example_idx: str) -> str:\n        \"\"\"\n        Improved pattern type lookup that uses synthetic assignments when needed.\n        \"\"\"\n        # Convert to string for consistency\n        idx_str = str(example_idx)\n        \n        # First check if the standardized map has direct assignments\n        if (self.pattern_map and 'pattern_assignments' in self.pattern_map and \n            idx_str in self.pattern_map['pattern_assignments']):\n            return self.pattern_map['pattern_assignments'][idx_str]['pattern_type']\n        \n        # Check synthetic assignments\n        if hasattr(self, 'synthetic_pattern_assignments') and idx_str in self.synthetic_pattern_assignments:\n            return self.synthetic_pattern_assignments[idx_str]['pattern_type']\n        \n        # If we have a pattern distribution, use deterministic assignment\n        if self.pattern_map and 'pattern_distribution' in self.pattern_map:\n            distribution = self.pattern_map['pattern_distribution']\n            if distribution:\n                # Create a deterministic mapping\n                pattern_types = list(distribution.keys())\n                pattern_counts = [distribution[pt] for pt in pattern_types]\n                total_samples = sum(pattern_counts)\n                \n                if total_samples > 0:\n                    # Use modulo to deterministically assign each index to a pattern\n                    idx_int = int(idx_str) if idx_str.isdigit() else hash(idx_str) % 50000\n                    cumulative = 0\n                    \n                    for i, (pattern_type, count) in enumerate(zip(pattern_types, pattern_counts)):\n                        cumulative += count\n                        if idx_int < cumulative:\n                            return pattern_type\n                    \n                    # If not found, use round-robin as fallback\n                    return pattern_types[idx_int % len(pattern_types)]\n        \n        # Fallback to default\n        return \"default\"\n    \n    # Apply patches\n    PatternRiskAccuracyTracker.__init__ = new_init\n    PatternRiskAccuracyTracker._get_pattern_type = new_get_pattern_type\n    \n    logger.info(\"PatternRiskAccuracyTracker patched successfully\")\n    \ndef patch_eve_natural_weights():\n    \"\"\"\n    Fix EVE optimizer to properly use the pattern risk tracker."
    },
    "patch_eve_natural_weights": {
      "start_line": 106,
      "end_line": 188,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "logger.info",
          "line": 186
        },
        {
          "name": "original_init",
          "line": 118
        },
        {
          "name": "self.get_dynamic_confidence_threshold",
          "line": 162
        },
        {
          "name": "max",
          "line": 173
        },
        {
          "name": "logger.debug",
          "line": 176
        },
        {
          "name": "hasattr",
          "line": 121
        },
        {
          "name": "hasattr",
          "line": 121
        },
        {
          "name": "self.pattern_tracker.pattern_stats.items",
          "line": 122
        },
        {
          "name": "hasattr",
          "line": 133
        },
        {
          "name": "hasattr",
          "line": 133
        },
        {
          "name": "self.pattern_tracker.get_pattern_risks",
          "line": 134
        },
        {
          "name": "pattern_risks.get",
          "line": 135
        },
        {
          "name": "hasattr",
          "line": 140
        },
        {
          "name": "hasattr",
          "line": 140
        },
        {
          "name": "self.pattern_tracker.get_current_recognition_rates",
          "line": 141
        },
        {
          "name": "recognition_rates.get",
          "line": 142
        },
        {
          "name": "hasattr",
          "line": 147
        },
        {
          "name": "hasattr",
          "line": 147
        },
        {
          "name": "self.pattern_tracker.pattern_stats.get",
          "line": 148
        },
        {
          "name": "pattern_stats.get",
          "line": 149
        },
        {
          "name": "min",
          "line": 173
        },
        {
          "name": "len",
          "line": 151
        },
        {
          "name": "stats.get",
          "line": 125
        },
        {
          "name": "min",
          "line": 126
        },
        {
          "name": "logger.info",
          "line": 127
        },
        {
          "name": "abs",
          "line": 152
        },
        {
          "name": "max",
          "line": 126
        }
      ],
      "docstring": "\n    Fix EVE optimizer to properly use the pattern risk tracker.\n    ",
      "code_snippet": "    logger.info(\"PatternRiskAccuracyTracker patched successfully\")\n    \ndef patch_eve_natural_weights():\n    \"\"\"\n    Fix EVE optimizer to properly use the pattern risk tracker.\n    \"\"\"\n    # Store original methods\n    original_calculate_natural_weight_adjustment = EVENaturalWeights.calculate_natural_weight_adjustment\n    original_init = EVENaturalWeights.__init__\n    \n    # New initialization that ensures pattern risks are properly loaded\n    def new_init(self, *args, **kwargs):\n        \"\"\"Enhanced initialization with better pattern risk handling.\"\"\"\n        # Call original init\n        original_init(self, *args, **kwargs)\n        \n        # If pattern tracker is initialized but has no risks, load them manually\n        if hasattr(self, 'pattern_tracker') and hasattr(self.pattern_tracker, 'pattern_stats'):\n            for pattern_type, stats in self.pattern_tracker.pattern_stats.items():\n                if 'risk' not in stats:\n                    # Initialize with complexity-based risk\n                    complexity = stats.get('complexity_score', 0.5)\n                    stats['risk'] = min(0.9, max(0.1, complexity))\n                    logger.info(f\"Initialized {pattern_type} risk to {stats['risk']:.2f} from complexity {complexity}\")\n    \n    # New natural weight adjustment that properly retrieves risks and accuracies\n    def new_calculate_natural_weight_adjustment(self, pattern_type: str) -> float:\n        \"\"\"Enhanced natural weight adjustment with better risk/accuracy retrieval.\"\"\"\n        # Get pattern risks from the correct source\n        if hasattr(self, 'pattern_tracker') and hasattr(self.pattern_tracker, 'get_pattern_risks'):\n            pattern_risks = self.pattern_tracker.get_pattern_risks()\n            pattern_risk = pattern_risks.get(pattern_type, 0.5)\n        else:\n            pattern_risk = 0.5\n            \n        # Get recognition rates properly\n        if hasattr(self, 'pattern_tracker') and hasattr(self.pattern_tracker, 'get_current_recognition_rates'):\n            recognition_rates = self.pattern_tracker.get_current_recognition_rates()\n            accuracy = recognition_rates.get(pattern_type, 0.5)\n        else:\n            accuracy = 0.5\n            \n        # Calculate stability metrics\n        if hasattr(self, 'pattern_tracker') and hasattr(self.pattern_tracker, 'pattern_stats'):\n            pattern_stats = self.pattern_tracker.pattern_stats.get(pattern_type, {})\n            accuracy_history = pattern_stats.get('accuracy_history', [])\n            \n            if len(accuracy_history) >= 2:\n                stability = 1.0 - abs(accuracy_history[-1] - accuracy_history[-2])\n            else:\n                stability = 0.5\n        else:\n            stability = 0.5\n            \n        # Calculate confidence score (0-1)\n        confidence = accuracy * (1.0 - pattern_risk) * stability\n        \n        # Get dynamic confidence threshold for this pattern\n        confidence_threshold = self.get_dynamic_confidence_threshold(pattern_type)\n        \n        # Calculate natural weight factor based on confidence vs threshold\n        if confidence > confidence_threshold:\n            # Strong performance = strengthen weights\n            weight_factor = 1.0 + (confidence - confidence_threshold)\n        else:\n            # Weak performance = reduce weights\n            weight_factor = confidence / confidence_threshold\n            \n        # Ensure bounds [0.1, 2.0]\n        weight_factor = max(0.1, min(2.0, weight_factor))\n        \n        # Log for debugging\n        logger.debug(f\"Pattern {pattern_type}: risk={pattern_risk:.3f}, accuracy={accuracy:.3f}, \"\n                    f\"stability={stability:.3f}, confidence={confidence:.3f}, threshold={confidence_threshold:.3f}, \"\n                    f\"weight={weight_factor:.3f}\")\n        \n        return weight_factor\n    \n    # Apply patches\n    EVENaturalWeights.__init__ = new_init\n    EVENaturalWeights.calculate_natural_weight_adjustment = new_calculate_natural_weight_adjustment\n    \n    logger.info(\"EVENaturalWeights patched successfully\")\n\ndef patch_pattern_translation():\n    \"\"\"\n    Fix pattern risk calculation in pattern_map_utils to properly scale complexity values."
    },
    "patch_pattern_translation": {
      "start_line": 188,
      "end_line": 245,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "logger.info",
          "line": 243
        },
        {
          "name": "logger.info",
          "line": 198
        },
        {
          "name": "standard_map.get",
          "line": 201
        },
        {
          "name": "complexities.items",
          "line": 203
        },
        {
          "name": "max",
          "line": 225
        },
        {
          "name": "logger.debug",
          "line": 228
        },
        {
          "name": "logger.info",
          "line": 238
        },
        {
          "name": "isinstance",
          "line": 205
        },
        {
          "name": "isinstance",
          "line": 207
        },
        {
          "name": "min",
          "line": 225
        },
        {
          "name": "sum",
          "line": 234
        },
        {
          "name": "len",
          "line": 234
        },
        {
          "name": "float",
          "line": 208
        },
        {
          "name": "pattern_risks.values",
          "line": 234
        },
        {
          "name": "min",
          "line": 222
        }
      ],
      "docstring": "\n    Fix pattern risk calculation in pattern_map_utils to properly scale complexity values.\n    ",
      "code_snippet": "    logger.info(\"EVENaturalWeights patched successfully\")\n\ndef patch_pattern_translation():\n    \"\"\"\n    Fix pattern risk calculation in pattern_map_utils to properly scale complexity values.\n    \"\"\"\n    # Store original method\n    original_calculate_initial_risks = translate_pattern_map_to_standard_format.__globals__['calculate_initial_risks']\n    \n    # New risk calculation method with better scaling\n    def new_calculate_initial_risks(standard_map):\n        \"\"\"Enhanced risk calculation with proper scaling for complex values.\"\"\"\n        logger.info(\"Calculating initial risk values with enhanced scaling\")\n        \n        pattern_risks = {}\n        complexities = standard_map.get('pattern_complexities', {})\n        \n        for pattern_type, complexity_data in complexities.items():\n            # Extract complexity value properly based on format\n            if isinstance(complexity_data, dict) and 'avg_complexity' in complexity_data:\n                complexity = complexity_data['avg_complexity']\n            elif isinstance(complexity_data, (int, float)):\n                complexity = float(complexity_data)\n            else:\n                complexity = 0.5  # Default\n            \n            # Enhanced risk calculation with better scaling\n            # Map complexity values to risk using a more dynamic range\n            if complexity < 0.2:  # Very low complexity (typical for streamlined patterns)\n                # Map 0.1-0.2 to 0.15-0.3 risk range\n                risk = 0.15 + (complexity * 1.5)\n            elif complexity < 1.0:  # Normal complexity range\n                # Map 0.2-1.0 to 0.3-0.6 risk range  \n                risk = 0.3 + ((complexity - 0.2) * 0.375)\n            else:  # High complexity range (for patterns with values > 1.0)\n                # Map 1.0-4.9 to 0.6-0.9 risk range\n                risk = 0.6 + (min(1.0, complexity / 10.0) * 0.3)\n            \n            # Ensure risk stays in reasonable bounds [0.1, 0.9]\n            pattern_risks[pattern_type] = max(0.1, min(0.9, risk))\n            \n            # Log the conversion for debugging\n            logger.debug(f\"Pattern {pattern_type}: complexity {complexity:.2f} -> risk {pattern_risks[pattern_type]:.2f}\")\n        \n        standard_map['pattern_risks'] = pattern_risks\n        \n        # Also calculate overall average risk for the map\n        if pattern_risks:\n            overall_risk = sum(pattern_risks.values()) / len(pattern_risks)\n            if 'pattern_metadata' not in standard_map:\n                standard_map['pattern_metadata'] = {}\n            standard_map['pattern_metadata']['overall_avg_risk'] = overall_risk\n            logger.info(f\"Overall average risk: {overall_risk:.3f}\")\n    \n    # Replace the original method\n    translate_pattern_map_to_standard_format.__globals__['calculate_initial_risks'] = new_calculate_initial_risks\n    \n    logger.info(\"Pattern translation utils patched successfully\")\n\ndef apply_all_patches():\n    \"\"\"Apply all necessary patches to fix pattern tracking issues.\"\"\"\n    logger.info(\"Applying pattern tracking fixes...\")"
    },
    "apply_all_patches": {
      "start_line": 245,
      "end_line": 255,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "logger.info",
          "line": 247
        },
        {
          "name": "patch_pattern_risk_accuracy_tracker",
          "line": 249
        },
        {
          "name": "patch_eve_natural_weights",
          "line": 250
        },
        {
          "name": "patch_pattern_translation",
          "line": 251
        },
        {
          "name": "logger.info",
          "line": 253
        }
      ],
      "docstring": "Apply all necessary patches to fix pattern tracking issues.",
      "code_snippet": "    logger.info(\"Pattern translation utils patched successfully\")\n\ndef apply_all_patches():\n    \"\"\"Apply all necessary patches to fix pattern tracking issues.\"\"\"\n    logger.info(\"Applying pattern tracking fixes...\")\n    \n    patch_pattern_risk_accuracy_tracker()\n    patch_eve_natural_weights()\n    patch_pattern_translation()\n    \n    logger.info(\"All pattern tracking fixes applied successfully\")\n\nif __name__ == \"__main__\":\n    apply_all_patches()"
    }
  },
  "constants": {}
}