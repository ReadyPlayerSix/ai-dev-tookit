{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\optimizers\\eve\\unified_ratio.py",
  "imports": [
    {
      "name": "math",
      "line": 12
    },
    {
      "name": "torch",
      "line": 13
    },
    {
      "name": "typing.List",
      "line": 14
    },
    {
      "name": "typing.Optional",
      "line": 14
    },
    {
      "name": "typing.Dict",
      "line": 14
    },
    {
      "name": "typing.Tuple",
      "line": 14
    },
    {
      "name": "logging",
      "line": 15
    },
    {
      "name": "base.EVENaturalWeights",
      "line": 18
    },
    {
      "name": "lr_boundary.LRBoundaryCalculator",
      "line": 19
    },
    {
      "name": "isekaizen.core.training.ratio_tracker.UnifiedRatioTracker",
      "line": 20
    },
    {
      "name": "isekaizen.core.optimization.equilibrium.PatternEquilibriumTracker",
      "line": 21
    },
    {
      "name": "isekaizen.core.pattern.tracking.PatternTracker",
      "line": 22
    }
  ],
  "classes": {
    "EVEUnifiedRatio": {
      "start_line": 26,
      "end_line": 452,
      "methods": {
        "__init__": {
          "start_line": 48,
          "end_line": 130,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "params"
            },
            {
              "name": "lr"
            },
            {
              "name": "betas"
            },
            {
              "name": "eps"
            },
            {
              "name": "weight_decay"
            },
            {
              "name": "pattern_map"
            },
            {
              "name": "weight_adjustment_range"
            },
            {
              "name": "weight_range_iris"
            },
            {
              "name": "fibonacci_intervals"
            },
            {
              "name": "warmup_epochs"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "....__init__",
              "line": 70
            },
            {
              "name": "UnifiedRatioTracker",
              "line": 73
            },
            {
              "name": "PatternTracker",
              "line": 76
            },
            {
              "name": "PatternEquilibriumTracker",
              "line": 89
            },
            {
              "name": "LRBoundaryCalculator",
              "line": 95
            },
            {
              "name": "kwargs.get",
              "line": 98
            },
            {
              "name": "kwargs.get",
              "line": 99
            },
            {
              "name": "kwargs.get",
              "line": 102
            },
            {
              "name": "kwargs.get",
              "line": 105
            },
            {
              "name": "logger.info",
              "line": 122
            },
            {
              "name": "logger.info",
              "line": 123
            },
            {
              "name": "logger.info",
              "line": 124
            },
            {
              "name": "logger.info",
              "line": 125
            },
            {
              "name": "logger.info",
              "line": 126
            },
            {
              "name": "logger.info",
              "line": 128
            },
            {
              "name": "super",
              "line": 70
            }
          ],
          "docstring": "\n        Initialize the EVE optimizer with unified ratio tracking.\n        \n        Args:\n            params: Iterable of parameters to optimize\n            lr: Learning rate\n            betas: Coefficients for computing running averages\n            eps: Term for numerical stability\n            weight_decay: Weight decay (L2 penalty)\n            pattern_map: Pattern map for pattern-aware optimization\n            weight_adjustment_range: Weight adjustment range ('default', 'narrow', or 'wide')\n            weight_range_iris: Whether to use weight range iris\n            fibonacci_intervals: List of epoch indices for Fibonacci-based checks\n            warmup_epochs: Number of epochs for learning rate warmup\n            **kwargs: Additional arguments\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, \n                weight_decay=0, pattern_map=None, \n                weight_adjustment_range=\"default\", weight_range_iris=False,\n                fibonacci_intervals=None, warmup_epochs=1, **kwargs):\n        \"\"\"\n        Initialize the EVE optimizer with unified ratio tracking.\n        \n        Args:\n            params: Iterable of parameters to optimize\n            lr: Learning rate\n            betas: Coefficients for computing running averages\n            eps: Term for numerical stability\n            weight_decay: Weight decay (L2 penalty)\n            pattern_map: Pattern map for pattern-aware optimization\n            weight_adjustment_range: Weight adjustment range ('default', 'narrow', or 'wide')\n            weight_range_iris: Whether to use weight range iris\n            fibonacci_intervals: List of epoch indices for Fibonacci-based checks\n            warmup_epochs: Number of epochs for learning rate warmup\n            **kwargs: Additional arguments\n        \"\"\"\n        # Store pattern map and initialize parent class\n        self._original_pattern_map = pattern_map\n        super().__init__(params, lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, **kwargs)\n        \n        # Initialize unified ratio tracker\n        self.ratio_tracker = UnifiedRatioTracker()\n        \n        # Initialize pattern mediator\n        self.pattern_tracker = PatternTracker(pattern_map)\n        \n        # Extract pattern info from pattern map\n        pattern_complexities = None\n        pattern_distribution = None\n        \n        if pattern_map:\n            if 'pattern_complexities' in pattern_map:\n                pattern_complexities = pattern_map['pattern_complexities']\n            if 'pattern_distribution' in pattern_map:\n                pattern_distribution = pattern_map['pattern_distribution']\n        \n        # Initialize the equilibrium bounds tracker\n        self.equilibrium_tracker = PatternEquilibriumTracker(\n            pattern_complexities=pattern_complexities,\n            pattern_distribution=pattern_distribution\n        )\n        \n        # Initialize learning rate boundary calculator\n        self.lr_calculator = LRBoundaryCalculator(initial_lr=lr, pattern_map=pattern_map)\n        \n        # Store configuration parameters\n        self.debug_ratios = kwargs.get('debug_ratios', False)\n        self.debug_bounds = kwargs.get('debug_bounds', False)\n        self.warmup_epochs = warmup_epochs\n        self.warmup_initial_lr = lr * 0.2  # Start at 20% of target LR\n        self.lr_check_interval = kwargs.get('lr_check_interval', 10)\n        self.weight_adjustment_range = weight_adjustment_range\n        self.weight_range_iris = weight_range_iris\n        self.use_equilibrium_bounds = kwargs.get('use_equilibrium_bounds', True)\n        \n        # Initialize tracking variables\n        self.epoch = 0\n        self.total_epochs = 100  # Default, will be updated from trainer\n        self.train_acc = 0.0\n        self.test_acc = 0.0\n        self.lr_history = [lr]\n        self.lr_check_counter = 0\n        \n        # Storage for batch data\n        self.last_batch_indices = []\n        self.last_correct_mask = []\n        \n        # Initialize fibonacci intervals if provided\n        self.fibonacci_intervals = fibonacci_intervals\n        \n        logger.info(\"EVEUnifiedRatio initialized with unified risk/accuracy ratio tracking\")\n        logger.info(f\"  Base learning rate: {lr}\")\n        logger.info(f\"  Warmup epochs: {self.warmup_epochs}\")\n        logger.info(f\"  Weight adjustment range: {self.weight_adjustment_range}\")\n        logger.info(f\"  Weight range iris: {'Enabled' if self.weight_range_iris else 'Disabled'}\")\n        if self.use_equilibrium_bounds:\n            logger.info(\"  Using pattern equilibrium bounds for adaptation\")\n    \n    def update_equilibrium_bounds(self, epoch):\n        \"\"\"\n        Update pattern equilibrium statuses based on current accuracies."
        },
        "update_equilibrium_bounds": {
          "start_line": 130,
          "end_line": 162,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "epoch"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.pattern_tracker.get_pattern_accuracies",
              "line": 144
            },
            {
              "name": "self.equilibrium_tracker.update_pattern_statuses",
              "line": 148
            },
            {
              "name": "status_map.items",
              "line": 152
            },
            {
              "name": "pattern_accuracies.get",
              "line": 153
            },
            {
              "name": "self.equilibrium_tracker.get_bounds_for_pattern",
              "line": 154
            },
            {
              "name": "logger.info",
              "line": 155
            },
            {
              "name": "logger.info",
              "line": 156
            }
          ],
          "docstring": "\n        Update pattern equilibrium statuses based on current accuracies.\n        \n        Args:\n            epoch: Current epoch number\n            \n        Returns:\n            Dictionary of pattern statuses relative to equilibrium bounds\n        ",
          "code_snippet": "            logger.info(\"  Using pattern equilibrium bounds for adaptation\")\n    \n    def update_equilibrium_bounds(self, epoch):\n        \"\"\"\n        Update pattern equilibrium statuses based on current accuracies.\n        \n        Args:\n            epoch: Current epoch number\n            \n        Returns:\n            Dictionary of pattern statuses relative to equilibrium bounds\n        \"\"\"\n        if not self.use_equilibrium_bounds:\n            return {}\n        \n        # Get pattern accuracies from tracker\n        pattern_accuracies = self.pattern_tracker.get_pattern_accuracies()\n            \n        if pattern_accuracies:\n            # Update equilibrium bounds with train/test accuracy\n            status_map = self.equilibrium_tracker.update_pattern_statuses(\n                epoch, pattern_accuracies, self.train_acc, self.test_acc)\n            \n            if self.debug_bounds:\n                for pattern, status in status_map.items():\n                    accuracy = pattern_accuracies.get(pattern, 0.0)\n                    min_bound, max_bound = self.equilibrium_tracker.get_bounds_for_pattern(pattern)\n                    logger.info(f\"  {pattern}: accuracy={accuracy:.3f}, bounds=[{min_bound:.3f}, {max_bound:.3f}]\")\n                    logger.info(f\"  {pattern} status: above_min={status['min']}, below_max={status['max']}\")\n            \n            return status_map\n        \n        return {}\n    \n    def calculate_unified_risk_accuracy_ratio(self, pattern_type: str) -> float:\n        \"\"\"\n        Calculate a unified risk/accuracy ratio that directly maps between "
        },
        "calculate_unified_risk_accuracy_ratio": {
          "start_line": 162,
          "end_line": 190,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_type",
              "type": "str"
            }
          ],
          "return_type": "float",
          "calls": [
            {
              "name": "self.pattern_tracker.get_pattern_accuracies",
              "line": 174
            },
            {
              "name": "pattern_accuracies.get",
              "line": 175
            },
            {
              "name": "self.ratio_tracker.calculate_unified_risk_accuracy_ratio",
              "line": 181
            },
            {
              "name": "logger.info",
              "line": 178
            },
            {
              "name": "self.ratio_tracker.pattern_risks.get",
              "line": 185
            },
            {
              "name": "logger.info",
              "line": 186
            }
          ],
          "docstring": "\n        Calculate a unified risk/accuracy ratio that directly maps between \n        training accuracy and risk.\n        \n        Args:\n            pattern_type: Pattern type to calculate ratio for\n            \n        Returns:\n            float: Calculated unified risk/accuracy ratio\n        ",
          "code_snippet": "        return {}\n    \n    def calculate_unified_risk_accuracy_ratio(self, pattern_type: str) -> float:\n        \"\"\"\n        Calculate a unified risk/accuracy ratio that directly maps between \n        training accuracy and risk.\n        \n        Args:\n            pattern_type: Pattern type to calculate ratio for\n            \n        Returns:\n            float: Calculated unified risk/accuracy ratio\n        \"\"\"\n        # Get pattern accuracy from the tracker\n        pattern_accuracies = self.pattern_tracker.get_pattern_accuracies()\n        pattern_accuracy = pattern_accuracies.get(pattern_type, 0.5)\n        \n        if self.debug_ratios:\n            logger.info(f\"  {pattern_type} accuracy: {pattern_accuracy:.3f}\")\n        \n        # Calculate unified ratio\n        ratio = self.ratio_tracker.calculate_unified_risk_accuracy_ratio(\n            pattern_type, pattern_accuracy)\n        \n        if self.debug_ratios:\n            pattern_risk = self.ratio_tracker.pattern_risks.get(pattern_type, 0.5)\n            logger.info(f\"  {pattern_type} derived risk: {pattern_risk:.3f}, unified ratio: {ratio:.3f}\")\n        \n        return ratio\n    \n    def calculate_risk_accuracy_ratios(self, force_refresh=False):\n        \"\"\"\n        Calculate risk/accuracy ratios using the simplified unified approach."
        },
        "calculate_risk_accuracy_ratios": {
          "start_line": 190,
          "end_line": 219,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "force_refresh"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "list",
              "line": 201
            },
            {
              "name": "self.ratio_tracker.store_risk_accuracy_ratios",
              "line": 215
            },
            {
              "name": "....keys",
              "line": 201
            },
            {
              "name": "logger.info",
              "line": 207
            },
            {
              "name": "self.calculate_unified_risk_accuracy_ratio",
              "line": 212
            },
            {
              "name": "self.pattern_tracker.get_pattern_accuracies",
              "line": 201
            }
          ],
          "docstring": "\n        Calculate risk/accuracy ratios using the simplified unified approach.\n        \n        Args:\n            force_refresh: Whether to force recalculation of pattern metrics\n        \n        Returns:\n            Dictionary mapping pattern types to their risk/accuracy ratios\n        ",
          "code_snippet": "        return ratio\n    \n    def calculate_risk_accuracy_ratios(self, force_refresh=False):\n        \"\"\"\n        Calculate risk/accuracy ratios using the simplified unified approach.\n        \n        Args:\n            force_refresh: Whether to force recalculation of pattern metrics\n        \n        Returns:\n            Dictionary mapping pattern types to their risk/accuracy ratios\n        \"\"\"\n        # Get pattern types from tracker\n        pattern_types = list(self.pattern_tracker.get_pattern_accuracies().keys())\n        \n        if not pattern_types:\n            pattern_types = ['structural', 'statistical', 'temporal']\n        \n        if self.debug_ratios or force_refresh:\n            logger.info(f\"Calculating unified risk/accuracy ratios for pattern types: {pattern_types}\")\n        \n        # Calculate ratio for each pattern type\n        risk_acc_ratios = {}\n        for pattern_type in pattern_types:\n            risk_acc_ratios[pattern_type] = self.calculate_unified_risk_accuracy_ratio(pattern_type)\n        \n        # Store in ratio tracker\n        self.ratio_tracker.store_risk_accuracy_ratios(self.epoch, risk_acc_ratios)\n        \n        return risk_acc_ratios\n    \n    def calculate_natural_weight_adjustment(self, pattern_type: str) -> float:\n        \"\"\"\n        Calculate weight adjustment based on equilibrium bounds and/or unified ratio."
        },
        "calculate_natural_weight_adjustment": {
          "start_line": 219,
          "end_line": 298,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_type",
              "type": "str"
            }
          ],
          "return_type": "float",
          "calls": [
            {
              "name": "self.pattern_tracker.get_pattern_accuracies",
              "line": 230
            },
            {
              "name": "pattern_accuracies.get",
              "line": 231
            },
            {
              "name": "self.calculate_unified_risk_accuracy_ratio",
              "line": 285
            },
            {
              "name": "min",
              "line": 289
            },
            {
              "name": "max",
              "line": 291
            },
            {
              "name": "logger.info",
              "line": 294
            },
            {
              "name": "self.equilibrium_tracker.get_patterns_below_min",
              "line": 247
            },
            {
              "name": "self.equilibrium_tracker.get_patterns_above_max",
              "line": 248
            },
            {
              "name": "logger.info",
              "line": 264
            },
            {
              "name": "logger.info",
              "line": 258
            },
            {
              "name": "logger.info",
              "line": 281
            },
            {
              "name": "min",
              "line": 289
            },
            {
              "name": "min",
              "line": 291
            },
            {
              "name": "logger.info",
              "line": 275
            }
          ],
          "docstring": "\n        Calculate weight adjustment based on equilibrium bounds and/or unified ratio.\n        \n        Args:\n            pattern_type: Pattern type to calculate adjustment for\n            \n        Returns:\n            float: Weight adjustment factor\n        ",
          "code_snippet": "        return risk_acc_ratios\n    \n    def calculate_natural_weight_adjustment(self, pattern_type: str) -> float:\n        \"\"\"\n        Calculate weight adjustment based on equilibrium bounds and/or unified ratio.\n        \n        Args:\n            pattern_type: Pattern type to calculate adjustment for\n            \n        Returns:\n            float: Weight adjustment factor\n        \"\"\"\n        # Get pattern accuracy from tracker\n        pattern_accuracies = self.pattern_tracker.get_pattern_accuracies()\n        pattern_accuracy = pattern_accuracies.get(pattern_type, 0.5)\n        \n        # Determine adjustment range based on configuration\n        if self.weight_adjustment_range == \"narrow\":\n            min_adjust = 0.9  # Narrow range\n            max_adjust = 1.1\n        elif self.weight_adjustment_range == \"wide\":\n            min_adjust = 0.8  # Wide range\n            max_adjust = 1.2\n        else:  # default\n            min_adjust = 0.85  # Default range\n            max_adjust = 1.15\n        \n        # If using equilibrium bounds, prioritize that\n        if self.use_equilibrium_bounds:\n            # Check bound statuses\n            is_below_min = pattern_type in self.equilibrium_tracker.get_patterns_below_min()\n            is_above_max = pattern_type in self.equilibrium_tracker.get_patterns_above_max()\n            \n            if is_below_min:\n                # Boost weight for underfitting patterns (high adjustment)\n                \n                # If iris feature is enabled, use more aggressive enhancement for patterns below min bounds\n                if self.weight_range_iris:\n                    # Override max_adjust to use wider range (1.25) instead of default (1.15) or narrow (1.1)\n                    max_adjust = 1.25\n                    if self.debug_bounds:\n                        logger.info(f\"  {pattern_type} using iris mode with wider range for min bound violation\")\n                \n                adjustment = max_adjust\n                \n                if self.debug_bounds:\n                    iris_msg = \" with iris\" if self.weight_range_iris else \"\"\n                    logger.info(f\"  {pattern_type} weight adjustment: {adjustment:.3f}{iris_msg} (below min bound)\")\n                return adjustment\n                \n            elif is_above_max:\n                # Reduce weight for potentially overfitting patterns (low adjustment)\n                \n                # If iris feature is enabled, use more aggressive correction for patterns exceeding max bounds\n                if self.weight_range_iris:\n                    # Override min_adjust to use wide range (0.8) instead of default (0.85) or narrow (0.9)\n                    min_adjust = 0.8\n                    if self.debug_bounds:\n                        logger.info(f\"  {pattern_type} using iris mode with wider range for max bound violation\")\n                \n                adjustment = min_adjust\n                \n                if self.debug_bounds:\n                    iris_msg = \" with iris\" if self.weight_range_iris else \"\"\n                    logger.info(f\"  {pattern_type} weight adjustment: {adjustment:.3f}{iris_msg} (above max bound)\")\n                return adjustment\n        \n        # Fallback to unified ratio approach\n        ratio = self.calculate_unified_risk_accuracy_ratio(pattern_type)\n        \n        # Map ratio to the selected adjustment range\n        if ratio > 1.0:  # High risk relative to accuracy\n            adjustment = min(max_adjust, 1.0 + (max_adjust - 1.0) * min(1.0, ratio - 1.0))\n        else:  # Low risk relative to accuracy\n            adjustment = max(min_adjust, 1.0 - (1.0 - min_adjust) * min(1.0, 1.0 - ratio))\n        \n        if self.debug_bounds:\n            logger.info(f\"  {pattern_type} weight adjustment: {adjustment:.3f} (from ratio: {ratio:.3f})\")\n        \n        return adjustment\n    \n    def step(self, closure=None, pattern_states=None):\n        \"\"\"\n        Enhanced step method with configurable learning rate adaptation sensitivity."
        },
        "step": {
          "start_line": 298,
          "end_line": 366,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "closure"
            },
            {
              "name": "pattern_states"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "....step",
              "line": 316
            },
            {
              "name": "hasattr",
              "line": 310
            },
            {
              "name": "hasattr",
              "line": 310
            },
            {
              "name": "hasattr",
              "line": 326
            },
            {
              "name": "hasattr",
              "line": 326
            },
            {
              "name": "self.pattern_tracker.update_from_batch",
              "line": 313
            },
            {
              "name": "super",
              "line": 316
            },
            {
              "name": "hasattr",
              "line": 331
            },
            {
              "name": "self.lr_history.append",
              "line": 339
            },
            {
              "name": "hasattr",
              "line": 343
            },
            {
              "name": "hasattr",
              "line": 343
            },
            {
              "name": "self.calculate_risk_accuracy_ratios",
              "line": 345
            },
            {
              "name": "self.lr_calculator.calculate_optimal_lr",
              "line": 348
            },
            {
              "name": "len",
              "line": 312
            },
            {
              "name": "len",
              "line": 312
            },
            {
              "name": "self.lr_history.append",
              "line": 358
            },
            {
              "name": "abs",
              "line": 353
            },
            {
              "name": "logger.info",
              "line": 362
            },
            {
              "name": "abs",
              "line": 361
            }
          ],
          "docstring": "\n        Enhanced step method with configurable learning rate adaptation sensitivity.\n        \n        Args:\n            closure: A closure that reevaluates the model and returns the loss\n            pattern_states: Additional pattern states for pattern-aware optimization\n            \n        Returns:\n            float: Loss value\n        ",
          "code_snippet": "        return adjustment\n    \n    def step(self, closure=None, pattern_states=None):\n        \"\"\"\n        Enhanced step method with configurable learning rate adaptation sensitivity.\n        \n        Args:\n            closure: A closure that reevaluates the model and returns the loss\n            pattern_states: Additional pattern states for pattern-aware optimization\n            \n        Returns:\n            float: Loss value\n        \"\"\"\n        # If batch data is available, update pattern tracker\n        if hasattr(self, 'last_batch_indices') and hasattr(self, 'last_correct_mask'):\n            # Update pattern tracker with batch data\n            if len(self.last_batch_indices) > 0 and len(self.last_correct_mask) > 0:\n                self.pattern_tracker.update_from_batch(self.last_batch_indices, self.last_correct_mask)\n        \n        # Call the parent step method\n        loss = super().step(closure=closure, pattern_states=pattern_states)\n        \n        # Only check for learning rate adjustments periodically to balance responsiveness and performance\n        self.lr_check_counter += 1\n        \n        # Check based on configured interval for adaptation sensitivity\n        if self.lr_check_counter % self.lr_check_interval != 0:\n            return loss\n        \n        # If we have training metrics, adjust learning rate\n        if hasattr(self, 'train_acc') and hasattr(self, 'test_acc'):\n            # Get current learning rate\n            current_lr = self.param_groups[0]['lr']\n            \n            # Handle learning rate warmup for the first few epochs\n            if hasattr(self, 'epoch') and self.epoch <= self.warmup_epochs:\n                # Linear warmup from warmup_initial_lr to target LR\n                warmup_factor = self.epoch / self.warmup_epochs\n                new_lr = self.warmup_initial_lr + (self.lr_calculator.initial_lr - self.warmup_initial_lr) * warmup_factor\n                \n                # Apply warmup LR\n                for param_group in self.param_groups:\n                    param_group['lr'] = new_lr\n                self.lr_history.append(new_lr)\n                return loss\n            \n            # Calculate optimal learning rate using the LRBoundaryCalculator\n            if hasattr(self, 'epoch') and hasattr(self, 'total_epochs'):\n                # Get current risk/accuracy ratios for additional context\n                risk_acc_ratios = self.calculate_risk_accuracy_ratios()\n                \n                # Calculate optimal learning rate\n                optimal_lr = self.lr_calculator.calculate_optimal_lr(\n                    current_lr, self.train_acc, self.test_acc, \n                    self.epoch, self.total_epochs, pattern_states)\n                \n                # Apply new learning rate if different - use threshold for sensitivity\n                if abs(optimal_lr - current_lr) / current_lr > 0.005:  # 0.5% change threshold\n                    for param_group in self.param_groups:\n                        param_group['lr'] = optimal_lr\n                    \n                    # Store in history\n                    self.lr_history.append(optimal_lr)\n                    \n                    # Log changes that exceed a higher threshold\n                    if abs(optimal_lr - current_lr) / current_lr > 0.05:  # 5% change for logging\n                        logger.info(f\"Adjusted learning rate from {current_lr:.6f} to {optimal_lr:.6f}\")\n        \n        return loss\n    \n    def update_accuracy_metrics_with_epoch(self, train_acc, test_acc, epoch, total_epochs):\n        \"\"\"\n        Update accuracy metrics with epoch information."
        },
        "update_accuracy_metrics_with_epoch": {
          "start_line": 366,
          "end_line": 422,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "train_acc"
            },
            {
              "name": "test_acc"
            },
            {
              "name": "epoch"
            },
            {
              "name": "total_epochs"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.pattern_tracker.get_pattern_accuracies",
              "line": 385
            },
            {
              "name": "logger.info",
              "line": 409
            },
            {
              "name": "self.calculate_risk_accuracy_ratios",
              "line": 412
            },
            {
              "name": "....update_accuracy_metrics",
              "line": 420
            },
            {
              "name": "self.ratio_tracker.update_pattern_accuracies",
              "line": 387
            },
            {
              "name": "self.update_equilibrium_bounds",
              "line": 391
            },
            {
              "name": "logger.info",
              "line": 417
            },
            {
              "name": "sum",
              "line": 416
            },
            {
              "name": "len",
              "line": 416
            },
            {
              "name": "super",
              "line": 420
            },
            {
              "name": "logger.info",
              "line": 399
            },
            {
              "name": "logger.info",
              "line": 401
            },
            {
              "name": "risk_acc_ratios.values",
              "line": 416
            },
            {
              "name": "bound_statuses.items",
              "line": 395
            },
            {
              "name": "bound_statuses.items",
              "line": 396
            },
            {
              "name": "....join",
              "line": 399
            },
            {
              "name": "....join",
              "line": 401
            }
          ],
          "docstring": "\n        Update accuracy metrics with epoch information.\n        \n        Args:\n            train_acc: Training accuracy (0-100 scale)\n            test_acc: Test accuracy (0-100 scale)\n            epoch: Current epoch number\n            total_epochs: Total number of epochs\n        ",
          "code_snippet": "        return loss\n    \n    def update_accuracy_metrics_with_epoch(self, train_acc, test_acc, epoch, total_epochs):\n        \"\"\"\n        Update accuracy metrics with epoch information.\n        \n        Args:\n            train_acc: Training accuracy (0-100 scale)\n            test_acc: Test accuracy (0-100 scale)\n            epoch: Current epoch number\n            total_epochs: Total number of epochs\n        \"\"\"\n        # Store accuracy metrics\n        self.train_acc = train_acc\n        self.test_acc = test_acc\n        \n        # Store epoch information\n        self.epoch = epoch\n        self.total_epochs = total_epochs\n        \n        # Update ratio tracker with pattern accuracies\n        pattern_accuracies = self.pattern_tracker.get_pattern_accuracies()\n        if pattern_accuracies:\n            self.ratio_tracker.update_pattern_accuracies(pattern_accuracies)\n        \n        # Update equilibrium bounds\n        if self.use_equilibrium_bounds:\n            bound_statuses = self.update_equilibrium_bounds(epoch)\n            \n            if bound_statuses:\n                # Log patterns outside of bounds\n                below_min = [p for p, s in bound_statuses.items() if not s['min']]\n                above_max = [p for p, s in bound_statuses.items() if not s['max']]\n                \n                if below_min:\n                    logger.info(f\"Patterns below minimum bound (underfitting): {', '.join(below_min)}\")\n                if above_max:\n                    logger.info(f\"Patterns above maximum bound (potential overfitting): {', '.join(above_max)}\")\n        \n        # Calculate train/test ratio for monitoring\n        if test_acc > 0:\n            tt_ratio = train_acc / test_acc\n        else:\n            tt_ratio = 2.0  # Default high ratio when test_acc is zero\n                \n        logger.info(f\"Epoch {epoch} - Train/Test ratio: {tt_ratio:.3f}\")\n        \n        # Calculate and store unified risk/accuracy ratios\n        risk_acc_ratios = self.calculate_risk_accuracy_ratios()\n        \n        # Calculate average for logging\n        if risk_acc_ratios:\n            avg_ratio = sum(risk_acc_ratios.values()) / len(risk_acc_ratios)\n            logger.info(f\"Epoch {epoch} - Avg Risk/Accuracy ratio: {avg_ratio:.3f}\")\n        \n        # Update the base accuracy metrics\n        super().update_accuracy_metrics(train_acc, test_acc)\n    \n    def get_pattern_risks(self) -> Dict[str, float]:\n        \"\"\"Get derived pattern risks from the ratio tracker.\"\"\"\n        return self.ratio_tracker.get_pattern_risks()"
        },
        "get_pattern_risks": {
          "start_line": 422,
          "end_line": 426,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "self.ratio_tracker.get_pattern_risks",
              "line": 424
            }
          ],
          "docstring": "Get derived pattern risks from the ratio tracker.",
          "code_snippet": "        super().update_accuracy_metrics(train_acc, test_acc)\n    \n    def get_pattern_risks(self) -> Dict[str, float]:\n        \"\"\"Get derived pattern risks from the ratio tracker.\"\"\"\n        return self.ratio_tracker.get_pattern_risks()\n    \n    def get_pattern_accuracies(self) -> Dict[str, float]:\n        \"\"\"Get pattern accuracies from the pattern tracker.\"\"\"\n        return self.pattern_tracker.get_pattern_accuracies()"
        },
        "get_pattern_accuracies": {
          "start_line": 426,
          "end_line": 430,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "self.pattern_tracker.get_pattern_accuracies",
              "line": 428
            }
          ],
          "docstring": "Get pattern accuracies from the pattern tracker.",
          "code_snippet": "        return self.ratio_tracker.get_pattern_risks()\n    \n    def get_pattern_accuracies(self) -> Dict[str, float]:\n        \"\"\"Get pattern accuracies from the pattern tracker.\"\"\"\n        return self.pattern_tracker.get_pattern_accuracies()\n    \n    def get_learning_rate_history(self):\n        \"\"\"Get history of learning rate changes.\"\"\"\n        return self.lr_history"
        },
        "get_learning_rate_history": {
          "start_line": 430,
          "end_line": 434,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [],
          "docstring": "Get history of learning rate changes.",
          "code_snippet": "        return self.pattern_tracker.get_pattern_accuracies()\n    \n    def get_learning_rate_history(self):\n        \"\"\"Get history of learning rate changes.\"\"\"\n        return self.lr_history\n    \n    def get_bound_status_history(self):\n        \"\"\"Get history of equilibrium bound statuses.\"\"\"\n        if self.use_equilibrium_bounds:"
        },
        "get_bound_status_history": {
          "start_line": 434,
          "end_line": 440,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.equilibrium_tracker.get_bounds_status_history",
              "line": 437
            }
          ],
          "docstring": "Get history of equilibrium bound statuses.",
          "code_snippet": "        return self.lr_history\n    \n    def get_bound_status_history(self):\n        \"\"\"Get history of equilibrium bound statuses.\"\"\"\n        if self.use_equilibrium_bounds:\n            return self.equilibrium_tracker.get_bounds_status_history()\n        return {}\n    \n    def get_bound_adjustment_history(self):\n        \"\"\"Get history of bound adjustment factors (train/test ratios).\"\"\"\n        if self.use_equilibrium_bounds:"
        },
        "get_bound_adjustment_history": {
          "start_line": 440,
          "end_line": 446,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.equilibrium_tracker.get_bounds_adjustment_history",
              "line": 443
            }
          ],
          "docstring": "Get history of bound adjustment factors (train/test ratios).",
          "code_snippet": "        return {}\n    \n    def get_bound_adjustment_history(self):\n        \"\"\"Get history of bound adjustment factors (train/test ratios).\"\"\"\n        if self.use_equilibrium_bounds:\n            return self.equilibrium_tracker.get_bounds_adjustment_history()\n        return {}\n    \n    def get_current_bounds(self):\n        \"\"\"Get current bounds for all patterns with adjustment information.\"\"\"\n        if self.use_equilibrium_bounds:"
        },
        "get_current_bounds": {
          "start_line": 446,
          "end_line": 452,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.equilibrium_tracker.get_current_bounds",
              "line": 449
            }
          ],
          "docstring": "Get current bounds for all patterns with adjustment information.",
          "code_snippet": "        return {}\n    \n    def get_current_bounds(self):\n        \"\"\"Get current bounds for all patterns with adjustment information.\"\"\"\n        if self.use_equilibrium_bounds:\n            return self.equilibrium_tracker.get_current_bounds()\n        return {}"
        }
      },
      "class_variables": [],
      "bases": [
        "EVENaturalWeights"
      ],
      "docstring": "\n    EVE optimizer variant with unified risk/accuracy ratio tracking and equilibrium bounds.\n    \n    This class extends EVENaturalWeights with a unified perspective that treats\n    risk and accuracy as complementary measurements rather than independent\n    variables that need reconciliation. It also adds pattern equilibrium bounds\n    based on complexity and prevalence in the dataset.\n    \n    The implementation follows the mathematical foundation of the isekaiZen framework,\n    with explicit connections to cognitive efficiency and resource allocation principles.\n    \n    Attributes:\n        pattern_map: Pattern map containing pattern information\n        ratio_tracker: Tracker for unified risk/accuracy ratios\n        equilibrium_tracker: Tracker for pattern equilibrium bounds\n        lr_calculator: Calculator for learning rate bounds\n        warmup_epochs: Number of epochs for learning rate warmup\n        weight_adjustment_range: Range for weight adjustments\n        weight_range_iris: Whether to use weight range iris\n    "
    }
  },
  "functions": {},
  "constants": {}
}