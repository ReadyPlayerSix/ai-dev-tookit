{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\benchmarks.old\\models\\src\\utils\\scil\\core.py",
  "imports": [
    {
      "name": "__future__.annotations",
      "line": 4
    },
    {
      "name": "typing.Dict",
      "line": 5
    },
    {
      "name": "typing.List",
      "line": 5
    },
    {
      "name": "typing.Optional",
      "line": 5
    },
    {
      "name": "typing.Any",
      "line": 5
    },
    {
      "name": "dataclasses.dataclass",
      "line": 6
    },
    {
      "name": "enum.Enum",
      "line": 7
    },
    {
      "name": "torch",
      "line": 8
    },
    {
      "name": "logging",
      "line": 9
    },
    {
      "name": "asyncio",
      "line": 10
    },
    {
      "name": "numpy",
      "line": 11
    },
    {
      "name": "datetime.datetime",
      "line": 12
    },
    {
      "name": "memory_pool.MemoryPoolManager",
      "line": 14
    },
    {
      "name": "memory_pool.ChunkSize",
      "line": 14
    },
    {
      "name": "cortex.resource_manager.ResourceManager",
      "line": 15
    },
    {
      "name": "kt_batch_optimizer_v3.KTBatchOptimizer",
      "line": 16
    }
  ],
  "classes": {
    "ComponentType": {
      "start_line": 18,
      "end_line": 23,
      "methods": {},
      "class_variables": [
        {
          "name": "SPECIALIST",
          "line": 19
        },
        {
          "name": "SEMANTIC_PROCESSOR",
          "line": 20
        },
        {
          "name": "PATTERN_ORCHESTRATOR",
          "line": 21
        }
      ],
      "bases": [
        "Enum"
      ]
    },
    "ResourceAllocation": {
      "start_line": 24,
      "end_line": 31,
      "methods": {},
      "class_variables": [],
      "bases": [],
      "docstring": "Resource allocation details for a component"
    },
    "SpinalCordIntegrationLayer": {
      "start_line": 31,
      "end_line": 595,
      "methods": {
        "__init__": {
          "start_line": 34,
          "end_line": 63,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._setup_logging",
              "line": 36
            },
            {
              "name": "KTBatchOptimizer",
              "line": 39
            },
            {
              "name": "ResourceManager",
              "line": 40
            },
            {
              "name": "MemoryPoolManager",
              "line": 41
            },
            {
              "name": "torch.device",
              "line": 42
            },
            {
              "name": "self._setup_logging",
              "line": 60
            },
            {
              "name": "self.logger.info",
              "line": 61
            },
            {
              "name": "torch.cuda.is_available",
              "line": 42
            }
          ],
          "code_snippet": "    \"\"\"Central coordination layer for the Neural Network Cortex System\"\"\"\n    \n    def __init__(self):\n        # Set up logging first\n        self._setup_logging()\n\n        # Initialize core optimization and resource management\n        self.batch_optimizer = KTBatchOptimizer()\n        self.resource_manager = ResourceManager()\n        self.memory_pool = MemoryPoolManager(self.logger)\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self._cuda_warmed_up = False\n        \n        # Component registration and resource tracking\n        self.registered_components: Dict[str, ComponentType] = {}\n        self.active_allocations: Dict[str, ResourceAllocation] = {}\n        self.component_metrics: Dict[str, Dict[str, Any]] = {}\n        \n        # Performance monitoring\n        self.performance_metrics = {\n            \"pattern_translations\": 0,\n            \"resource_utilization\": 0.0,\n            \"avg_processing_time\": 0.0,\n            \"peak_memory_usage\": 0.0,\n            \"registration_times\": []\n        }\n        \n        # Configure logging\n        self._setup_logging()\n        self.logger.info(\"SCIL initialized with ResourceManager and KTBatchOptimizer\")\n        \n    def _setup_logging(self):\n        \"\"\"Configure SCIL-specific logging\"\"\"\n        self.logger = logging.getLogger(__name__)"
        },
        "_setup_logging": {
          "start_line": 63,
          "end_line": 76,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logging.getLogger",
              "line": 65
            },
            {
              "name": "self.logger.setLevel",
              "line": 66
            },
            {
              "name": "logging.StreamHandler",
              "line": 69
            },
            {
              "name": "logging.Formatter",
              "line": 70
            },
            {
              "name": "handler.setFormatter",
              "line": 73
            },
            {
              "name": "self.logger.addHandler",
              "line": 74
            }
          ],
          "docstring": "Configure SCIL-specific logging",
          "code_snippet": "        self.logger.info(\"SCIL initialized with ResourceManager and KTBatchOptimizer\")\n        \n    def _setup_logging(self):\n        \"\"\"Configure SCIL-specific logging\"\"\"\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.INFO)\n        \n        if not self.logger.handlers:\n            handler = logging.StreamHandler()\n            formatter = logging.Formatter(\n                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n            )\n            handler.setFormatter(formatter)\n            self.logger.addHandler(handler)\n\n    async def register_component(self, \n                            component_id: str, \n                            component_type: ComponentType,"
        },
        "_warmup_cuda": {
          "start_line": 146,
          "end_line": 181,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "torch.cuda.is_available",
              "line": 148
            },
            {
              "name": "torch.cuda.empty_cache",
              "line": 172
            },
            {
              "name": "self.logger.info",
              "line": 174
            },
            {
              "name": "torch.zeros",
              "line": 154
            },
            {
              "name": "warmup_tensor.cpu",
              "line": 164
            },
            {
              "name": "warmup_tensor.cuda",
              "line": 165
            },
            {
              "name": "torch.cuda.synchronize",
              "line": 168
            },
            {
              "name": "self.logger.warning",
              "line": 177
            },
            {
              "name": "torch.matmul",
              "line": 158
            },
            {
              "name": "warmup_tensor.view",
              "line": 159
            },
            {
              "name": "warmup_tensor.view",
              "line": 160
            },
            {
              "name": "str",
              "line": 177
            }
          ],
          "docstring": "Enhanced CUDA warmup to reduce initial latency",
          "code_snippet": "            return False\n        \n    def _warmup_cuda(self):\n        \"\"\"Enhanced CUDA warmup to reduce initial latency\"\"\"\n        if torch.cuda.is_available():\n            try:\n                # Series of progressively larger operations\n                sizes = [1000, 5000, 10000, 50000]\n                for size in sizes:\n                    # Allocation warmup\n                    warmup_tensor = torch.zeros(size, device=self.device)\n                    warmup_tensor += 1\n                    \n                    # Basic compute warmup\n                    warmup_tensor = torch.matmul(\n                        warmup_tensor.view(-1, 1), \n                        warmup_tensor.view(1, -1)\n                    )[:100, :100]\n                    \n                    # Memory transfer warmup\n                    warmup_tensor = warmup_tensor.cpu()\n                    warmup_tensor = warmup_tensor.cuda()\n                    \n                    # Ensure operations complete\n                    torch.cuda.synchronize()\n                    \n                # Clear memory\n                del warmup_tensor\n                torch.cuda.empty_cache()\n                \n                self.logger.info(\"Enhanced CUDA warmup complete\")\n                \n            except Exception as e:\n                self.logger.warning(f\"CUDA warmup encountered an error: {str(e)}\")\n                # Continue even if warmup fails\n                pass\n        \n    async def _cleanup_fragmented_memory(self, component_id: str) -> bool:\n        \"\"\"Attempt to clean up fragmented memory for a component\"\"\"\n        try:"
        },
        "get_status": {
          "start_line": 219,
          "end_line": 234,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "self.resource_manager.get_status",
              "line": 221
            },
            {
              "name": "self.memory_pool.get_pool_stats",
              "line": 222
            },
            {
              "name": "self.memory_pool.get_memory_usage",
              "line": 223
            },
            {
              "name": "len",
              "line": 226
            },
            {
              "name": "len",
              "line": 227
            },
            {
              "name": "self.batch_optimizer.optimize_batch_size",
              "line": 232
            }
          ],
          "docstring": "Get current status of the SCIL",
          "code_snippet": "            return False\n\n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"Get current status of the SCIL\"\"\"\n        resource_status = self.resource_manager.get_status()\n        memory_pool_status = self.memory_pool.get_pool_stats()\n        memory_usage = self.memory_pool.get_memory_usage()\n        \n        return {\n            \"registered_components\": len(self.registered_components),\n            \"active_allocations\": len(self.active_allocations),\n            \"performance_metrics\": self.performance_metrics,\n            \"resource_status\": resource_status,\n            \"memory_pool_status\": memory_pool_status,\n            \"memory_usage\": memory_usage,\n            \"optimization_status\": self.batch_optimizer.optimize_batch_size()\n        }\n    \n    def get_batch_optimizer_stats(self) -> Dict[str, Any]:\n        \"\"\"Get statistics from the batch optimizer\"\"\""
        },
        "get_batch_optimizer_stats": {
          "start_line": 235,
          "end_line": 242,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "self.batch_optimizer.optimize_batch_size",
              "line": 237
            },
            {
              "name": "optimization_results.get",
              "line": 239
            },
            {
              "name": "optimization_results.get",
              "line": 240
            }
          ],
          "docstring": "Get statistics from the batch optimizer",
          "code_snippet": "        }\n    \n    def get_batch_optimizer_stats(self) -> Dict[str, Any]:\n        \"\"\"Get statistics from the batch optimizer\"\"\"\n        optimization_results = self.batch_optimizer.optimize_batch_size()\n        return {\n            \"optimal_batch_size\": optimization_results.get(\"optimal_batch_size\", 256),\n            \"peak_efficiency\": optimization_results.get(\"peak_efficiency\", 43.6)\n        }\n            \n    async def _initialize_component_optimization(\n        self,"
        },
        "_calculate_memory_requirement": {
          "start_line": 399,
          "end_line": 425,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "component_type",
              "type": "ComponentType"
            },
            {
              "name": "batch_size",
              "type": "int"
            }
          ],
          "return_type": "float",
          "calls": [
            {
              "name": "....get",
              "line": 406
            }
          ],
          "docstring": "Calculate memory requirement based on component type and batch size",
          "code_snippet": "            )\n\n    def _calculate_memory_requirement(\n        self,\n        component_type: ComponentType,\n        batch_size: int\n    ) -> float:\n        \"\"\"Calculate memory requirement based on component type and batch size\"\"\"\n        # Base memory varies by component type\n        base_memory = {\n            ComponentType.SPECIALIST: 250 * 1024 * 1024,  # 250MB for YOLO model\n            ComponentType.SEMANTIC_PROCESSOR: 100 * 1024 * 1024,  # 100MB\n            ComponentType.PATTERN_ORCHESTRATOR: 50 * 1024 * 1024   # 50MB\n        }.get(component_type, 100 * 1024 * 1024)  # Default 100MB\n\n        # Calculate input tensor memory (following same model as KTBatchOptimizer)\n        if component_type == ComponentType.SPECIALIST:\n            # For specialists (like YOLO), calculate full tensor memory\n            input_memory = batch_size * 3 * 640 * 640 * 4  # (batch, channels, height, width) * bytes_per_float\n            activations_memory = input_memory * 2.5  # Account for intermediate activations\n            total_memory = (base_memory + input_memory + activations_memory) / (1024 * 1024)  # Convert to MB\n        else:\n            # For other components, use simpler memory model\n            memory_per_item = 2 * 1024 * 1024  # 2MB per batch item\n            total_memory = (base_memory + (batch_size * memory_per_item)) / (1024 * 1024)\n\n        return total_memory\n\n    async def _handle_resource_constraint(\n        self,\n        component_id: str,"
        },
        "_determine_chunk_size": {
          "start_line": 521,
          "end_line": 535,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "batch_size"
            }
          ],
          "return_type": "ChunkSize",
          "calls": [],
          "docstring": "Determine appropriate chunk size based on batch size",
          "code_snippet": "                await self._optimize_component_allocation(component_id)\n\n    def _determine_chunk_size(self, batch_size: Optional[int]) -> ChunkSize:\n        \"\"\"Determine appropriate chunk size based on batch size\"\"\"\n        if batch_size is None:\n            return ChunkSize.STANDARD\n            \n        if batch_size <= 32:\n            return ChunkSize.QUICK\n        elif batch_size <= 64:\n            return ChunkSize.STANDARD\n        elif batch_size <= 128:\n            return ChunkSize.BULK\n        else:\n            return ChunkSize.ARCHIVE\n\n    async def _optimize_component_allocation(self, component_id: str):\n        \"\"\"Optimize resource allocation for a component based on performance\"\"\"\n        if component_id in self.active_allocations:"
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "Central coordination layer for the Neural Network Cortex System"
    }
  },
  "functions": {},
  "constants": {}
}