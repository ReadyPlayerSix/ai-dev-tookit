{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\core\\optimizer\\enhanced_risk_assessment.py",
  "imports": [
    {
      "name": "torch",
      "line": 8
    },
    {
      "name": "logging",
      "line": 9
    },
    {
      "name": "time",
      "line": 10
    },
    {
      "name": "random",
      "line": 11
    },
    {
      "name": "math",
      "line": 12
    },
    {
      "name": "numpy",
      "line": 13
    },
    {
      "name": "typing.Union",
      "line": 14
    },
    {
      "name": "typing.Optional",
      "line": 14
    },
    {
      "name": "typing.Dict",
      "line": 14
    },
    {
      "name": "typing.List",
      "line": 14
    },
    {
      "name": "typing.Tuple",
      "line": 14
    },
    {
      "name": "typing.Any",
      "line": 14
    },
    {
      "name": "typing.Set",
      "line": 14
    },
    {
      "name": "enum.Enum",
      "line": 15
    },
    {
      "name": "isekaizen.core.optimizer.risk_aware_optimizer.RiskLevel",
      "line": 18
    },
    {
      "name": "isekaizen.core.optimizer.risk_aware_optimizer.RiskPattern",
      "line": 18
    }
  ],
  "classes": {
    "EnhancedRiskAssessmentTracker": {
      "start_line": 22,
      "end_line": 636,
      "methods": {
        "__init__": {
          "start_line": 31,
          "end_line": 89,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "pattern_map"
            },
            {
              "name": "rpg_manager"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._extract_pattern_types",
              "line": 54
            },
            {
              "name": "logger.info",
              "line": 86
            },
            {
              "name": "logger.info",
              "line": 87
            },
            {
              "name": "....join",
              "line": 87
            }
          ],
          "docstring": "\n        Initialize the enhanced risk assessment tracker.\n        \n        Args:\n            pattern_map: Pattern map containing pattern information\n            rpg_manager: RPG manager instance for risk assessment\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(self, pattern_map=None, rpg_manager=None):\n        \"\"\"\n        Initialize the enhanced risk assessment tracker.\n        \n        Args:\n            pattern_map: Pattern map containing pattern information\n            rpg_manager: RPG manager instance for risk assessment\n        \"\"\"\n        self.pattern_map = pattern_map or {}\n        self.rpg_manager = rpg_manager\n        \n        # Risk thresholds\n        self.risk_thresholds = {\n            RiskLevel.LOW: 0.25,\n            RiskLevel.MEDIUM: 0.5,\n            RiskLevel.HIGH: 0.75,\n            RiskLevel.CRITICAL: 0.9\n        }\n        \n        # Risk patterns discovered during training\n        self.risk_patterns = {}\n        \n        # Pattern type information from pattern map\n        self.pattern_types = self._extract_pattern_types()\n        \n        # Track pattern-specific performance\n        self.pattern_performance = {pattern_type: {\n            'epochs_seen': 0,\n            'loss_history': [],\n            'accuracy_history': [],\n            'efficiency_history': [],\n            'batch_performance': {},\n            'risk_level': RiskLevel.LOW\n        } for pattern_type in self.pattern_types}\n        \n        # Track batch-specific performance\n        self.batch_performance = {}\n        \n        # Risk metrics\n        self.risk_metrics = {\n            \"total_risks_identified\": 0,\n            \"risks_by_level\": {level.value: 0 for level in RiskLevel},\n            \"risks_by_pattern_type\": {},\n            \"mitigated_risks\": 0,\n            \"mitigation_success_rate\": 0.0,\n            \"average_risk_factor\": 0.0\n        }\n        \n        # Track epochs with performance issues\n        self.unstable_epochs = 0\n        self.current_epoch = 0\n        \n        # Track risk history\n        self.risk_history = []\n        \n        logger.info(\"Enhanced risk assessment tracker initialized\")\n        logger.info(f\"Found pattern types in map: {', '.join(self.pattern_types)}\")\n    \n    def _extract_pattern_types(self) -> Set[str]:\n        \"\"\"\n        Extract pattern types from pattern map."
        },
        "_extract_pattern_types": {
          "start_line": 89,
          "end_line": 112,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "set",
              "line": 96
            },
            {
              "name": "set",
              "line": 101
            },
            {
              "name": "pattern_distribution.keys",
              "line": 101
            },
            {
              "name": "set",
              "line": 104
            },
            {
              "name": "pattern_distribution.keys",
              "line": 104
            }
          ],
          "docstring": "\n        Extract pattern types from pattern map.\n        \n        Returns:\n            Set of pattern types\n        ",
          "code_snippet": "        logger.info(f\"Found pattern types in map: {', '.join(self.pattern_types)}\")\n    \n    def _extract_pattern_types(self) -> Set[str]:\n        \"\"\"\n        Extract pattern types from pattern map.\n        \n        Returns:\n            Set of pattern types\n        \"\"\"\n        pattern_types = set()\n        \n        # Extract from pattern distribution if available\n        if 'pattern_map' in self.pattern_map and 'pattern_distribution' in self.pattern_map['pattern_map']:\n            pattern_distribution = self.pattern_map['pattern_map']['pattern_distribution']\n            pattern_types = set(pattern_distribution.keys())\n        elif 'pattern_distribution' in self.pattern_map:\n            pattern_distribution = self.pattern_map['pattern_distribution']\n            pattern_types = set(pattern_distribution.keys())\n        \n        # Fall back to default types if none found\n        if not pattern_types:\n            pattern_types = {\"structure\", \"relationship\", \"intensity\", \"dominance\", \"temporal\"}\n            \n        return pattern_types\n    \n    def _get_pattern_type(self, example_idx: Union[int, str]) -> Optional[str]:\n        \"\"\"\n        Get pattern type for an example from the pattern map."
        },
        "_get_pattern_type": {
          "start_line": 112,
          "end_line": 133,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "example_idx"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "str",
              "line": 123
            },
            {
              "name": "....get",
              "line": 129
            }
          ],
          "docstring": "\n        Get pattern type for an example from the pattern map.\n        \n        Args:\n            example_idx: Example index\n            \n        Returns:\n            Pattern type or None if not found\n        ",
          "code_snippet": "        return pattern_types\n    \n    def _get_pattern_type(self, example_idx: Union[int, str]) -> Optional[str]:\n        \"\"\"\n        Get pattern type for an example from the pattern map.\n        \n        Args:\n            example_idx: Example index\n            \n        Returns:\n            Pattern type or None if not found\n        \"\"\"\n        # Convert to string for lookup\n        idx_str = str(example_idx)\n        \n        # Look up in pattern map\n        if 'pattern_map' in self.pattern_map and 'pattern_map' in self.pattern_map['pattern_map']:\n            pattern_data = self.pattern_map['pattern_map']['pattern_map']\n            if idx_str in pattern_data:\n                return pattern_data[idx_str].get('pattern_type')\n        \n        return None\n    \n    def _calculate_epoch_efficiency(self, epoch_metrics: Dict[str, Any]) -> float:\n        \"\"\"\n        Calculate epoch efficiency based on training metrics."
        },
        "_calculate_epoch_efficiency": {
          "start_line": 133,
          "end_line": 178,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "epoch_metrics"
            }
          ],
          "return_type": "float",
          "calls": [
            {
              "name": "epoch_metrics.get",
              "line": 146
            },
            {
              "name": "epoch_metrics.get",
              "line": 147
            },
            {
              "name": "epoch_metrics.get",
              "line": 148
            },
            {
              "name": "epoch_metrics.get",
              "line": 149
            },
            {
              "name": "min",
              "line": 152
            },
            {
              "name": "max",
              "line": 156
            },
            {
              "name": "min",
              "line": 176
            },
            {
              "name": "float",
              "line": 147
            },
            {
              "name": "max",
              "line": 176
            },
            {
              "name": "min",
              "line": 156
            },
            {
              "name": "math.exp",
              "line": 166
            }
          ],
          "docstring": "\n        Calculate epoch efficiency based on training metrics.\n        \n        Higher values indicate more efficient training.\n        \n        Args:\n            epoch_metrics: Dictionary with epoch metrics (loss, accuracy, time, etc.)\n            \n        Returns:\n            Efficiency score from 0.0 to 1.0\n        ",
          "code_snippet": "        return None\n    \n    def _calculate_epoch_efficiency(self, epoch_metrics: Dict[str, Any]) -> float:\n        \"\"\"\n        Calculate epoch efficiency based on training metrics.\n        \n        Higher values indicate more efficient training.\n        \n        Args:\n            epoch_metrics: Dictionary with epoch metrics (loss, accuracy, time, etc.)\n            \n        Returns:\n            Efficiency score from 0.0 to 1.0\n        \"\"\"\n        # Extract metrics\n        accuracy = epoch_metrics.get('accuracy', 0.0)\n        loss = epoch_metrics.get('loss', float('inf'))\n        time_taken = epoch_metrics.get('time', 0.0)\n        batch_size = epoch_metrics.get('batch_size', 0)\n        \n        # Normalized accuracy (0-1)\n        norm_accuracy = min(1.0, accuracy / 100.0)\n        \n        # Normalized loss (closer to 0 is better)\n        # Map typical loss range (0-5) to 0-1 range, invert so higher is better\n        norm_loss = max(0.0, 1.0 - min(1.0, loss / 5.0))\n        \n        # Time efficiency\n        # For an adaptive framework, this needs to account for total epochs\n        # and batch size - larger batches process more examples per unit time\n        time_efficiency = 1.0\n        if time_taken > 0 and batch_size > 0:\n            # Process more examples per second = more efficient\n            examples_per_second = batch_size / time_taken\n            # Map to 0-1 range using sigmoid (adjust scale factor for your hardware)\n            time_efficiency = 1.0 / (1.0 + math.exp(-0.01 * examples_per_second + 2.0))\n        \n        # Calculate overall efficiency\n        # Weighted combination of metrics - adjust weights based on importance\n        efficiency = (\n            norm_accuracy * 0.4 +  # Accuracy is important\n            norm_loss * 0.3 +      # Loss is important\n            time_efficiency * 0.3  # Time efficiency matters too\n        )\n        \n        return min(1.0, max(0.0, efficiency))\n    \n    def update_with_epoch_metrics(self, epoch_metrics: Dict[str, Any],\n                                batch_indices: List[int],\n                                current_epoch: int):"
        },
        "update_with_epoch_metrics": {
          "start_line": 178,
          "end_line": 254,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "epoch_metrics"
            },
            {
              "name": "batch_indices"
            },
            {
              "name": "current_epoch",
              "type": "int"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._calculate_epoch_efficiency",
              "line": 192
            },
            {
              "name": "epoch_metrics.get",
              "line": 195
            },
            {
              "name": "....append",
              "line": 208
            },
            {
              "name": "....append",
              "line": 209
            },
            {
              "name": "....append",
              "line": 210
            },
            {
              "name": "self._detect_instability",
              "line": 213
            },
            {
              "name": "set",
              "line": 220
            },
            {
              "name": "self._update_risk_levels",
              "line": 245
            },
            {
              "name": "self._generate_risk_patterns",
              "line": 248
            },
            {
              "name": "epoch_metrics.get",
              "line": 209
            },
            {
              "name": "epoch_metrics.get",
              "line": 210
            },
            {
              "name": "max",
              "line": 217
            },
            {
              "name": "self._get_pattern_type",
              "line": 222
            },
            {
              "name": "self._log_risk_assessment",
              "line": 252
            },
            {
              "name": "batch_pattern_types.add",
              "line": 224
            },
            {
              "name": "....append",
              "line": 230
            },
            {
              "name": "....append",
              "line": 231
            },
            {
              "name": "....append",
              "line": 232
            },
            {
              "name": "....append",
              "line": 241
            },
            {
              "name": "epoch_metrics.get",
              "line": 230
            },
            {
              "name": "epoch_metrics.get",
              "line": 231
            }
          ],
          "docstring": "\n        Update risk assessment based on epoch metrics.\n        \n        Args:\n            epoch_metrics: Dictionary with epoch metrics\n            batch_indices: Indices of examples in the batch\n            current_epoch: Current epoch number\n        ",
          "code_snippet": "        return min(1.0, max(0.0, efficiency))\n    \n    def update_with_epoch_metrics(self, epoch_metrics: Dict[str, Any],\n                                batch_indices: List[int],\n                                current_epoch: int):\n        \"\"\"\n        Update risk assessment based on epoch metrics.\n        \n        Args:\n            epoch_metrics: Dictionary with epoch metrics\n            batch_indices: Indices of examples in the batch\n            current_epoch: Current epoch number\n        \"\"\"\n        self.current_epoch = current_epoch\n        \n        # Calculate epoch efficiency\n        efficiency = self._calculate_epoch_efficiency(epoch_metrics)\n        \n        # Extract batch size\n        batch_size = epoch_metrics.get('batch_size', 0)\n        \n        # Track batch performance\n        if batch_size not in self.batch_performance:\n            self.batch_performance[batch_size] = {\n                'efficiency_history': [],\n                'loss_history': [],\n                'accuracy_history': [],\n                'risk_level': RiskLevel.LOW,\n                'risk_factor': 0.2  # Default low risk\n            }\n        \n        # Update batch performance\n        self.batch_performance[batch_size]['efficiency_history'].append(efficiency)\n        self.batch_performance[batch_size]['loss_history'].append(epoch_metrics.get('loss', 0.0))\n        self.batch_performance[batch_size]['accuracy_history'].append(epoch_metrics.get('accuracy', 0.0))\n        \n        # Detect instability in training\n        is_unstable = self._detect_instability(epoch_metrics)\n        if is_unstable:\n            self.unstable_epochs += 1\n        else:\n            self.unstable_epochs = max(0, self.unstable_epochs - 1)\n        \n        # Get pattern types in this batch\n        batch_pattern_types = set()\n        for idx in batch_indices:\n            pattern_type = self._get_pattern_type(idx)\n            if pattern_type:\n                batch_pattern_types.add(pattern_type)\n        \n        # Update pattern-specific performance for patterns in this batch\n        for pattern_type in batch_pattern_types:\n            if pattern_type in self.pattern_performance:\n                self.pattern_performance[pattern_type]['epochs_seen'] += 1\n                self.pattern_performance[pattern_type]['loss_history'].append(epoch_metrics.get('loss', 0.0))\n                self.pattern_performance[pattern_type]['accuracy_history'].append(epoch_metrics.get('accuracy', 0.0))\n                self.pattern_performance[pattern_type]['efficiency_history'].append(efficiency)\n                \n                # Track batch performance for this pattern\n                if batch_size not in self.pattern_performance[pattern_type]['batch_performance']:\n                    self.pattern_performance[pattern_type]['batch_performance'][batch_size] = {\n                        'efficiency_history': [],\n                        'count': 0\n                    }\n                \n                self.pattern_performance[pattern_type]['batch_performance'][batch_size]['efficiency_history'].append(efficiency)\n                self.pattern_performance[pattern_type]['batch_performance'][batch_size]['count'] += 1\n        \n        # Update risk levels based on performance\n        self._update_risk_levels(batch_size, efficiency, is_unstable, batch_pattern_types)\n        \n        # Generate risk patterns based on current understanding\n        self._generate_risk_patterns(batch_size, batch_indices, batch_pattern_types, is_unstable)\n        \n        # Log current risk assessment\n        if current_epoch % 5 == 0:  # Log every 5 epochs to avoid spam\n            self._log_risk_assessment()\n    \n    def _detect_instability(self, epoch_metrics: Dict[str, Any]) -> bool:\n        \"\"\"\n        Detect instability in training based on metrics."
        },
        "_detect_instability": {
          "start_line": 254,
          "end_line": 290,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "epoch_metrics"
            }
          ],
          "return_type": "bool",
          "calls": [
            {
              "name": "epoch_metrics.get",
              "line": 265
            },
            {
              "name": "epoch_metrics.get",
              "line": 266
            },
            {
              "name": "len",
              "line": 277
            },
            {
              "name": "....get",
              "line": 278
            },
            {
              "name": "len",
              "line": 283
            },
            {
              "name": "....get",
              "line": 284
            }
          ],
          "docstring": "\n        Detect instability in training based on metrics.\n        \n        Args:\n            epoch_metrics: Dictionary with epoch metrics\n            \n        Returns:\n            True if training appears unstable, False otherwise\n        ",
          "code_snippet": "            self._log_risk_assessment()\n    \n    def _detect_instability(self, epoch_metrics: Dict[str, Any]) -> bool:\n        \"\"\"\n        Detect instability in training based on metrics.\n        \n        Args:\n            epoch_metrics: Dictionary with epoch metrics\n            \n        Returns:\n            True if training appears unstable, False otherwise\n        \"\"\"\n        # Extract metrics\n        loss = epoch_metrics.get('loss', 0.0)\n        accuracy = epoch_metrics.get('accuracy', 0.0)\n        \n        # Check for high loss\n        if loss > 3.0:\n            return True\n        \n        # Check for very low accuracy after a few epochs\n        if self.current_epoch > 3 and accuracy < 20.0:\n            return True\n        \n        # Check for loss increase if we have history\n        if len(self.risk_history) > 0:\n            prev_loss = self.risk_history[-1].get('loss', 0.0)\n            if loss > prev_loss * 1.2:  # 20% increase in loss\n                return True\n        \n        # Check for accuracy decrease if we have history\n        if len(self.risk_history) > 0:\n            prev_accuracy = self.risk_history[-1].get('accuracy', 0.0)\n            if accuracy < prev_accuracy * 0.95:  # 5% decrease in accuracy\n                return True\n        \n        return False\n    \n    def _update_risk_levels(self, batch_size: int, efficiency: float,\n                          is_unstable: bool, batch_pattern_types: Set[str]):\n        \"\"\""
        },
        "_update_risk_levels": {
          "start_line": 290,
          "end_line": 326,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "batch_size",
              "type": "int"
            },
            {
              "name": "efficiency",
              "type": "float"
            },
            {
              "name": "is_unstable",
              "type": "bool"
            },
            {
              "name": "batch_pattern_types"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._determine_risk_level",
              "line": 302
            },
            {
              "name": "min",
              "line": 308
            },
            {
              "name": "self._determine_risk_level",
              "line": 323
            },
            {
              "name": "sum",
              "line": 320
            },
            {
              "name": "len",
              "line": 320
            }
          ],
          "docstring": "\n        Update risk levels based on current performance.\n        \n        Args:\n            batch_size: Batch size\n            efficiency: Training efficiency\n            is_unstable: Whether training is unstable\n            batch_pattern_types: Pattern types in batch\n        ",
          "code_snippet": "        return False\n    \n    def _update_risk_levels(self, batch_size: int, efficiency: float,\n                          is_unstable: bool, batch_pattern_types: Set[str]):\n        \"\"\"\n        Update risk levels based on current performance.\n        \n        Args:\n            batch_size: Batch size\n            efficiency: Training efficiency\n            is_unstable: Whether training is unstable\n            batch_pattern_types: Pattern types in batch\n        \"\"\"\n        # Update batch risk level\n        batch_risk = self._determine_risk_level(efficiency, is_unstable)\n        self.batch_performance[batch_size]['risk_level'] = batch_risk\n        \n        # Calculate risk factor (0-1 range)\n        risk_factor = 1.0 - efficiency\n        if is_unstable:\n            risk_factor = min(1.0, risk_factor + 0.3)  # Increase risk for instability\n            \n        self.batch_performance[batch_size]['risk_factor'] = risk_factor\n        \n        # Update pattern risk levels\n        for pattern_type in batch_pattern_types:\n            if pattern_type in self.pattern_performance:\n                pattern_stats = self.pattern_performance[pattern_type]\n                \n                # Only update if we have enough observations\n                if pattern_stats['epochs_seen'] >= 3:\n                    # Calculate average efficiency\n                    avg_efficiency = sum(pattern_stats['efficiency_history']) / len(pattern_stats['efficiency_history'])\n                    \n                    # Update risk level\n                    pattern_risk = self._determine_risk_level(avg_efficiency, is_unstable)\n                    pattern_stats['risk_level'] = pattern_risk\n    \n    def _determine_risk_level(self, efficiency: float, is_unstable: bool) -> RiskLevel:\n        \"\"\"\n        Determine risk level based on efficiency and stability."
        },
        "_determine_risk_level": {
          "start_line": 326,
          "end_line": 354,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "efficiency",
              "type": "float"
            },
            {
              "name": "is_unstable",
              "type": "bool"
            }
          ],
          "return_type": "RiskLevel",
          "calls": [
            {
              "name": "min",
              "line": 342
            }
          ],
          "docstring": "\n        Determine risk level based on efficiency and stability.\n        \n        Args:\n            efficiency: Training efficiency (0-1)\n            is_unstable: Whether training is unstable\n            \n        Returns:\n            Risk level\n        ",
          "code_snippet": "                    pattern_stats['risk_level'] = pattern_risk\n    \n    def _determine_risk_level(self, efficiency: float, is_unstable: bool) -> RiskLevel:\n        \"\"\"\n        Determine risk level based on efficiency and stability.\n        \n        Args:\n            efficiency: Training efficiency (0-1)\n            is_unstable: Whether training is unstable\n            \n        Returns:\n            Risk level\n        \"\"\"\n        # Start with risk based on efficiency\n        risk_factor = 1.0 - efficiency\n        \n        # Increase risk for instability\n        if is_unstable:\n            risk_factor = min(1.0, risk_factor + 0.3)\n        \n        # Determine risk level based on risk factor\n        if risk_factor >= self.risk_thresholds[RiskLevel.CRITICAL]:\n            return RiskLevel.CRITICAL\n        elif risk_factor >= self.risk_thresholds[RiskLevel.HIGH]:\n            return RiskLevel.HIGH\n        elif risk_factor >= self.risk_thresholds[RiskLevel.MEDIUM]:\n            return RiskLevel.MEDIUM\n        else:\n            return RiskLevel.LOW\n    \n    def _generate_risk_patterns(self, batch_size: int, batch_indices: List[int],\n                              batch_pattern_types: Set[str], is_unstable: bool):\n        \"\"\""
        },
        "_generate_risk_patterns": {
          "start_line": 354,
          "end_line": 437,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "batch_size",
              "type": "int"
            },
            {
              "name": "batch_indices"
            },
            {
              "name": "batch_pattern_types"
            },
            {
              "name": "is_unstable",
              "type": "bool"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.batch_performance.get",
              "line": 370
            },
            {
              "name": "batch_info.get",
              "line": 371
            },
            {
              "name": "self._get_pattern_type",
              "line": 377
            },
            {
              "name": "batch_info.get",
              "line": 393
            },
            {
              "name": "self._determine_risk_level_from_factor",
              "line": 397
            },
            {
              "name": "str",
              "line": 400
            },
            {
              "name": "RiskPattern",
              "line": 402
            },
            {
              "name": "sum",
              "line": 389
            },
            {
              "name": "min",
              "line": 389
            },
            {
              "name": "len",
              "line": 389
            }
          ],
          "docstring": "\n        Generate risk patterns based on observed performance.\n        \n        Args:\n            batch_size: Batch size\n            batch_indices: Indices of examples in the batch\n            batch_pattern_types: Pattern types in batch\n            is_unstable: Whether training is unstable\n        ",
          "code_snippet": "            return RiskLevel.LOW\n    \n    def _generate_risk_patterns(self, batch_size: int, batch_indices: List[int],\n                              batch_pattern_types: Set[str], is_unstable: bool):\n        \"\"\"\n        Generate risk patterns based on observed performance.\n        \n        Args:\n            batch_size: Batch size\n            batch_indices: Indices of examples in the batch\n            batch_pattern_types: Pattern types in batch\n            is_unstable: Whether training is unstable\n        \"\"\"\n        # Only generate risk patterns if:\n        # 1. We have observed instability, or\n        # 2. Efficiency is low (high risk), or\n        # 3. We have enough history to generate meaningful patterns\n        \n        batch_info = self.batch_performance.get(batch_size, {})\n        batch_risk = batch_info.get('risk_level', RiskLevel.LOW)\n        \n        # Check if risk is high enough to generate patterns\n        if is_unstable or batch_risk in [RiskLevel.HIGH, RiskLevel.CRITICAL] or self.current_epoch >= 5:\n            # Create risk patterns for each relevant index\n            for idx in batch_indices:\n                pattern_type = self._get_pattern_type(idx)\n                if not pattern_type:\n                    continue\n                \n                # Calculate risk factor based on pattern type and batch performance\n                pattern_risk_factor = 0.0\n                \n                if pattern_type in self.pattern_performance:\n                    pattern_stats = self.pattern_performance[pattern_type]\n                    # Average the last few efficiency values if available\n                    history = pattern_stats['efficiency_history']\n                    if history:\n                        avg_efficiency = sum(history[-3:]) / min(3, len(history))\n                        pattern_risk_factor = 1.0 - avg_efficiency\n                \n                # Risk factor is weighted mix of pattern risk and batch risk\n                batch_risk_factor = batch_info.get('risk_factor', 0.2)\n                risk_factor = pattern_risk_factor * 0.7 + batch_risk_factor * 0.3\n                \n                # Determine risk level\n                risk_level = self._determine_risk_level_from_factor(risk_factor)\n                \n                # Generate risk pattern\n                pattern_id = str(idx)\n                if pattern_id not in self.risk_patterns:\n                    risk_pattern = RiskPattern(\n                        pattern_type=pattern_type,\n                        risk_level=risk_level,\n                        risk_factor=risk_factor,\n                        pattern_id=pattern_id\n                    )\n                    \n                    # Add to registry\n                    self.risk_patterns[pattern_id] = risk_pattern\n                    \n                    # Update metrics\n                    self.risk_metrics[\"total_risks_identified\"] += 1\n                    self.risk_metrics[\"risks_by_level\"][risk_level.value] += 1\n                    \n                    if pattern_type not in self.risk_metrics[\"risks_by_pattern_type\"]:\n                        self.risk_metrics[\"risks_by_pattern_type\"][pattern_type] = 0\n                    self.risk_metrics[\"risks_by_pattern_type\"][pattern_type] += 1\n                else:\n                    # Update existing risk pattern\n                    risk_pattern = self.risk_patterns[pattern_id]\n                    \n                    # Update risk level if it has changed\n                    if risk_pattern.risk_level != risk_level:\n                        # Decrement old count\n                        self.risk_metrics[\"risks_by_level\"][risk_pattern.risk_level.value] -= 1\n                        # Update risk level\n                        risk_pattern.risk_level = risk_level\n                        # Increment new count\n                        self.risk_metrics[\"risks_by_level\"][risk_level.value] += 1\n                    \n                    # Update risk factor with exponential moving average\n                    # This keeps risk assessment responsive but stable\n                    alpha = 0.2  # Smoothing factor\n                    risk_pattern.risk_factor = alpha * risk_factor + (1 - alpha) * risk_pattern.risk_factor\n    \n    def _determine_risk_level_from_factor(self, risk_factor: float) -> RiskLevel:\n        \"\"\"\n        Determine risk level from risk factor."
        },
        "_determine_risk_level_from_factor": {
          "start_line": 437,
          "end_line": 456,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "risk_factor",
              "type": "float"
            }
          ],
          "return_type": "RiskLevel",
          "calls": [],
          "docstring": "\n        Determine risk level from risk factor.\n        \n        Args:\n            risk_factor: Risk factor (0-1)\n            \n        Returns:\n            Risk level\n        ",
          "code_snippet": "                    risk_pattern.risk_factor = alpha * risk_factor + (1 - alpha) * risk_pattern.risk_factor\n    \n    def _determine_risk_level_from_factor(self, risk_factor: float) -> RiskLevel:\n        \"\"\"\n        Determine risk level from risk factor.\n        \n        Args:\n            risk_factor: Risk factor (0-1)\n            \n        Returns:\n            Risk level\n        \"\"\"\n        if risk_factor >= self.risk_thresholds[RiskLevel.CRITICAL]:\n            return RiskLevel.CRITICAL\n        elif risk_factor >= self.risk_thresholds[RiskLevel.HIGH]:\n            return RiskLevel.HIGH\n        elif risk_factor >= self.risk_thresholds[RiskLevel.MEDIUM]:\n            return RiskLevel.MEDIUM\n        else:\n            return RiskLevel.LOW\n    \n    def _log_risk_assessment(self):\n        \"\"\"Log current risk assessment\"\"\"\n        logger.info(f\"Risk assessment - Epoch {self.current_epoch}\")"
        },
        "_log_risk_assessment": {
          "start_line": 456,
          "end_line": 480,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logger.info",
              "line": 458
            },
            {
              "name": "logger.info",
              "line": 459
            },
            {
              "name": "logger.info",
              "line": 463
            },
            {
              "name": "level_counts.items",
              "line": 464
            },
            {
              "name": "logger.info",
              "line": 475
            },
            {
              "name": "self.batch_performance.items",
              "line": 476
            },
            {
              "name": "logger.info",
              "line": 465
            },
            {
              "name": "logger.info",
              "line": 470
            },
            {
              "name": "type_counts.items",
              "line": 471
            },
            {
              "name": "perf.get",
              "line": 477
            },
            {
              "name": "logger.info",
              "line": 478
            },
            {
              "name": "logger.info",
              "line": 472
            }
          ],
          "docstring": "Log current risk assessment",
          "code_snippet": "            return RiskLevel.LOW\n    \n    def _log_risk_assessment(self):\n        \"\"\"Log current risk assessment\"\"\"\n        logger.info(f\"Risk assessment - Epoch {self.current_epoch}\")\n        logger.info(f\"Total risks identified: {self.risk_metrics['total_risks_identified']}\")\n        \n        # Log risk levels\n        level_counts = self.risk_metrics[\"risks_by_level\"]\n        logger.info(\"Risk levels:\")\n        for level, count in level_counts.items():\n            logger.info(f\"  {level}: {count}\")\n        \n        # Log pattern type risks\n        type_counts = self.risk_metrics[\"risks_by_pattern_type\"]\n        if type_counts:\n            logger.info(\"Risks by pattern type:\")\n            for pattern_type, count in type_counts.items():\n                logger.info(f\"  {pattern_type}: {count}\")\n        \n        # Log batch performance\n        logger.info(\"Batch performance:\")\n        for batch_size, perf in self.batch_performance.items():\n            risk_level = perf.get('risk_level', RiskLevel.LOW)\n            logger.info(f\"  Batch {batch_size}: {risk_level.value} risk\")\n    \n    def assess_risk(self, batch_indices, batch_size):\n        \"\"\"\n        Assess risk for a batch of examples."
        },
        "assess_risk": {
          "start_line": 480,
          "end_line": 539,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "batch_indices"
            },
            {
              "name": "batch_size"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "str",
              "line": 513
            },
            {
              "name": "....get",
              "line": 504
            },
            {
              "name": "batch_risk_patterns.append",
              "line": 516
            },
            {
              "name": "....append",
              "line": 517
            },
            {
              "name": "....append",
              "line": 518
            },
            {
              "name": "....append",
              "line": 519
            },
            {
              "name": "....get",
              "line": 525
            }
          ],
          "docstring": "\n        Assess risk for a batch of examples.\n        \n        Args:\n            batch_indices: Indices of examples in the batch\n            batch_size: Current batch size\n            \n        Returns:\n            Dictionary with risk assessment results\n        ",
          "code_snippet": "            logger.info(f\"  Batch {batch_size}: {risk_level.value} risk\")\n    \n    def assess_risk(self, batch_indices, batch_size):\n        \"\"\"\n        Assess risk for a batch of examples.\n        \n        Args:\n            batch_indices: Indices of examples in the batch\n            batch_size: Current batch size\n            \n        Returns:\n            Dictionary with risk assessment results\n        \"\"\"\n        # Initialize risk assessment\n        risk_assessment = {\n            \"highest_risk_level\": RiskLevel.LOW,\n            \"risk_factors\": [],\n            \"recommended_batch_size\": batch_size,\n            \"risky_indices\": [],\n            \"patterns_by_risk\": {level.value: [] for level in RiskLevel}\n        }\n        \n        # No risk patterns yet\n        if not self.risk_patterns:\n            # Check if batch size has observed performance issues\n            if batch_size in self.batch_performance:\n                batch_risk = self.batch_performance[batch_size].get('risk_level', RiskLevel.LOW)\n                if batch_risk != RiskLevel.LOW:\n                    risk_assessment[\"highest_risk_level\"] = batch_risk\n            \n            return risk_assessment\n        \n        # Identify risk patterns in batch\n        batch_risk_patterns = []\n        for idx in batch_indices:\n            pattern_id = str(idx)\n            if pattern_id in self.risk_patterns:\n                risk_pattern = self.risk_patterns[pattern_id]\n                batch_risk_patterns.append(risk_pattern)\n                risk_assessment[\"risk_factors\"].append(risk_pattern.risk_factor)\n                risk_assessment[\"risky_indices\"].append(idx)\n                risk_assessment[\"patterns_by_risk\"][risk_pattern.risk_level.value].append(idx)\n        \n        # If no risk patterns found, check batch size risk\n        if not batch_risk_patterns:\n            # Check if batch size has observed performance issues\n            if batch_size in self.batch_performance:\n                batch_risk = self.batch_performance[batch_size].get('risk_level', RiskLevel.LOW)\n                if batch_risk != RiskLevel.LOW:\n                    risk_assessment[\"highest_risk_level\"] = batch_risk\n            \n            return risk_assessment\n        \n        # Find highest risk level in batch\n        for risk_level in [RiskLevel.CRITICAL, RiskLevel.HIGH, RiskLevel.MEDIUM, RiskLevel.LOW]:\n            if risk_assessment[\"patterns_by_risk\"][risk_level.value]:\n                risk_assessment[\"highest_risk_level\"] = risk_level\n                break\n        \n        return risk_assessment\n    \n    def calculate_mitigation_adjustment(self, batch_size, risk_level):\n        \"\"\"\n        Calculate batch size adjustment for risk mitigation."
        },
        "calculate_mitigation_adjustment": {
          "start_line": 539,
          "end_line": 568,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "batch_size"
            },
            {
              "name": "risk_level"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "mitigation_factors.get",
              "line": 559
            },
            {
              "name": "max",
              "line": 565
            },
            {
              "name": "int",
              "line": 565
            }
          ],
          "docstring": "\n        Calculate batch size adjustment for risk mitigation.\n        \n        Args:\n            batch_size: Current batch size\n            risk_level: Current risk level\n            \n        Returns:\n            Adjusted batch size\n        ",
          "code_snippet": "        return risk_assessment\n    \n    def calculate_mitigation_adjustment(self, batch_size, risk_level):\n        \"\"\"\n        Calculate batch size adjustment for risk mitigation.\n        \n        Args:\n            batch_size: Current batch size\n            risk_level: Current risk level\n            \n        Returns:\n            Adjusted batch size\n        \"\"\"\n        # Default mitigation strategies\n        mitigation_factors = {\n            RiskLevel.LOW: 0.95,\n            RiskLevel.MEDIUM: 0.85,\n            RiskLevel.HIGH: 0.7,\n            RiskLevel.CRITICAL: 0.5\n        }\n        \n        # Apply risk mitigation factor\n        factor = mitigation_factors.get(risk_level, 0.9)\n        \n        # Adjust factor based on batch size - be more conservative with smaller batches\n        if batch_size < 64:\n            factor = (factor + 1) / 2  # Less aggressive reduction\n        \n        adjusted_batch = max(4, int(batch_size * factor))\n        return adjusted_batch\n    \n    def update_mitigation_results(self, assessment, success):\n        \"\"\"\n        Update mitigation results based on training success."
        },
        "update_mitigation_results": {
          "start_line": 568,
          "end_line": 591,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "assessment"
            },
            {
              "name": "success"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "str",
              "line": 578
            },
            {
              "name": "....update_mitigation",
              "line": 580
            }
          ],
          "docstring": "\n        Update mitigation results based on training success.\n        \n        Args:\n            assessment: Risk assessment from assess_risk\n            success: Whether training was successful (e.g., loss decreased)\n        ",
          "code_snippet": "        return adjusted_batch\n    \n    def update_mitigation_results(self, assessment, success):\n        \"\"\"\n        Update mitigation results based on training success.\n        \n        Args:\n            assessment: Risk assessment from assess_risk\n            success: Whether training was successful (e.g., loss decreased)\n        \"\"\"\n        # Update risk patterns with mitigation results\n        for idx in assessment[\"risky_indices\"]:\n            pattern_id = str(idx)\n            if pattern_id in self.risk_patterns:\n                self.risk_patterns[pattern_id].update_mitigation(success)\n        \n        # Update metrics\n        if assessment[\"risky_indices\"]:\n            if success:\n                self.risk_metrics[\"mitigated_risks\"] += 1\n            \n            total_attempts = self.risk_metrics[\"total_risks_identified\"]\n            if total_attempts > 0:\n                self.risk_metrics[\"mitigation_success_rate\"] = self.risk_metrics[\"mitigated_risks\"] / total_attempts\n    \n    def get_current_risk_metrics(self):\n        \"\"\"\n        Get current risk metrics."
        },
        "get_current_risk_metrics": {
          "start_line": 591,
          "end_line": 606,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "sum",
              "line": 600
            },
            {
              "name": "len",
              "line": 602
            },
            {
              "name": "self.risk_patterns.values",
              "line": 601
            }
          ],
          "docstring": "\n        Get current risk metrics.\n        \n        Returns:\n            Dictionary with current risk metrics\n        ",
          "code_snippet": "                self.risk_metrics[\"mitigation_success_rate\"] = self.risk_metrics[\"mitigated_risks\"] / total_attempts\n    \n    def get_current_risk_metrics(self):\n        \"\"\"\n        Get current risk metrics.\n        \n        Returns:\n            Dictionary with current risk metrics\n        \"\"\"\n        # Calculate average risk factor across all patterns\n        if self.risk_patterns:\n            self.risk_metrics[\"average_risk_factor\"] = sum(\n                pattern.risk_factor for pattern in self.risk_patterns.values()\n            ) / len(self.risk_patterns)\n        \n        return self.risk_metrics\n    \n    def snapshot_risk_metrics(self):\n        \"\"\"\n        Take a snapshot of current risk metrics for history tracking."
        },
        "snapshot_risk_metrics": {
          "start_line": 606,
          "end_line": 636,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.risk_history.append",
              "line": 633
            },
            {
              "name": "time.time",
              "line": 614
            },
            {
              "name": "....copy",
              "line": 615
            },
            {
              "name": "str",
              "line": 625
            },
            {
              "name": "self.get_current_risk_metrics",
              "line": 615
            },
            {
              "name": "self.pattern_performance.items",
              "line": 622
            },
            {
              "name": "self.batch_performance.items",
              "line": 629
            },
            {
              "name": "sum",
              "line": 621
            },
            {
              "name": "max",
              "line": 621
            },
            {
              "name": "sum",
              "line": 628
            },
            {
              "name": "max",
              "line": 628
            },
            {
              "name": "len",
              "line": 621
            },
            {
              "name": "len",
              "line": 628
            }
          ],
          "docstring": "\n        Take a snapshot of current risk metrics for history tracking.\n        \n        Returns:\n            Snapshot of current risk metrics\n        ",
          "code_snippet": "        return self.risk_metrics\n    \n    def snapshot_risk_metrics(self):\n        \"\"\"\n        Take a snapshot of current risk metrics for history tracking.\n        \n        Returns:\n            Snapshot of current risk metrics\n        \"\"\"\n        snapshot = {\n            \"timestamp\": time.time(),\n            \"metrics\": self.get_current_risk_metrics().copy(),\n            \"unstable_epochs\": self.unstable_epochs,\n            \"pattern_performance\": {\n                pattern_type: {\n                    \"epochs_seen\": stats[\"epochs_seen\"],\n                    \"risk_level\": stats[\"risk_level\"].value,\n                    \"avg_efficiency\": sum(stats[\"efficiency_history\"]) / max(1, len(stats[\"efficiency_history\"]))\n                } for pattern_type, stats in self.pattern_performance.items() if stats[\"epochs_seen\"] > 0\n            },\n            \"batch_performance\": {\n                str(batch_size): {\n                    \"risk_level\": perf[\"risk_level\"].value,\n                    \"risk_factor\": perf[\"risk_factor\"],\n                    \"avg_efficiency\": sum(perf[\"efficiency_history\"]) / max(1, len(perf[\"efficiency_history\"]))\n                } for batch_size, perf in self.batch_performance.items()\n            }\n        }\n        \n        self.risk_history.append(snapshot)\n        return snapshot"
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "\n    Enhanced risk assessment tracker that builds risk patterns dynamically during training.\n    \n    Unlike the original tracker, this one doesn't try to extract risk patterns from\n    the pattern map upfront. Instead, it observes training performance to identify\n    which patterns and batch sizes are associated with risks.\n    "
    }
  },
  "functions": {},
  "constants": {}
}