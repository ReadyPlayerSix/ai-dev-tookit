{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\models\\swapping\\model_swap_manager.py",
  "imports": [
    {
      "name": "logging",
      "line": 11
    },
    {
      "name": "torch",
      "line": 12
    },
    {
      "name": "isekaizen.models.architectures.create_model",
      "line": 13
    },
    {
      "name": "traceback",
      "line": 168
    }
  ],
  "classes": {
    "ModelSwapManager": {
      "start_line": 18,
      "end_line": 322,
      "methods": {
        "__init__": {
          "start_line": 34,
          "end_line": 59,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "device"
            },
            {
              "name": "model_config"
            },
            {
              "name": "current_model_type"
            }
          ],
          "return_type": null,
          "calls": [],
          "docstring": "\n        Initialize the ModelSwapManager.\n        \n        Args:\n            device (torch.device): Device on which the model is running\n            model_config (dict, optional): Configuration parameters for model creation.\n                                        Defaults to None.\n            current_model_type (str, optional): Initial model architecture type.\n                                            Defaults to \"resnet18\".\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(self, device, model_config=None, current_model_type=\"resnet18\"):\n        \"\"\"\n        Initialize the ModelSwapManager.\n        \n        Args:\n            device (torch.device): Device on which the model is running\n            model_config (dict, optional): Configuration parameters for model creation.\n                                        Defaults to None.\n            current_model_type (str, optional): Initial model architecture type.\n                                            Defaults to \"resnet18\".\n        \"\"\"\n        self.device = device\n        self.model_config = model_config or {\n            'use_pretrained': False,\n            'num_classes': 10,\n            'input_channels': 3,\n            'input_size': 32\n        }\n        self.current_model_type = current_model_type\n        self.model_swaps = []\n        self.swap_thresholds = {\n            'accuracy_stagnation': 0.005,  # Less than 0.5% improvement\n            'consecutive_epochs': 3,       # For 3 consecutive epochs\n            'min_epoch': 5                 # Don't swap before epoch 5\n        }\n    \n    def swap_model(self, model, optimizer_class, optimizer_kwargs, \n                  scheduler_class=None, scheduler_kwargs=None, new_model_type=None):"
        },
        "swap_model": {
          "start_line": 60,
          "end_line": 173,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "model"
            },
            {
              "name": "optimizer_class"
            },
            {
              "name": "optimizer_kwargs"
            },
            {
              "name": "scheduler_class"
            },
            {
              "name": "scheduler_kwargs"
            },
            {
              "name": "new_model_type"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logger.info",
              "line": 92
            },
            {
              "name": "self._get_next_model_size",
              "line": 83
            },
            {
              "name": "logger.warning",
              "line": 89
            },
            {
              "name": "create_model",
              "line": 96
            },
            {
              "name": "new_model.to",
              "line": 105
            },
            {
              "name": "model.state_dict",
              "line": 108
            },
            {
              "name": "new_model.state_dict",
              "line": 109
            },
            {
              "name": "old_state.items",
              "line": 113
            },
            {
              "name": "len",
              "line": 118
            },
            {
              "name": "len",
              "line": 119
            },
            {
              "name": "logger.info",
              "line": 122
            },
            {
              "name": "self.model_swaps.append",
              "line": 152
            },
            {
              "name": "self._get_model_size_category",
              "line": 84
            },
            {
              "name": "new_state.update",
              "line": 126
            },
            {
              "name": "new_model.load_state_dict",
              "line": 127
            },
            {
              "name": "logger.info",
              "line": 128
            },
            {
              "name": "logger.warning",
              "line": 130
            },
            {
              "name": "optimizer_class",
              "line": 139
            },
            {
              "name": "logger.info",
              "line": 140
            },
            {
              "name": "logger.error",
              "line": 167
            },
            {
              "name": "logger.error",
              "line": 169
            },
            {
              "name": "self.model_config.get",
              "line": 98
            },
            {
              "name": "self.model_config.get",
              "line": 99
            },
            {
              "name": "self.model_config.get",
              "line": 100
            },
            {
              "name": "self.model_config.get",
              "line": 101
            },
            {
              "name": "hasattr",
              "line": 135
            },
            {
              "name": "new_model.parameters",
              "line": 139
            },
            {
              "name": "scheduler_class",
              "line": 145
            },
            {
              "name": "logger.info",
              "line": 146
            },
            {
              "name": "traceback.format_exc",
              "line": 169
            },
            {
              "name": "str",
              "line": 167
            }
          ],
          "docstring": "\n        Swap the current model for a different architecture and transfer weights where possible.\n        \n        This method creates a new model with the specified architecture, transfers\n        compatible weights from the current model, and creates a new optimizer\n        and scheduler.\n        \n        Args:\n            model (torch.nn.Module): Current model\n            optimizer_class: Optimizer class to use for the new model\n            optimizer_kwargs (dict): Keyword arguments for the optimizer\n            scheduler_class: Scheduler class to use for the new model\n            scheduler_kwargs (dict): Keyword arguments for the scheduler\n            new_model_type (str, optional): Type of the new model. If None, an appropriate\n                                        model is selected based on the current model.\n            \n        Returns:\n            tuple: (new_model, new_optimizer, new_scheduler, success_flag)\n        ",
          "code_snippet": "        }\n    \n    def swap_model(self, model, optimizer_class, optimizer_kwargs, \n                  scheduler_class=None, scheduler_kwargs=None, new_model_type=None):\n        \"\"\"\n        Swap the current model for a different architecture and transfer weights where possible.\n        \n        This method creates a new model with the specified architecture, transfers\n        compatible weights from the current model, and creates a new optimizer\n        and scheduler.\n        \n        Args:\n            model (torch.nn.Module): Current model\n            optimizer_class: Optimizer class to use for the new model\n            optimizer_kwargs (dict): Keyword arguments for the optimizer\n            scheduler_class: Scheduler class to use for the new model\n            scheduler_kwargs (dict): Keyword arguments for the scheduler\n            new_model_type (str, optional): Type of the new model. If None, an appropriate\n                                        model is selected based on the current model.\n            \n        Returns:\n            tuple: (new_model, new_optimizer, new_scheduler, success_flag)\n        \"\"\"\n        # If no new model type specified, select based on current model\n        if new_model_type is None:\n            new_model_type = self._get_next_model_size(\n                self._get_model_size_category(self.current_model_type),\n                larger=True\n            )\n        \n        if new_model_type == self.current_model_type:\n            logger.warning(f\"Model is already {new_model_type}, no need to swap\")\n            return model, None, None, False\n        \n        logger.info(f\"Swapping model from {self.current_model_type} to {new_model_type}\")\n        \n        try:\n            # Create new model\n            new_model = create_model(\n                model_type=new_model_type,\n                use_pretrained=self.model_config.get('use_pretrained', False),\n                num_classes=self.model_config.get('num_classes', 10),\n                input_channels=self.model_config.get('input_channels', 3),\n                input_size=self.model_config.get('input_size', 32)\n            )\n            \n            # Move to the same device\n            new_model = new_model.to(self.device)\n            \n            # Extract state from old model\n            old_state = model.state_dict()\n            new_state = new_model.state_dict()\n            \n            # Try to transfer weights for layers with matching names and shapes\n            compatible_layers = {}\n            for name, param in old_state.items():\n                if name in new_state and new_state[name].shape == param.shape:\n                    compatible_layers[name] = param\n            \n            # Log transfer statistics\n            total_params = len(new_state)\n            transferred_params = len(compatible_layers)\n            transfer_percentage = (transferred_params / total_params) * 100\n            \n            logger.info(f\"Transferring weights: {transferred_params}/{total_params} layers ({transfer_percentage:.1f}% of parameters)\")\n            \n            # Load compatible weights\n            if compatible_layers:\n                new_state.update(compatible_layers)\n                new_model.load_state_dict(new_state)\n                logger.info(f\"Successfully transferred weights to {new_model_type}\")\n            else:\n                logger.warning(\"No compatible layers found for weight transfer\")\n            \n            # Create a new optimizer with the new model parameters\n            if optimizer_class:\n                # Use current optimizer's learning rate if not specified\n                if 'lr' not in optimizer_kwargs and hasattr(optimizer_kwargs, 'param_groups'):\n                    optimizer_kwargs['lr'] = optimizer_kwargs.param_groups[0]['lr']\n                    \n                # Create a new optimizer\n                new_optimizer = optimizer_class(new_model.parameters(), **optimizer_kwargs)\n                logger.info(\"Created new optimizer for the swapped model\")\n                \n                # Create a new scheduler if needed\n                new_scheduler = None\n                if scheduler_class and scheduler_kwargs:\n                    new_scheduler = scheduler_class(new_optimizer, **scheduler_kwargs)\n                    logger.info(\"Created new scheduler for the swapped model\")\n            else:\n                new_optimizer = None\n                new_scheduler = None\n            \n            # Record the swap\n            self.model_swaps.append({\n                'old_model': self.current_model_type,\n                'new_model': new_model_type,\n                'transferred_params': transferred_params,\n                'total_params': total_params,\n                'transfer_percentage': transfer_percentage\n            })\n            \n            # Update current model type\n            self.current_model_type = new_model_type\n            \n            return new_model, new_optimizer, new_scheduler, True\n            \n        except Exception as e:\n            # Log the error\n            logger.error(f\"Error swapping model: {str(e)}\")\n            import traceback\n            logger.error(traceback.format_exc())\n            \n            return model, None, None, False\n    \n    def check_and_swap_model(self, history, model, optimizer_class, optimizer_kwargs, \n                           scheduler_class=None, scheduler_kwargs=None, current_epoch=0):\n        \"\"\""
        },
        "check_and_swap_model": {
          "start_line": 173,
          "end_line": 264,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "history"
            },
            {
              "name": "model"
            },
            {
              "name": "optimizer_class"
            },
            {
              "name": "optimizer_kwargs"
            },
            {
              "name": "scheduler_class"
            },
            {
              "name": "scheduler_kwargs"
            },
            {
              "name": "current_epoch"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "history.get",
              "line": 198
            },
            {
              "name": "all",
              "line": 211
            },
            {
              "name": "len",
              "line": 202
            },
            {
              "name": "logger.debug",
              "line": 203
            },
            {
              "name": "logger.warning",
              "line": 215
            },
            {
              "name": "logger.info",
              "line": 219
            },
            {
              "name": "logger.info",
              "line": 220
            },
            {
              "name": "self._get_model_size_category",
              "line": 223
            },
            {
              "name": "logger.info",
              "line": 250
            },
            {
              "name": "self.swap_model",
              "line": 253
            },
            {
              "name": "self._get_next_model_size",
              "line": 229
            },
            {
              "name": "len",
              "line": 203
            },
            {
              "name": "....join",
              "line": 219
            }
          ],
          "docstring": "\n        Check if model swapping is needed based on training history and performance.\n        \n        This method analyzes the training history to determine if model swapping\n        is needed, and performs the swap if necessary.\n        \n        Args:\n            history (dict): Training history dictionary\n            model (torch.nn.Module): Current model\n            optimizer_class: Optimizer class to use for the new model\n            optimizer_kwargs (dict): Keyword arguments for the optimizer\n            scheduler_class: Scheduler class to use for the new model\n            scheduler_kwargs (dict): Keyword arguments for the scheduler\n            current_epoch (int, optional): Current training epoch. Defaults to 0.\n            \n        Returns:\n            tuple: (new_model, new_optimizer, new_scheduler, swapped_flag)\n        ",
          "code_snippet": "            return model, None, None, False\n    \n    def check_and_swap_model(self, history, model, optimizer_class, optimizer_kwargs, \n                           scheduler_class=None, scheduler_kwargs=None, current_epoch=0):\n        \"\"\"\n        Check if model swapping is needed based on training history and performance.\n        \n        This method analyzes the training history to determine if model swapping\n        is needed, and performs the swap if necessary.\n        \n        Args:\n            history (dict): Training history dictionary\n            model (torch.nn.Module): Current model\n            optimizer_class: Optimizer class to use for the new model\n            optimizer_kwargs (dict): Keyword arguments for the optimizer\n            scheduler_class: Scheduler class to use for the new model\n            scheduler_kwargs (dict): Keyword arguments for the scheduler\n            current_epoch (int, optional): Current training epoch. Defaults to 0.\n            \n        Returns:\n            tuple: (new_model, new_optimizer, new_scheduler, swapped_flag)\n        \"\"\"\n        # Don't swap too early in training\n        if current_epoch < self.swap_thresholds['min_epoch']:\n            return model, None, None, False\n        \n        # Check for accuracy stagnation over the last few epochs\n        val_acc = history.get('val_acc', [])\n        \n        # Need enough epochs of validation data to make a decision\n        required_epochs = self.swap_thresholds['consecutive_epochs'] + 1\n        if len(val_acc) < required_epochs:\n            logger.debug(f\"Not enough validation data for model swap decision: {len(val_acc)}/{required_epochs}\")\n            return model, None, None, False\n            \n        # Get the last few validation accuracies\n        recent_acc = val_acc[-self.swap_thresholds['consecutive_epochs']:]\n        previous_acc = val_acc[-(self.swap_thresholds['consecutive_epochs'] + 1)]\n        \n        # Check if all recent accuracies show minimal improvement\n        stagnant = all(acc - previous_acc < self.swap_thresholds['accuracy_stagnation'] \n                     for acc in recent_acc)\n        \n        if stagnant:\n            logger.warning(f\"Detected accuracy stagnation over {self.swap_thresholds['consecutive_epochs']} epochs\")\n            \n            # Format accuracy values for logging\n            acc_strings = [f\"{acc:.2f}%\" for acc in recent_acc]\n            logger.info(f\"Recent accuracies: {', '.join(acc_strings)}\")\n            logger.info(f\"Previous accuracy: {previous_acc:.2f}%\")\n            \n            # Decide which model to swap to based on current model and training progress\n            current_model_size = self._get_model_size_category(self.current_model_type)\n            \n            # Determine whether to go larger or smaller\n            current_acc = recent_acc[-1]\n            if current_acc < 70.0:\n                # For lower accuracy, prefer a larger model for more capacity\n                new_model_type = self._get_next_model_size(current_model_size, larger=True)\n            else:\n                # For good accuracy but stalled, try a different architecture family\n                if 'resnet' in self.current_model_type:\n                    if current_acc > 85.0:\n                        # Try more efficient architecture if accuracy is already good\n                        new_model_type = \"mobilenet_v2\"\n                    else:\n                        # Try more powerful architecture\n                        new_model_type = \"vgg16\"\n                elif 'vgg' in self.current_model_type:\n                    # VGG is large, try a more efficient architecture\n                    new_model_type = \"resnet34\"\n                elif 'mobilenet' in self.current_model_type:\n                    # MobileNet is efficient but may lack capacity\n                    new_model_type = \"resnet34\"\n                else:\n                    # Default fallback\n                    new_model_type = \"resnet50\"\n            \n            # Log the decision\n            logger.info(f\"Current accuracy: {current_acc:.2f}%, proposing model swap: {self.current_model_type} \u2192 {new_model_type}\")\n            \n            # Perform the swap\n            return self.swap_model(\n                model=model,\n                optimizer_class=optimizer_class,\n                optimizer_kwargs=optimizer_kwargs,\n                scheduler_class=scheduler_class,\n                scheduler_kwargs=scheduler_kwargs,\n                new_model_type=new_model_type\n            )\n        \n        return model, None, None, False\n        \n    def _get_model_size_category(self, model_type):\n        \"\"\"\n        Determine the size category of a model."
        },
        "_get_model_size_category": {
          "start_line": 264,
          "end_line": 283,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "model_type"
            }
          ],
          "return_type": null,
          "calls": [],
          "docstring": "\n        Determine the size category of a model.\n        \n        Args:\n            model_type (str): Model type to categorize\n            \n        Returns:\n            str: Size category ('small', 'medium', or 'large')\n        ",
          "code_snippet": "        return model, None, None, False\n        \n    def _get_model_size_category(self, model_type):\n        \"\"\"\n        Determine the size category of a model.\n        \n        Args:\n            model_type (str): Model type to categorize\n            \n        Returns:\n            str: Size category ('small', 'medium', or 'large')\n        \"\"\"\n        if 'resnet18' in model_type or 'mobilenet' in model_type:\n            return 'small'\n        elif 'resnet34' in model_type or 'resnet50' in model_type:\n            return 'medium'\n        elif 'vgg' in model_type or 'resnet101' in model_type or 'resnet152' in model_type:\n            return 'large'\n        else:\n            return 'medium'  # Default\n            \n    def _get_next_model_size(self, current_size, larger=True):\n        \"\"\"\n        Get the next model size based on the current size."
        },
        "_get_next_model_size": {
          "start_line": 283,
          "end_line": 322,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "current_size"
            },
            {
              "name": "larger"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "....get",
              "line": 311
            },
            {
              "name": "size_to_model.get",
              "line": 320
            },
            {
              "name": "size_progression.get",
              "line": 311
            }
          ],
          "docstring": "\n        Get the next model size based on the current size.\n        \n        Args:\n            current_size (str): Current model size category\n            larger (bool, optional): Whether to get a larger or smaller model.\n                                  Defaults to True.\n                                  \n        Returns:\n            str: Model type for the next size category\n        ",
          "code_snippet": "            return 'medium'  # Default\n            \n    def _get_next_model_size(self, current_size, larger=True):\n        \"\"\"\n        Get the next model size based on the current size.\n        \n        Args:\n            current_size (str): Current model size category\n            larger (bool, optional): Whether to get a larger or smaller model.\n                                  Defaults to True.\n                                  \n        Returns:\n            str: Model type for the next size category\n        \"\"\"\n        size_progression = {\n            'small': {\n                'larger': 'medium',\n                'smaller': 'small'  # Can't go smaller than small\n            },\n            'medium': {\n                'larger': 'large',\n                'smaller': 'small'\n            },\n            'large': {\n                'larger': 'large',  # Can't go larger than large\n                'smaller': 'medium'\n            }\n        }\n        \n        direction = 'larger' if larger else 'smaller'\n        next_size = size_progression.get(current_size, {}).get(direction, current_size)\n        \n        # Map size to actual model\n        size_to_model = {\n            'small': 'resnet18',\n            'medium': 'resnet34',\n            'large': 'resnet50'\n        }\n        \n        return size_to_model.get(next_size, 'resnet34')"
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "\n    Handles model architecture swapping during training.\n    \n    This class manages the dynamic swapping of model architectures during training\n    based on performance metrics. It handles the creation of new models, weight\n    transfer, and optimizer/scheduler updates.\n    \n    Attributes:\n        device (torch.device): Device on which the model is running\n        model_config (dict): Configuration parameters for model creation\n        current_model_type (str): Current model architecture type\n        model_swaps (list): History of model swaps performed\n        swap_thresholds (dict): Thresholds for triggering model swaps\n    "
    }
  },
  "functions": {},
  "constants": {}
}