{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\semantic\\optimizer.py",
  "imports": [
    {
      "name": "os",
      "line": 9
    },
    {
      "name": "time",
      "line": 10
    },
    {
      "name": "json",
      "line": 11
    },
    {
      "name": "random",
      "line": 12
    },
    {
      "name": "logging",
      "line": 13
    },
    {
      "name": "numpy",
      "line": 14
    },
    {
      "name": "torch",
      "line": 15
    },
    {
      "name": "optimizers.isekaizen.IsekaiZenOptimizer",
      "line": 16
    }
  ],
  "classes": {
    "TopographicalAwareIsekaiZen": {
      "start_line": 20,
      "end_line": 414,
      "methods": {
        "__init__": {
          "start_line": 25,
          "end_line": 71,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "model"
            },
            {
              "name": "device"
            },
            {
              "name": "semantic_map"
            },
            {
              "name": "min_batch"
            },
            {
              "name": "max_batch"
            },
            {
              "name": "total_epochs"
            },
            {
              "name": "batch_assignment_strategy"
            },
            {
              "name": "curriculum_phases"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "....__init__",
              "line": 50
            },
            {
              "name": "self._initialize_from_map",
              "line": 66
            },
            {
              "name": "logger.info",
              "line": 68
            },
            {
              "name": "logger.info",
              "line": 69
            },
            {
              "name": "super",
              "line": 50
            }
          ],
          "docstring": "\n        Initialize the optimizer with semantic map awareness.\n        \n        Args:\n            model: PyTorch model to optimize\n            device: Device to use (CPU or CUDA)\n            semantic_map: Semantic topographical map of the dataset\n            min_batch: Minimum batch size to consider\n            max_batch: Maximum batch size to consider\n            total_epochs: Total number of epochs for training\n            batch_assignment_strategy: Strategy for batch assignment ('difficulty_aware', 'curriculum', 'resonance')\n            curriculum_phases: Number of phases for curriculum learning\n            **kwargs: Additional arguments passed to parent class\n        ",
          "code_snippet": "    to improve training efficiency.\n    \"\"\"\n    def __init__(self, \n                 model, \n                 device, \n                 semantic_map, \n                 min_batch=4, \n                 max_batch=512,\n                 total_epochs=50,\n                 batch_assignment_strategy='difficulty_aware',\n                 curriculum_phases=3,\n                 **kwargs):\n        \"\"\"\n        Initialize the optimizer with semantic map awareness.\n        \n        Args:\n            model: PyTorch model to optimize\n            device: Device to use (CPU or CUDA)\n            semantic_map: Semantic topographical map of the dataset\n            min_batch: Minimum batch size to consider\n            max_batch: Maximum batch size to consider\n            total_epochs: Total number of epochs for training\n            batch_assignment_strategy: Strategy for batch assignment ('difficulty_aware', 'curriculum', 'resonance')\n            curriculum_phases: Number of phases for curriculum learning\n            **kwargs: Additional arguments passed to parent class\n        \"\"\"\n        # Initialize parent with run_diagnostics=True to establish baseline parameters\n        super().__init__(model, \n                        device=device, \n                        run_diagnostics=True,\n                        min_batch=min_batch,\n                        max_batch=max_batch,\n                        **kwargs)\n        \n        # Store semantic map and initialize from it\n        self.semantic_map = semantic_map\n        self.difficulty_ratings = semantic_map['difficulty_ratings']\n        self.current_epoch = 0\n        self.total_epochs = total_epochs\n        self.batch_assignment_strategy = batch_assignment_strategy\n        self.curriculum_phases = curriculum_phases\n        \n        # Initialize from map\n        self._initialize_from_map()\n        \n        logger.info(f\"Initialized TopographicalAwareIsekaiZen with {batch_assignment_strategy} strategy\")\n        logger.info(f\"Resonance zone: {self.resonance_zone}\")\n        \n    def _initialize_from_map(self):\n        \"\"\"Initialize optimizer parameters based on the semantic map\"\"\"\n        # Extract difficulty distribution from map"
        },
        "_initialize_from_map": {
          "start_line": 71,
          "end_line": 89,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._analyze_difficulty_distribution",
              "line": 74
            },
            {
              "name": "self._configure_lanes_from_map",
              "line": 77
            },
            {
              "name": "self._configure_batch_preferences",
              "line": 80
            },
            {
              "name": "self._update_resonance_zones",
              "line": 83
            },
            {
              "name": "self._configure_curriculum",
              "line": 87
            }
          ],
          "docstring": "Initialize optimizer parameters based on the semantic map",
          "code_snippet": "        logger.info(f\"Resonance zone: {self.resonance_zone}\")\n        \n    def _initialize_from_map(self):\n        \"\"\"Initialize optimizer parameters based on the semantic map\"\"\"\n        # Extract difficulty distribution from map\n        self.difficulty_distribution = self._analyze_difficulty_distribution()\n        \n        # Configure lanes based on difficulty topology\n        self._configure_lanes_from_map()\n        \n        # Set up batch size preferences for different difficulty levels\n        self._configure_batch_preferences()\n        \n        # Reconfigure resonance zones based on difficulty topology\n        self._update_resonance_zones()\n        \n        # Set up curriculum phases if using curriculum strategy\n        if self.batch_assignment_strategy == 'curriculum':\n            self._configure_curriculum()\n    \n    def _analyze_difficulty_distribution(self):\n        \"\"\"\n        Analyze the distribution of difficulty in the dataset."
        },
        "_analyze_difficulty_distribution": {
          "start_line": 89,
          "end_line": 119,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.difficulty_ratings.items",
              "line": 97
            },
            {
              "name": "sum",
              "line": 104
            },
            {
              "name": "sorted",
              "line": 108
            },
            {
              "name": "int",
              "line": 98
            },
            {
              "name": "levels.values",
              "line": 104
            },
            {
              "name": "levels.keys",
              "line": 108
            }
          ],
          "docstring": "\n        Analyze the distribution of difficulty in the dataset.\n        \n        Returns:\n            Dictionary with difficulty distribution statistics\n        ",
          "code_snippet": "            self._configure_curriculum()\n    \n    def _analyze_difficulty_distribution(self):\n        \"\"\"\n        Analyze the distribution of difficulty in the dataset.\n        \n        Returns:\n            Dictionary with difficulty distribution statistics\n        \"\"\"\n        levels = {}\n        for idx, rating in self.difficulty_ratings.items():\n            rating = int(rating)  # Ensure rating is integer\n            if rating not in levels:\n                levels[rating] = 0\n            levels[rating] += 1\n        \n        # Calculate percentiles for later use\n        total_samples = sum(levels.values())\n        cumulative = 0\n        percentiles = {}\n        \n        for level in sorted(levels.keys()):\n            count = levels[level]\n            cumulative += count\n            percentile = cumulative / total_samples\n            percentiles[level] = percentile\n        \n        return {\n            'counts': levels,\n            'total': total_samples,\n            'percentiles': percentiles\n        }\n    \n    def _configure_lanes_from_map(self):\n        \"\"\"Configure training lanes based on difficulty topology\"\"\""
        },
        "_configure_lanes_from_map": {
          "start_line": 120,
          "end_line": 162,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "sorted",
              "line": 125
            },
            {
              "name": "min",
              "line": 126
            },
            {
              "name": "range",
              "line": 132
            },
            {
              "name": "logger.info",
              "line": 160
            },
            {
              "name": "....keys",
              "line": 125
            },
            {
              "name": "len",
              "line": 126
            },
            {
              "name": "....get",
              "line": 148
            },
            {
              "name": "self.lanes.append",
              "line": 151
            },
            {
              "name": "int",
              "line": 136
            },
            {
              "name": "max",
              "line": 143
            },
            {
              "name": "len",
              "line": 160
            },
            {
              "name": "len",
              "line": 136
            }
          ],
          "docstring": "Configure training lanes based on difficulty topology",
          "code_snippet": "        }\n    \n    def _configure_lanes_from_map(self):\n        \"\"\"Configure training lanes based on difficulty topology\"\"\"\n        # Create lanes that align with the natural topography of the dataset\n        \n        # Define how many lanes to create based on difficulty distribution\n        difficulty_levels = sorted(self.difficulty_distribution['counts'].keys())\n        num_lanes = min(5, len(difficulty_levels))\n        \n        # Distribute batch sizes across lanes based on difficulty\n        self.lanes = []\n        \n        # Initialize lanes based on difficulty levels\n        for i in range(num_lanes):\n            # Map each lane to appropriate batch sizes\n            # Easier examples (lower difficulty) \u2192 larger batch sizes\n            # Harder examples (higher difficulty) \u2192 smaller batch sizes\n            lane_difficulty = difficulty_levels[int(i * len(difficulty_levels) / num_lanes)]\n            \n            # Map difficulty to batch size range\n            min_batch = self.min_batch\n            max_batch = self.max_batch\n            \n            # More difficult examples get smaller batches\n            difficulty_ratio = lane_difficulty / max(difficulty_levels)\n            lane_max_batch = max_batch - (max_batch - min_batch) * difficulty_ratio\n            lane_min_batch = min_batch\n            \n            # Calculate lane weight based on sample count\n            lane_count = self.difficulty_distribution['counts'].get(lane_difficulty, 0)\n            lane_weight = lane_count / self.difficulty_distribution['total']\n            \n            self.lanes.append({\n                'difficulty_level': lane_difficulty,\n                'min_batch': lane_min_batch,\n                'max_batch': lane_max_batch,\n                'current_batch': (lane_min_batch + lane_max_batch) / 2,\n                'weight': lane_weight,\n                'batch_history': []\n            })\n            \n        logger.info(f\"Configured {len(self.lanes)} difficulty-based lanes\")\n    \n    def _configure_batch_preferences(self):\n        \"\"\"Set up batch size preferences for different difficulty levels\"\"\"\n        # Map difficulty ratings to preferred batch size ranges"
        },
        "_configure_batch_preferences": {
          "start_line": 162,
          "end_line": 190,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "list",
              "line": 168
            },
            {
              "name": "min",
              "line": 169
            },
            {
              "name": "max",
              "line": 170
            },
            {
              "name": "....keys",
              "line": 168
            }
          ],
          "docstring": "Set up batch size preferences for different difficulty levels",
          "code_snippet": "        logger.info(f\"Configured {len(self.lanes)} difficulty-based lanes\")\n    \n    def _configure_batch_preferences(self):\n        \"\"\"Set up batch size preferences for different difficulty levels\"\"\"\n        # Map difficulty ratings to preferred batch size ranges\n        self.batch_preferences = {}\n        \n        # Get difficulty range\n        difficulty_levels = list(self.difficulty_distribution['counts'].keys())\n        min_difficulty = min(difficulty_levels)\n        max_difficulty = max(difficulty_levels)\n        difficulty_range = max_difficulty - min_difficulty\n        \n        for difficulty in difficulty_levels:\n            # Normalize difficulty to 0-1 range\n            if difficulty_range > 0:\n                normalized_difficulty = (difficulty - min_difficulty) / difficulty_range\n            else:\n                normalized_difficulty = 0.5  # Default if only one difficulty level\n            \n            # Calculate preferred batch size for this difficulty\n            # Lower difficulty \u2192 larger batch size\n            # Higher difficulty \u2192 smaller batch size\n            preferred_batch = self.max_batch - normalized_difficulty * (self.max_batch - self.min_batch)\n            \n            # Store preference\n            self.batch_preferences[difficulty] = {\n                'preferred_size': preferred_batch,\n                'tolerance': 0.2 * (self.max_batch - self.min_batch)  # Allow some flexibility\n            }\n    \n    def _update_resonance_zones(self):\n        \"\"\"Update resonance zones based on semantic map\"\"\""
        },
        "_update_resonance_zones": {
          "start_line": 191,
          "end_line": 236,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logger.info",
              "line": 197
            },
            {
              "name": "list",
              "line": 200
            },
            {
              "name": "logger.info",
              "line": 234
            },
            {
              "name": "....keys",
              "line": 200
            },
            {
              "name": "len",
              "line": 203
            },
            {
              "name": "min",
              "line": 206
            },
            {
              "name": "max",
              "line": 215
            },
            {
              "name": "min",
              "line": 216
            },
            {
              "name": "max",
              "line": 220
            },
            {
              "name": "max",
              "line": 226
            },
            {
              "name": "min",
              "line": 227
            },
            {
              "name": "abs",
              "line": 207
            }
          ],
          "docstring": "Update resonance zones based on semantic map",
          "code_snippet": "            }\n    \n    def _update_resonance_zones(self):\n        \"\"\"Update resonance zones based on semantic map\"\"\"\n        # Use difficulty distribution to find natural resonance zones\n        \n        # Start with the resonance zone from parent class diagnostics\n        original_min, original_max = self.resonance_zone\n        logger.info(f\"Original resonance zone from diagnostics: {original_min}-{original_max}\")\n        \n        # Adjust based on difficulty distribution\n        difficulty_levels = list(self.difficulty_distribution['counts'].keys())\n        \n        # For datasets with clear difficulty stratification\n        if len(difficulty_levels) >= 3:\n            # Find moderate difficulty level (around 40th-60th percentile)\n            target_percentile = 0.5  # Aim for median difficulty\n            closest_level = min(difficulty_levels, \n                              key=lambda x: abs(self.difficulty_distribution['percentiles'][x] - target_percentile))\n            \n            # Get batch preference for this difficulty\n            pref = self.batch_preferences[closest_level]\n            preferred_size = pref['preferred_size']\n            tolerance = pref['tolerance']\n            \n            # Adjust resonance zone to center around this batch size\n            resonance_min = max(self.min_batch, preferred_size - tolerance)\n            resonance_max = min(self.max_batch, preferred_size + tolerance)\n            \n            # Ensure resonance zone isn't too narrow (at least 25% of original)\n            original_width = original_max - original_min\n            min_width = max(original_width * 0.25, 16)  # At least 16 or 25% of original\n            \n            if resonance_max - resonance_min < min_width:\n                # Expand the zone while maintaining center\n                center = (resonance_min + resonance_max) / 2\n                half_width = min_width / 2\n                resonance_min = max(self.min_batch, center - half_width)\n                resonance_max = min(self.max_batch, center + half_width)\n        else:\n            # For more uniform datasets, use the original resonance zone\n            resonance_min, resonance_max = original_min, original_max\n        \n        # Update resonance zone\n        self.resonance_zone = (resonance_min, resonance_max)\n        logger.info(f\"Updated resonance zone based on difficulty map: {resonance_min}-{resonance_max}\")\n    \n    def _configure_curriculum(self):\n        \"\"\"Configure curriculum learning phases based on difficulty distribution\"\"\"\n        # Divide difficulties into phases for curriculum learning"
        },
        "_configure_curriculum": {
          "start_line": 236,
          "end_line": 275,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "sorted",
              "line": 239
            },
            {
              "name": "range",
              "line": 244
            },
            {
              "name": "logger.info",
              "line": 273
            },
            {
              "name": "....keys",
              "line": 239
            },
            {
              "name": "min",
              "line": 249
            },
            {
              "name": "self.curriculum.append",
              "line": 266
            },
            {
              "name": "max",
              "line": 255
            },
            {
              "name": "min",
              "line": 261
            },
            {
              "name": "len",
              "line": 273
            },
            {
              "name": "abs",
              "line": 250
            }
          ],
          "docstring": "Configure curriculum learning phases based on difficulty distribution",
          "code_snippet": "        logger.info(f\"Updated resonance zone based on difficulty map: {resonance_min}-{resonance_max}\")\n    \n    def _configure_curriculum(self):\n        \"\"\"Configure curriculum learning phases based on difficulty distribution\"\"\"\n        # Divide difficulties into phases for curriculum learning\n        difficulty_levels = sorted(self.difficulty_distribution['counts'].keys())\n        \n        # Create phases from easiest to hardest\n        self.curriculum = []\n        \n        for phase in range(self.curriculum_phases):\n            # Calculate difficulty threshold for this phase\n            percentile_threshold = (phase + 1) / self.curriculum_phases\n            \n            # Find difficulty level closest to this percentile\n            closest_level = min(difficulty_levels, \n                              key=lambda x: abs(self.difficulty_distribution['percentiles'][x] - percentile_threshold))\n            \n            # Get batch size range for this phase\n            if phase == self.curriculum_phases - 1:\n                # Final phase includes all difficulties\n                max_difficulty = max(difficulty_levels)\n                batch_size = self.batch_preferences[closest_level]['preferred_size']\n            else:\n                # Intermediate phase\n                max_difficulty = closest_level\n                # Use batch size slightly larger than preferred for this difficulty\n                batch_size = min(\n                    self.max_batch,\n                    self.batch_preferences[closest_level]['preferred_size'] * 1.2\n                )\n            \n            self.curriculum.append({\n                'phase': phase,\n                'percentile': percentile_threshold,\n                'max_difficulty': max_difficulty,\n                'batch_size': batch_size\n            })\n            \n        logger.info(f\"Configured {len(self.curriculum)} curriculum phases\")\n    \n    def get_optimal_batch_size(self):\n        \"\"\"\n        Get optimal batch size for current training state,"
        },
        "get_optimal_batch_size": {
          "start_line": 275,
          "end_line": 294,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self._get_difficulty_aware_batch_size",
              "line": 284
            },
            {
              "name": "self._get_curriculum_batch_size",
              "line": 286
            },
            {
              "name": "....get_optimal_batch_size",
              "line": 289
            },
            {
              "name": "....get_optimal_batch_size",
              "line": 292
            },
            {
              "name": "super",
              "line": 289
            },
            {
              "name": "super",
              "line": 292
            }
          ],
          "docstring": "\n        Get optimal batch size for current training state,\n        informed by the semantic map.\n        \n        Returns:\n            Optimal batch size (integer)\n        ",
          "code_snippet": "        logger.info(f\"Configured {len(self.curriculum)} curriculum phases\")\n    \n    def get_optimal_batch_size(self):\n        \"\"\"\n        Get optimal batch size for current training state,\n        informed by the semantic map.\n        \n        Returns:\n            Optimal batch size (integer)\n        \"\"\"\n        if self.batch_assignment_strategy == 'difficulty_aware':\n            return self._get_difficulty_aware_batch_size()\n        elif self.batch_assignment_strategy == 'curriculum':\n            return self._get_curriculum_batch_size()\n        elif self.batch_assignment_strategy == 'resonance':\n            # Use parent class's resonance approach, but with our updated resonance zone\n            return super().get_optimal_batch_size()\n        else:\n            # Fall back to standard IsekaiZen approach\n            return super().get_optimal_batch_size()\n    \n    def _get_difficulty_aware_batch_size(self):\n        \"\"\"\n        Select batch size based on dataset difficulty topology."
        },
        "_get_difficulty_aware_batch_size": {
          "start_line": 294,
          "end_line": 335,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "sum",
              "line": 303
            },
            {
              "name": "random.random",
              "line": 307
            },
            {
              "name": "enumerate",
              "line": 311
            },
            {
              "name": "min",
              "line": 326
            },
            {
              "name": "....append",
              "line": 330
            },
            {
              "name": "int",
              "line": 333
            },
            {
              "name": "max",
              "line": 322
            },
            {
              "name": "int",
              "line": 330
            }
          ],
          "docstring": "\n        Select batch size based on dataset difficulty topology.\n        \n        Returns:\n            Optimal batch size (integer)\n        ",
          "code_snippet": "            return super().get_optimal_batch_size()\n    \n    def _get_difficulty_aware_batch_size(self):\n        \"\"\"\n        Select batch size based on dataset difficulty topology.\n        \n        Returns:\n            Optimal batch size (integer)\n        \"\"\"\n        # Select from lanes with probability proportional to their weight\n        lane_weights = [lane['weight'] for lane in self.lanes]\n        total_weight = sum(lane_weights)\n        normalized_weights = [w / total_weight for w in lane_weights]\n        \n        # Randomly select a lane based on weights\n        rand_val = random.random()\n        cumulative = 0\n        selected_lane = 0\n        \n        for i, weight in enumerate(normalized_weights):\n            cumulative += weight\n            if rand_val <= cumulative:\n                selected_lane = i\n                break\n        \n        # Get batch size from selected lane\n        lane = self.lanes[selected_lane]\n        \n        # Apply linear interpolation within lane's batch range\n        # Start with larger batches (lane max) and gradually decrease\n        progress = self.current_epoch / max(1, self.total_epochs)\n        \n        # Early epochs: prefer larger batches (lane max)\n        # Later epochs: prefer smaller batches (lane min)\n        interpolation = min(1.0, progress * 2)  # 0->1 over first half of training\n        batch_size = lane['max_batch'] - interpolation * (lane['max_batch'] - lane['min_batch'])\n        \n        # Record for history\n        lane['batch_history'].append(int(batch_size))\n        \n        # Return as integer\n        return int(batch_size)\n    \n    def _get_curriculum_batch_size(self):\n        \"\"\"\n        Implement curriculum learning based on semantic map."
        },
        "_get_curriculum_batch_size": {
          "start_line": 335,
          "end_line": 361,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "min",
              "line": 346
            },
            {
              "name": "int",
              "line": 359
            },
            {
              "name": "max",
              "line": 343
            },
            {
              "name": "int",
              "line": 347
            },
            {
              "name": "logger.info",
              "line": 355
            },
            {
              "name": "len",
              "line": 346
            },
            {
              "name": "len",
              "line": 355
            }
          ],
          "docstring": "\n        Implement curriculum learning based on semantic map.\n        \n        Returns:\n            Optimal batch size (integer)\n        ",
          "code_snippet": "        return int(batch_size)\n    \n    def _get_curriculum_batch_size(self):\n        \"\"\"\n        Implement curriculum learning based on semantic map.\n        \n        Returns:\n            Optimal batch size (integer)\n        \"\"\"\n        # Calculate progress through curriculum (0.0 to 1.0)\n        progress = self.current_epoch / max(1, self.total_epochs)\n        \n        # Determine current phase based on progress\n        current_phase = min(len(self.curriculum) - 1, \n                          int(progress * self.curriculum_phases))\n        \n        # Get batch size for this phase\n        phase_info = self.curriculum[current_phase]\n        batch_size = phase_info['batch_size']\n        \n        # Log curriculum progress occasionally\n        if self.current_epoch % 5 == 0:\n            logger.info(f\"Curriculum phase {current_phase+1}/{len(self.curriculum)}, \"\n                      f\"max difficulty: {phase_info['max_difficulty']}, \"\n                      f\"batch size: {batch_size}\")\n        \n        return int(batch_size)\n    \n    def increment_epoch(self):\n        \"\"\"Track current epoch and update parameters as needed\"\"\"\n        self.current_epoch += 1"
        },
        "increment_epoch": {
          "start_line": 361,
          "end_line": 369,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "hasattr",
              "line": 366
            },
            {
              "name": "super",
              "line": 366
            },
            {
              "name": "....increment_epoch",
              "line": 367
            },
            {
              "name": "super",
              "line": 367
            }
          ],
          "docstring": "Track current epoch and update parameters as needed",
          "code_snippet": "        return int(batch_size)\n    \n    def increment_epoch(self):\n        \"\"\"Track current epoch and update parameters as needed\"\"\"\n        self.current_epoch += 1\n        \n        # Update parent class epoch counter if it exists\n        if hasattr(super(), 'increment_epoch'):\n            super().increment_epoch()\n    \n    def visualize_topology(self):\n        \"\"\"\n        Create a visualization of the dataset topology based on the semantic map."
        },
        "visualize_topology": {
          "start_line": 369,
          "end_line": 414,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "output.append",
              "line": 378
            },
            {
              "name": "output.append",
              "line": 381
            },
            {
              "name": "sorted",
              "line": 385
            },
            {
              "name": "output.append",
              "line": 393
            },
            {
              "name": "enumerate",
              "line": 394
            },
            {
              "name": "output.append",
              "line": 401
            },
            {
              "name": "hasattr",
              "line": 404
            },
            {
              "name": "....join",
              "line": 412
            },
            {
              "name": "difficulty_counts.keys",
              "line": 385
            },
            {
              "name": "int",
              "line": 388
            },
            {
              "name": "output.append",
              "line": 390
            },
            {
              "name": "output.append",
              "line": 395
            },
            {
              "name": "output.append",
              "line": 405
            },
            {
              "name": "output.append",
              "line": 407
            }
          ],
          "docstring": "\n        Create a visualization of the dataset topology based on the semantic map.\n        \n        Returns:\n            Text-based visualization of the topology\n        ",
          "code_snippet": "            super().increment_epoch()\n    \n    def visualize_topology(self):\n        \"\"\"\n        Create a visualization of the dataset topology based on the semantic map.\n        \n        Returns:\n            Text-based visualization of the topology\n        \"\"\"\n        # Create a text-based visualization\n        output = []\n        output.append(\"=== Dataset Topology Visualization ===\")\n        \n        # Difficulty distribution\n        output.append(\"\\nDifficulty Distribution:\")\n        difficulty_counts = self.difficulty_distribution['counts']\n        total = self.difficulty_distribution['total']\n        \n        for level in sorted(difficulty_counts.keys()):\n            count = difficulty_counts[level]\n            percentage = count * 100 / total\n            bar_length = int(percentage / 2)\n            bar = '#' * bar_length\n            output.append(f\"Level {level}: {count} samples ({percentage:.1f}%) {bar}\")\n        \n        # Lane configuration\n        output.append(\"\\nLane Configuration:\")\n        for i, lane in enumerate(self.lanes):\n            output.append(f\"Lane {i+1}: Difficulty {lane['difficulty_level']}, \"\n                        f\"Batch range {lane['min_batch']:.0f}-{lane['max_batch']:.0f}, \"\n                        f\"Weight {lane['weight']:.2f}\")\n        \n        # Resonance zone\n        r_min, r_max = self.resonance_zone\n        output.append(f\"\\nResonance Zone: {r_min:.0f}-{r_max:.0f}\")\n        \n        # If curriculum is configured\n        if hasattr(self, 'curriculum'):\n            output.append(\"\\nCurriculum Phases:\")\n            for phase in self.curriculum:\n                output.append(f\"Phase {phase['phase']+1}: \"\n                            f\"Up to {phase['percentile']*100:.0f}th percentile, \"\n                            f\"Max difficulty {phase['max_difficulty']}, \"\n                            f\"Batch size {phase['batch_size']:.0f}\")\n        \n        return '\\n'.join(output)"
        }
      },
      "class_variables": [],
      "bases": [
        "IsekaiZenOptimizer"
      ],
      "docstring": "\n    IsekaiZen optimizer that leverages semantic topographical maps\n    to improve training efficiency.\n    "
    }
  },
  "functions": {},
  "constants": {}
}