{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\core\\cortex\\coordinator.py",
  "imports": [
    {
      "name": "typing.Dict",
      "line": 4
    },
    {
      "name": "typing.Any",
      "line": 4
    },
    {
      "name": "typing.List",
      "line": 4
    },
    {
      "name": "typing.Optional",
      "line": 4
    },
    {
      "name": "enum.Enum",
      "line": 5
    },
    {
      "name": "isekaizen.core.cortex.diagnostics.CortexDiagnostics",
      "line": 6
    },
    {
      "name": "isekaizen.core.cortex.integrated_kt_rpg.IntegratedCortexSystem",
      "line": 7
    },
    {
      "name": "isekaizen.core.cortex.pattern_orchestrator.PatternOrchestrator",
      "line": 8
    },
    {
      "name": "isekaizen.core.cortex.resource_manager.ResourceManager",
      "line": 9
    },
    {
      "name": "isekaizen.core.cortex.rpg_manager.RPGCortexManager",
      "line": 10
    },
    {
      "name": "dataclasses.dataclass",
      "line": 11
    },
    {
      "name": "datetime.datetime",
      "line": 13
    },
    {
      "name": "time",
      "line": 14
    },
    {
      "name": "isekaizen.utils.types.CortexFlowMetadata",
      "line": 15
    },
    {
      "name": "isekaizen.utils.types.ProcessingStage",
      "line": 15
    },
    {
      "name": "isekaizen.utils.input_translator.InputTranslator",
      "line": 17
    },
    {
      "name": "utils.scil.core.SpinalCordIntegrationLayer",
      "line": 41
    },
    {
      "name": "semantic_core.SemanticPatternRegistry",
      "line": 50
    },
    {
      "name": "semantic_core.DomainPatternExtractor",
      "line": 50
    }
  ],
  "classes": {
    "DomainType": {
      "start_line": 19,
      "end_line": 24,
      "methods": {},
      "class_variables": [
        {
          "name": "VISUAL",
          "line": 20
        },
        {
          "name": "LINGUISTIC",
          "line": 21
        },
        {
          "name": "EMOTIONAL",
          "line": 22
        }
      ],
      "bases": [
        "Enum"
      ]
    },
    "ProcessingConfig": {
      "start_line": 25,
      "end_line": 32,
      "methods": {},
      "class_variables": [],
      "bases": [],
      "docstring": "Configuration for pattern processing"
    },
    "CortexCoordinator": {
      "start_line": 32,
      "end_line": 366,
      "methods": {
        "__init__": {
          "start_line": 33,
          "end_line": 85,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "config"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "CortexDiagnostics",
              "line": 38
            },
            {
              "name": "SpinalCordIntegrationLayer",
              "line": 42
            },
            {
              "name": "PatternOrchestrator",
              "line": 45
            },
            {
              "name": "ResourceManager",
              "line": 46
            },
            {
              "name": "ProcessingConfig",
              "line": 35
            },
            {
              "name": "SemanticPatternRegistry",
              "line": 51
            },
            {
              "name": "DomainPatternExtractor",
              "line": 52
            },
            {
              "name": "IntegratedCortexSystem",
              "line": 71
            },
            {
              "name": "RPGCortexManager",
              "line": 73
            }
          ],
          "code_snippet": "\nclass CortexCoordinator:\n    def __init__(self, config: Optional[ProcessingConfig] = None):\n        # Initialize configuration\n        self.config = config or ProcessingConfig()\n        \n        # Initialize the diagnostic system\n        self.diagnostics = CortexDiagnostics()\n        \n        # Initialize SCIL\n        from ..utils.scil.core import SpinalCordIntegrationLayer\n        self.scil = SpinalCordIntegrationLayer()\n\n        # Initialize core systems\n        self.pattern_orchestrator = PatternOrchestrator()\n        self.resource_manager = ResourceManager()\n        \n        # Initialize semantic pattern recognition\n        if self.config.use_semantic_core:\n            from .semantic_core import SemanticPatternRegistry, DomainPatternExtractor\n            self.semantic_registry = SemanticPatternRegistry()\n            self.pattern_extractor = DomainPatternExtractor()\n        \n        # Initialize pattern tracking\n        self.active_patterns = {\n            DomainType.VISUAL: [],\n            DomainType.LINGUISTIC: [],\n            DomainType.EMOTIONAL: []\n        }\n        \n        # Add stage-based pattern tracking\n        self.stage_patterns = {\n            ProcessingStage.INPUT: {},\n            ProcessingStage.SEMANTIC: {},\n            ProcessingStage.PATTERN: {},\n            ProcessingStage.OUTPUT: {}\n    }\n\n        # Choose processing system\n        if self.config.enable_rpg:\n            self.processing_system = IntegratedCortexSystem()\n        else:\n            self.rpg_system = RPGCortexManager()\n        \n        # Performance tracking\n        self.metrics = {\n            \"patterns_processed\": 0,\n            \"semantic_patterns_extracted\": 0,\n            \"successful_translations\": 0,\n            \"cross_domain_matches\": 0\n        }\n        \n        self.initialized = True\n    \n    def _extract_semantic_pattern(self, domain: DomainType, data: Dict[str, Any]) -> Optional[Any]:\n        \"\"\"Extract semantic pattern based on domain\"\"\"\n        if not self.config.use_semantic_core:"
        },
        "_extract_semantic_pattern": {
          "start_line": 85,
          "end_line": 101,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "domain",
              "type": "DomainType"
            },
            {
              "name": "data"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "self.pattern_extractor.extract_visual_semantics",
              "line": 92
            },
            {
              "name": "self.diagnostics.record_error",
              "line": 98
            },
            {
              "name": "self.pattern_extractor.extract_text_semantics",
              "line": 94
            },
            {
              "name": "self.pattern_extractor.extract_emotion_semantics",
              "line": 96
            },
            {
              "name": "str",
              "line": 98
            }
          ],
          "docstring": "Extract semantic pattern based on domain",
          "code_snippet": "        self.initialized = True\n    \n    def _extract_semantic_pattern(self, domain: DomainType, data: Dict[str, Any]) -> Optional[Any]:\n        \"\"\"Extract semantic pattern based on domain\"\"\"\n        if not self.config.use_semantic_core:\n            return None\n            \n        try:\n            if domain == DomainType.VISUAL:\n                return self.pattern_extractor.extract_visual_semantics(data)\n            elif domain == DomainType.LINGUISTIC:\n                return self.pattern_extractor.extract_text_semantics(data)\n            elif domain == DomainType.EMOTIONAL:\n                return self.pattern_extractor.extract_emotion_semantics(data)\n        except Exception as e:\n            self.diagnostics.record_error(f\"Semantic extraction error: {str(e)}\")\n            return None\n    \n    def process_specialist_output(self, \n                                domain: DomainType, \n                                pattern: Any) -> Dict[str, Any]:"
        },
        "process_specialist_output": {
          "start_line": 101,
          "end_line": 163,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "domain",
              "type": "DomainType"
            },
            {
              "name": "pattern",
              "type": "Any"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "print",
              "line": 105
            },
            {
              "name": "hasattr",
              "line": 116
            },
            {
              "name": "print",
              "line": 126
            },
            {
              "name": "....append",
              "line": 139
            },
            {
              "name": "hasattr",
              "line": 143
            },
            {
              "name": "print",
              "line": 160
            },
            {
              "name": "hasattr",
              "line": 130
            },
            {
              "name": "print",
              "line": 131
            },
            {
              "name": "self._extract_semantic_pattern",
              "line": 132
            },
            {
              "name": "print",
              "line": 144
            },
            {
              "name": "self.processing_system.process_pattern",
              "line": 145
            },
            {
              "name": "print",
              "line": 147
            },
            {
              "name": "self.rpg_system.process_pattern",
              "line": 148
            },
            {
              "name": "hasattr",
              "line": 153
            },
            {
              "name": "pattern.signature.tolist",
              "line": 120
            },
            {
              "name": "self.semantic_registry.recognize_pattern",
              "line": 135
            },
            {
              "name": "processing_result.get",
              "line": 157
            },
            {
              "name": "self.semantic_registry.get_semantic_stats",
              "line": 156
            },
            {
              "name": "hasattr",
              "line": 156
            }
          ],
          "docstring": "Process output from a specialist with semantic pattern recognition",
          "code_snippet": "            return None\n    \n    def process_specialist_output(self, \n                                domain: DomainType, \n                                pattern: Any) -> Dict[str, Any]:\n        \"\"\"Process output from a specialist with semantic pattern recognition\"\"\"\n        print(f\"DEBUG - Processing {domain} pattern: {pattern}\")  # Debug line\n        \n        result = {\n            \"success\": False,\n            \"semantic_pattern\": None,\n            \"processing_result\": None,\n            \"metrics\": {}\n        }\n\n        # Convert Pattern object to dict for semantic extraction\n        pattern_dict = {}\n        if hasattr(pattern, 'signature'):  # If it's a Pattern object\n            pattern_dict = {\n                \"confidence\": pattern.weight,\n                \"complexity\": pattern.complexity,\n                \"features\": pattern.signature.tolist(),\n                **pattern.domain_data  # Add this line to include domain-specific data\n            }\n        else:\n            pattern_dict = pattern  # If it's already a dict\n            \n        print(f\"DEBUG - Pattern dict with domain data: {pattern_dict}\")\n        \n        # Extract semantic pattern if enabled\n        semantic_pattern = None\n        if hasattr(self, 'config') and self.config.use_semantic_core:\n            print(\"DEBUG - Attempting semantic extraction\")  # Debug line\n            semantic_pattern = self._extract_semantic_pattern(domain, pattern_dict)\n            if semantic_pattern:\n                self.metrics[\"semantic_patterns_extracted\"] += 1\n                recognition_result = self.semantic_registry.recognize_pattern(semantic_pattern)\n                result[\"semantic_pattern\"] = recognition_result\n        \n        # Store pattern\n        self.active_patterns[domain].append(pattern)\n        self.metrics[\"patterns_processed\"] += 1\n        \n        # Process using selected system\n        if hasattr(self, 'processing_system'):\n            print(\"DEBUG - Using processing system\")  # Debug line\n            processing_result = self.processing_system.process_pattern(pattern)\n        else:\n            print(\"DEBUG - Using RPG system\")  # Debug line\n            processing_result = self.rpg_system.process_pattern(pattern)\n        \n        result[\"processing_result\"] = processing_result\n        result[\"success\"] = True\n        \n        if hasattr(self, 'config') and self.config.track_metrics:\n            result[\"metrics\"] = {\n                \"coordinator_metrics\": self.metrics,\n                \"semantic_stats\": self.semantic_registry.get_semantic_stats() if hasattr(self, 'config') and self.config.use_semantic_core else None,\n                \"processing_metrics\": processing_result.get(\"metrics\", {})\n            }\n        \n        print(f\"DEBUG - Final result: {result}\")  # Debug line\n        return result\n    \n    async def process_input(self, domain: str, input_data: Dict[str, Any]) -> Dict[str, Any]:\n        try:\n            # Validate input"
        },
        "coordinate_specialists": {
          "start_line": 270,
          "end_line": 305,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "patterns"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "patterns.items",
              "line": 281
            },
            {
              "name": "self.resource_manager.allocate_resources",
              "line": 285
            },
            {
              "name": "self.resource_manager.get_status",
              "line": 299
            },
            {
              "name": "str",
              "line": 285
            },
            {
              "name": "self.semantic_registry.get_semantic_stats",
              "line": 300
            },
            {
              "name": "self.process_specialist_output",
              "line": 287
            },
            {
              "name": "....append",
              "line": 288
            },
            {
              "name": "match_result.get",
              "line": 290
            },
            {
              "name": "self.resource_manager.release_resources",
              "line": 293
            },
            {
              "name": "....append",
              "line": 291
            },
            {
              "name": "str",
              "line": 293
            }
          ],
          "docstring": "Coordinate pattern matching across multiple specialists",
          "code_snippet": "            }\n\n    def coordinate_specialists(self, \n                             patterns: Dict[DomainType, List[Dict[str, Any]]]) -> Dict[str, Any]:\n        \"\"\"Coordinate pattern matching across multiple specialists\"\"\"\n        results = {\n            \"pattern_matches\": [],\n            \"semantic_patterns\": [],\n            \"resource_usage\": {},\n            \"performance_metrics\": {}\n        }\n        \n        # Process patterns from each domain\n        for domain, domain_patterns in patterns.items():\n            for pattern in domain_patterns:\n                # Check resource availability\n                specialist_memory = 300  # Base memory requirement\n                if self.resource_manager.allocate_resources(str(domain), specialist_memory):\n                    try:\n                        match_result = self.process_specialist_output(domain, pattern)\n                        results[\"pattern_matches\"].append(match_result)\n                        \n                        if match_result.get(\"semantic_pattern\"):\n                            results[\"semantic_patterns\"].append(match_result[\"semantic_pattern\"])\n                    finally:\n                        self.resource_manager.release_resources(str(domain), specialist_memory)\n        \n        # Compile metrics\n        if self.config.track_metrics:\n            results[\"performance_metrics\"] = {\n                \"coordinator_metrics\": self.metrics,\n                \"resource_usage\": self.resource_manager.get_status(),\n                \"semantic_metrics\": self.semantic_registry.get_semantic_stats() if self.config.use_semantic_core else None\n            }\n        \n        return results\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"Get the current status of the coordinator\"\"\"\n        status = {"
        },
        "get_status": {
          "start_line": 305,
          "end_line": 329,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "hasattr",
              "line": 321
            },
            {
              "name": "self.semantic_registry.get_semantic_stats",
              "line": 319
            },
            {
              "name": "status.update",
              "line": 322
            },
            {
              "name": "len",
              "line": 314
            },
            {
              "name": "self.active_patterns.items",
              "line": 315
            },
            {
              "name": "self.processing_system.optimize_batch_size",
              "line": 323
            }
          ],
          "docstring": "Get the current status of the coordinator",
          "code_snippet": "        return results\n    \n    def get_status(self) -> Dict[str, Any]:\n        \"\"\"Get the current status of the coordinator\"\"\"\n        status = {\n            \"initialized\": self.initialized,\n            \"config\": {\n                \"semantic_core\": self.config.use_semantic_core,\n                \"rpg_enabled\": self.config.enable_rpg,\n                \"batch_processing\": self.config.batch_processing\n            },\n            \"active_patterns\": {domain.value: len(patterns) \n                              for domain, patterns in self.active_patterns.items()}\n        }\n        \n        if self.config.use_semantic_core:\n            status[\"semantic_stats\"] = self.semantic_registry.get_semantic_stats()\n        \n        if hasattr(self, 'processing_system'):\n            status.update({\n                \"batch_config\": self.processing_system.optimize_batch_size(),\n                \"system_metrics\": self.processing_system.metrics\n            })\n        \n        return status\n    \n    def get_domain_distribution(self):\n        \"\"\"\n        Calculate and return a distribution summary of patterns across domains."
        },
        "get_domain_distribution": {
          "start_line": 329,
          "end_line": 351,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.semantic_registry.patterns.items",
              "line": 341
            },
            {
              "name": "pattern.source_domain.lower",
              "line": 343
            }
          ],
          "docstring": "\n        Calculate and return a distribution summary of patterns across domains.\n        ",
          "code_snippet": "        return status\n    \n    def get_domain_distribution(self):\n        \"\"\"\n        Calculate and return a distribution summary of patterns across domains.\n        \"\"\"\n        domain_distribution = {\n            \"visual\": 0,\n            \"linguistic\": 0,\n            \"emotional\": 0,\n            \"ambiguous\": 0\n        }\n\n        # Retrieve patterns from the semantic registry instead of a non-existent semantic_core\n        for pattern_type, patterns in self.semantic_registry.patterns.items():\n            for pattern in patterns:\n                domain = pattern.source_domain.lower()\n                if domain in domain_distribution:\n                    domain_distribution[domain] += 1\n                else:\n                    domain_distribution[\"ambiguous\"] += 1\n        \n        return domain_distribution\n    \n    def get_risk_queue_size(self):\n        \"\"\"\n        Calculate and return the current size of the risk/intuition queue."
        },
        "get_risk_queue_size": {
          "start_line": 351,
          "end_line": 366,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "hasattr",
              "line": 356
            },
            {
              "name": "len",
              "line": 357
            },
            {
              "name": "self.logger.error",
              "line": 363
            },
            {
              "name": "hasattr",
              "line": 358
            },
            {
              "name": "hasattr",
              "line": 358
            },
            {
              "name": "len",
              "line": 359
            },
            {
              "name": "str",
              "line": 363
            }
          ],
          "docstring": "\n        Calculate and return the current size of the risk/intuition queue.\n        ",
          "code_snippet": "        return domain_distribution\n    \n    def get_risk_queue_size(self):\n        \"\"\"\n        Calculate and return the current size of the risk/intuition queue.\n        \"\"\"\n        try:\n            if hasattr(self, \"risk_event_queue\"):\n                return len(self.risk_event_queue)\n            elif hasattr(self, \"risk_manager\") and hasattr(self.risk_manager, \"risk_queue\"):\n                return len(self.risk_manager.risk_queue)\n            else:\n                return 0  # Default if no risk queue is found\n        except Exception as e:\n            self.logger.error(f\"Error retrieving risk queue size: {str(e)}\")\n            return -1\n\n"
        }
      },
      "class_variables": [],
      "bases": []
    }
  },
  "functions": {},
  "constants": {}
}