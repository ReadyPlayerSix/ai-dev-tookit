{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\core\\cortex\\diagnostics.py",
  "imports": [
    {
      "name": "torch",
      "line": 4
    },
    {
      "name": "numpy",
      "line": 5
    },
    {
      "name": "dataclasses.dataclass",
      "line": 6
    },
    {
      "name": "typing.Dict",
      "line": 7
    },
    {
      "name": "typing.List",
      "line": 7
    },
    {
      "name": "typing.Optional",
      "line": 7
    },
    {
      "name": "typing.Tuple",
      "line": 7
    },
    {
      "name": "typing.Any",
      "line": 7
    },
    {
      "name": "math",
      "line": 8
    },
    {
      "name": "enum.Enum",
      "line": 9
    }
  ],
  "classes": {
    "DiagnosticType": {
      "start_line": 11,
      "end_line": 17,
      "methods": {},
      "class_variables": [
        {
          "name": "SYSTEM",
          "line": 12
        },
        {
          "name": "PATTERN",
          "line": 13
        },
        {
          "name": "PERFORMANCE",
          "line": 14
        },
        {
          "name": "RISK",
          "line": 15
        }
      ],
      "bases": [
        "Enum"
      ]
    },
    "DiagnosticResult": {
      "start_line": 18,
      "end_line": 26,
      "methods": {},
      "class_variables": [],
      "bases": [],
      "docstring": "Standardized diagnostic result for risk system integration"
    },
    "CortexDiagnostics": {
      "start_line": 26,
      "end_line": 219,
      "methods": {
        "__init__": {
          "start_line": 27,
          "end_line": 40,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "params"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "torch.device",
              "line": 28
            },
            {
              "name": "self._get_default_params",
              "line": 29
            },
            {
              "name": "torch.cuda.is_available",
              "line": 28
            }
          ],
          "code_snippet": "\nclass CortexDiagnostics:\n    def __init__(self, params: Optional[Dict[str, Any]] = None):\n        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n        self.params = params or self._get_default_params()\n        \n        # History of diagnostic results for pattern analysis\n        self.diagnostic_history: List[DiagnosticResult] = []\n        \n        # Risk patterns identified from diagnostics\n        self.risk_patterns: Dict[str, List[float]] = {\n            \"system\": [],\n            \"pattern\": [],\n            \"performance\": []\n        }\n    \n    def _get_default_params(self) -> Dict[str, Any]:\n        \"\"\"Get default system parameters\"\"\""
        },
        "_get_default_params": {
          "start_line": 41,
          "end_line": 52,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [],
          "docstring": "Get default system parameters",
          "code_snippet": "        }\n    \n    def _get_default_params(self) -> Dict[str, Any]:\n        \"\"\"Get default system parameters\"\"\"\n        return {\n            \"xp_base_rate\": 34,\n            \"level_scaling_factor\": 1.08,\n            \"skill_improvement_rate\": 0.1,\n            \"pattern_complexity_limit\": 3.4,\n            \"pattern_memory_size\": 100,\n            \"weight_threshold\": 0.6,\n            \"pattern_similarity_threshold\": 0.85\n        }\n    \n    def get_risk_assessment(self) -> Tuple[float, List[str]]:\n        \"\"\"Calculate overall system risk based on diagnostic history\"\"\""
        },
        "get_risk_assessment": {
          "start_line": 53,
          "end_line": 89,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "risk_trends.items",
              "line": 74
            },
            {
              "name": "min",
              "line": 85
            },
            {
              "name": "....append",
              "line": 62
            },
            {
              "name": "len",
              "line": 66
            },
            {
              "name": "insights.append",
              "line": 76
            },
            {
              "name": "np.polyfit",
              "line": 67
            },
            {
              "name": "insights.append",
              "line": 79
            },
            {
              "name": "range",
              "line": 67
            },
            {
              "name": "len",
              "line": 67
            }
          ],
          "docstring": "Calculate overall system risk based on diagnostic history",
          "code_snippet": "        }\n    \n    def get_risk_assessment(self) -> Tuple[float, List[str]]:\n        \"\"\"Calculate overall system risk based on diagnostic history\"\"\"\n        if not self.diagnostic_history:\n            return 0.0, [\"No diagnostic history available\"]\n        \n        # Calculate risk trends\n        risk_trends = {}\n        for diagnostic in self.diagnostic_history[-10:]:  # Look at last 10 diagnostics\n            risk_type = diagnostic.diagnostic_type.value\n            self.risk_patterns[risk_type].append(diagnostic.risk_factor)\n            \n            # Calculate trend for this type\n            pattern = self.risk_patterns[risk_type][-5:]  # Last 5 readings\n            if len(pattern) >= 2:\n                trend = np.polyfit(range(len(pattern)), pattern, 1)[0]\n                risk_trends[risk_type] = trend\n        \n        # Generate risk insights\n        insights = []\n        overall_risk = 0.0\n        \n        for risk_type, trend in risk_trends.items():\n            if trend > 0.1:\n                insights.append(f\"Increasing risk trend in {risk_type}\")\n                overall_risk += 0.2\n            elif trend < -0.1:\n                insights.append(f\"Improving trend in {risk_type}\")\n            \n            # Add current level to overall risk\n            current_level = self.risk_patterns[risk_type][-1]\n            overall_risk += current_level * 0.5  # Weight current levels at 50%\n        \n        overall_risk = min(1.0, overall_risk)  # Cap at 1.0\n        \n        return overall_risk, insights\n    \n    def run_system_diagnostics(self) -> DiagnosticResult:\n        \"\"\"Run system-level diagnostics\"\"\"\n        metrics = {}"
        },
        "run_system_diagnostics": {
          "start_line": 89,
          "end_line": 124,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "DiagnosticResult",
          "calls": [
            {
              "name": "torch.cuda.is_available",
              "line": 96
            },
            {
              "name": "DiagnosticResult",
              "line": 117
            },
            {
              "name": "torch.cuda.get_device_properties",
              "line": 97
            },
            {
              "name": "recommendations.append",
              "line": 106
            },
            {
              "name": "recommendations.append",
              "line": 115
            },
            {
              "name": "torch.cuda.memory_allocated",
              "line": 99
            },
            {
              "name": "recommendations.append",
              "line": 103
            }
          ],
          "docstring": "Run system-level diagnostics",
          "code_snippet": "        return overall_risk, insights\n    \n    def run_system_diagnostics(self) -> DiagnosticResult:\n        \"\"\"Run system-level diagnostics\"\"\"\n        metrics = {}\n        recommendations = []\n        risk_factor = 0.0\n        \n        # GPU Check\n        if torch.cuda.is_available():\n            gpu_props = torch.cuda.get_device_properties(0)\n            metrics[\"total_memory_mb\"] = gpu_props.total_memory / (1024 * 1024)\n            metrics[\"gpu_utilization\"] = torch.cuda.memory_allocated() / gpu_props.total_memory\n            \n            if metrics[\"gpu_utilization\"] > 0.8:\n                risk_factor += 0.3\n                recommendations.append(\"High GPU memory utilization detected\")\n        else:\n            risk_factor += 0.5\n            recommendations.append(\"No GPU available - system running in CPU mode\")\n        \n        # XP Scaling Check\n        xp_ratio = (self.params[\"xp_base_rate\"] * \n                   (self.params[\"level_scaling_factor\"] ** 9))  # Check 10 levels\n        metrics[\"xp_scaling_ratio\"] = xp_ratio\n        \n        if xp_ratio > 100:\n            risk_factor += 0.2\n            recommendations.append(\"XP scaling may be too steep\")\n        \n        return DiagnosticResult(\n            diagnostic_type=DiagnosticType.SYSTEM,\n            status=\"ok\" if risk_factor < 0.3 else \"warning\",\n            metrics=metrics,\n            risk_factor=risk_factor,\n            recommendations=recommendations\n        )\n    \n    def run_pattern_diagnostics(self) -> DiagnosticResult:\n        \"\"\"Run pattern recognition diagnostics\"\"\""
        },
        "run_pattern_diagnostics": {
          "start_line": 125,
          "end_line": 157,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "DiagnosticResult",
          "calls": [
            {
              "name": "np.linspace",
              "line": 132
            },
            {
              "name": "np.mean",
              "line": 139
            },
            {
              "name": "DiagnosticResult",
              "line": 150
            },
            {
              "name": "recognition_rates.append",
              "line": 137
            },
            {
              "name": "recommendations.append",
              "line": 146
            },
            {
              "name": "max",
              "line": 137
            },
            {
              "name": "min",
              "line": 137
            }
          ],
          "docstring": "Run pattern recognition diagnostics",
          "code_snippet": "        )\n    \n    def run_pattern_diagnostics(self) -> DiagnosticResult:\n        \"\"\"Run pattern recognition diagnostics\"\"\"\n        metrics = {}\n        recommendations = []\n        risk_factor = 0.0\n        \n        # Test pattern complexity handling\n        complexities = np.linspace(0.5, 2.0, 10)\n        recognition_rates = []\n        \n        for complexity in complexities:\n            base_rate = 1.0 - (complexity / self.params[\"pattern_complexity_limit\"])\n            recognition_rates.append(max(0, min(1, base_rate)))\n        \n        metrics[\"avg_recognition_rate\"] = np.mean(recognition_rates)\n        metrics[\"pattern_memory_efficiency\"] = (\n            self.params[\"pattern_memory_size\"] / 100.0\n        )\n        \n        if metrics[\"avg_recognition_rate\"] < 0.5:\n            risk_factor += 0.3\n            recommendations.append(\n                \"Pattern recognition rate below threshold\"\n            )\n        \n        return DiagnosticResult(\n            diagnostic_type=DiagnosticType.PATTERN,\n            status=\"ok\" if risk_factor < 0.3 else \"warning\",\n            metrics=metrics,\n            risk_factor=risk_factor,\n            recommendations=recommendations\n        )\n    \n    def run_performance_diagnostics(self) -> DiagnosticResult:\n        \"\"\"Run performance diagnostics\"\"\""
        },
        "run_performance_diagnostics": {
          "start_line": 158,
          "end_line": 194,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "DiagnosticResult",
          "calls": [
            {
              "name": "DiagnosticResult",
              "line": 187
            },
            {
              "name": "torch.cuda.Event",
              "line": 166
            },
            {
              "name": "torch.cuda.Event",
              "line": 167
            },
            {
              "name": "start_time.record",
              "line": 169
            },
            {
              "name": "....cuda",
              "line": 170
            },
            {
              "name": "end_time.record",
              "line": 171
            },
            {
              "name": "torch.cuda.synchronize",
              "line": 173
            },
            {
              "name": "start_time.elapsed_time",
              "line": 174
            },
            {
              "name": "torch.cuda.empty_cache",
              "line": 177
            },
            {
              "name": "recommendations.append",
              "line": 181
            },
            {
              "name": "recommendations.append",
              "line": 185
            },
            {
              "name": "torch.zeros",
              "line": 170
            },
            {
              "name": "str",
              "line": 185
            }
          ],
          "docstring": "Run performance diagnostics",
          "code_snippet": "        )\n    \n    def run_performance_diagnostics(self) -> DiagnosticResult:\n        \"\"\"Run performance diagnostics\"\"\"\n        metrics = {}\n        recommendations = []\n        risk_factor = 0.0\n        \n        # Test memory allocation speed\n        try:\n            start_time = torch.cuda.Event(enable_timing=True)\n            end_time = torch.cuda.Event(enable_timing=True)\n            \n            start_time.record()\n            test_tensor = torch.zeros(1000000).cuda()\n            end_time.record()\n            \n            torch.cuda.synchronize()\n            metrics[\"memory_allocation_ms\"] = start_time.elapsed_time(end_time)\n            \n            del test_tensor\n            torch.cuda.empty_cache()\n            \n            if metrics[\"memory_allocation_ms\"] > 5:\n                risk_factor += 0.2\n                recommendations.append(\"Slow memory allocation detected\")\n                \n        except Exception as e:\n            risk_factor += 0.4\n            recommendations.append(f\"Memory allocation test failed: {str(e)}\")\n        \n        return DiagnosticResult(\n            diagnostic_type=DiagnosticType.PERFORMANCE,\n            status=\"ok\" if risk_factor < 0.3 else \"warning\",\n            metrics=metrics,\n            risk_factor=risk_factor,\n            recommendations=recommendations\n        )\n    \n    def run_full_diagnostics(self) -> Dict[str, DiagnosticResult]:\n        \"\"\"Run all diagnostics and update history\"\"\""
        },
        "run_full_diagnostics": {
          "start_line": 195,
          "end_line": 219,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": "complex_type",
          "calls": [
            {
              "name": "results.values",
              "line": 204
            },
            {
              "name": "self.get_risk_assessment",
              "line": 208
            },
            {
              "name": "DiagnosticResult",
              "line": 209
            },
            {
              "name": "self.run_system_diagnostics",
              "line": 198
            },
            {
              "name": "self.run_pattern_diagnostics",
              "line": 199
            },
            {
              "name": "self.run_performance_diagnostics",
              "line": 200
            },
            {
              "name": "self.diagnostic_history.append",
              "line": 205
            }
          ],
          "docstring": "Run all diagnostics and update history",
          "code_snippet": "        )\n    \n    def run_full_diagnostics(self) -> Dict[str, DiagnosticResult]:\n        \"\"\"Run all diagnostics and update history\"\"\"\n        results = {\n            \"system\": self.run_system_diagnostics(),\n            \"pattern\": self.run_pattern_diagnostics(),\n            \"performance\": self.run_performance_diagnostics()\n        }\n        \n        # Update diagnostic history\n        for result in results.values():\n            self.diagnostic_history.append(result)\n        \n        # Calculate overall risk assessment\n        overall_risk, insights = self.get_risk_assessment()\n        results[\"risk_assessment\"] = DiagnosticResult(\n            diagnostic_type=DiagnosticType.RISK,\n            status=\"ok\" if overall_risk < 0.3 else \"warning\",\n            metrics={\"overall_risk\": overall_risk},\n            risk_factor=overall_risk,\n            recommendations=insights\n        )\n        \n        return results\n\ndef test_integrated_diagnostics():\n    \"\"\"Test the integrated diagnostic system\"\"\"\n    diagnostics = CortexDiagnostics()"
        }
      },
      "class_variables": [],
      "bases": []
    }
  },
  "functions": {
    "test_integrated_diagnostics": {
      "start_line": 219,
      "end_line": 248,
      "parameters": [],
      "return_type": null,
      "calls": [
        {
          "name": "CortexDiagnostics",
          "line": 221
        },
        {
          "name": "print",
          "line": 223
        },
        {
          "name": "range",
          "line": 226
        },
        {
          "name": "print",
          "line": 227
        },
        {
          "name": "diagnostics.run_full_diagnostics",
          "line": 228
        },
        {
          "name": "results.items",
          "line": 230
        },
        {
          "name": "print",
          "line": 231
        },
        {
          "name": "print",
          "line": 232
        },
        {
          "name": "print",
          "line": 233
        },
        {
          "name": "print",
          "line": 236
        },
        {
          "name": "print",
          "line": 241
        },
        {
          "name": "result.metrics.items",
          "line": 242
        },
        {
          "name": "print",
          "line": 238
        },
        {
          "name": "isinstance",
          "line": 243
        },
        {
          "name": "diagnostic_type.upper",
          "line": 231
        },
        {
          "name": "print",
          "line": 244
        },
        {
          "name": "print",
          "line": 246
        }
      ],
      "docstring": "Test the integrated diagnostic system",
      "code_snippet": "        return results\n\ndef test_integrated_diagnostics():\n    \"\"\"Test the integrated diagnostic system\"\"\"\n    diagnostics = CortexDiagnostics()\n    \n    print(\"\\nRunning Integrated Cortex Diagnostics...\")\n    \n    # Run diagnostics multiple times to build history\n    for i in range(3):\n        print(f\"\\nDiagnostic Run {i+1}:\")\n        results = diagnostics.run_full_diagnostics()\n        \n        for diagnostic_type, result in results.items():\n            print(f\"\\n{diagnostic_type.upper()}:\")\n            print(f\"Status: {result.status}\")\n            print(f\"Risk Factor: {result.risk_factor:.2f}\")\n            \n            if result.recommendations:\n                print(\"Recommendations:\")\n                for rec in result.recommendations:\n                    print(f\"- {rec}\")\n            \n            if result.metrics:\n                print(\"Metrics:\")\n                for metric, value in result.metrics.items():\n                    if isinstance(value, float):\n                        print(f\"- {metric}: {value:.2f}\")\n                    else:\n                        print(f\"- {metric}: {value}\")\n\nif __name__ == \"__main__\":\n    test_integrated_diagnostics()"
    }
  },
  "constants": {}
}