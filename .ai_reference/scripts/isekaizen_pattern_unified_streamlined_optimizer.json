{
  "path": "D:\\Projects\\isekaiZen\\machine-learning-optimizer\\isekaizen\\pattern\\unified\\streamlined_optimizer.py",
  "imports": [
    {
      "name": "logging",
      "line": 11
    },
    {
      "name": "math",
      "line": 12
    },
    {
      "name": "torch",
      "line": 13
    },
    {
      "name": "collections.deque",
      "line": 14
    },
    {
      "name": "multiprocessing",
      "line": 120
    }
  ],
  "classes": {
    "StreamlinedBatchOptimizer": {
      "start_line": 18,
      "end_line": 270,
      "methods": {
        "__init__": {
          "start_line": 36,
          "end_line": 91,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "model"
            },
            {
              "name": "device"
            },
            {
              "name": "min_batch"
            },
            {
              "name": "max_batch"
            },
            {
              "name": "max_history_len"
            },
            {
              "name": "total_epochs"
            },
            {
              "name": "run_diagnostics"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "deque",
              "line": 70
            },
            {
              "name": "logger.info",
              "line": 88
            },
            {
              "name": "torch.device",
              "line": 59
            },
            {
              "name": "self._run_hardware_diagnostics",
              "line": 86
            },
            {
              "name": "torch.cuda.is_available",
              "line": 59
            }
          ],
          "docstring": "\n        Initialize the streamlined batch optimizer.\n        \n        Args:\n            model: PyTorch model being trained\n            device: Computing device (CPU/GPU)\n            min_batch: Minimum allowed batch size\n            max_batch: Maximum allowed batch size\n            max_history_len: Maximum history length to maintain\n            total_epochs: Total expected training epochs\n            run_diagnostics: Whether to run hardware diagnostics\n        ",
          "code_snippet": "    \"\"\"\n    \n    def __init__(\n        self, \n        model,\n        device=None,\n        min_batch=16,\n        max_batch=256,\n        max_history_len=3,\n        total_epochs=100,\n        run_diagnostics=False\n    ):\n        \"\"\"\n        Initialize the streamlined batch optimizer.\n        \n        Args:\n            model: PyTorch model being trained\n            device: Computing device (CPU/GPU)\n            min_batch: Minimum allowed batch size\n            max_batch: Maximum allowed batch size\n            max_history_len: Maximum history length to maintain\n            total_epochs: Total expected training epochs\n            run_diagnostics: Whether to run hardware diagnostics\n        \"\"\"\n        self.model = model\n        self.device = device or torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n        self.min_batch = min_batch\n        self.max_batch = max_batch\n        self.epoch = 0\n        self.total_epochs = total_epochs\n        \n        # Set aliases for trainer compatibility\n        self.min_batch_size = min_batch\n        self.max_batch_size = max_batch\n        \n        # Use efficient fixed-length collection\n        self.batch_history = deque(maxlen=max_history_len)\n        \n        # Metric tracking\n        self.train_acc = None\n        self.val_acc = None\n        self.best_val_acc = 0.0\n        self.consecutive_no_improvement = 0\n        self.underfitting_detected = False\n        self.prevent_batch_size_decrease = False\n        \n        # Batch size adjustment parameters\n        self.overfitting_threshold = 1.0  # Train acc > val acc by this percentage\n        self.stagnation_threshold = 3     # Consecutive epochs without improvement\n        \n        # Run hardware diagnostics if requested\n        if run_diagnostics:\n            self._run_hardware_diagnostics()\n            \n        logger.info(\"StreamlinedBatchOptimizer initialized with batch size range: [%d, %d]\",\n                  self.min_batch, self.max_batch)\n    \n    def _run_hardware_diagnostics(self):\n        \"\"\"Run diagnostics to adjust batch size limits based on hardware characteristics.\"\"\"\n        logger.info(\"Running hardware diagnostics for batch size boundaries\")"
        },
        "_run_hardware_diagnostics": {
          "start_line": 91,
          "end_line": 146,
          "parameters": [
            {
              "name": "self"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logger.info",
              "line": 93
            },
            {
              "name": "any",
              "line": 132
            },
            {
              "name": "logger.info",
              "line": 144
            },
            {
              "name": "torch.cuda.is_available",
              "line": 96
            },
            {
              "name": "logger.info",
              "line": 138
            },
            {
              "name": "torch.cuda.get_device_properties",
              "line": 100
            },
            {
              "name": "logger.debug",
              "line": 104
            },
            {
              "name": "max",
              "line": 108
            },
            {
              "name": "logger.info",
              "line": 110
            },
            {
              "name": "multiprocessing.cpu_count",
              "line": 121
            },
            {
              "name": "max",
              "line": 123
            },
            {
              "name": "logger.info",
              "line": 124
            },
            {
              "name": "isinstance",
              "line": 132
            },
            {
              "name": "logger.warning",
              "line": 114
            },
            {
              "name": "logger.warning",
              "line": 127
            },
            {
              "name": "self.model.modules",
              "line": 133
            },
            {
              "name": "str",
              "line": 114
            },
            {
              "name": "str",
              "line": 127
            }
          ],
          "docstring": "Run diagnostics to adjust batch size limits based on hardware characteristics.",
          "code_snippet": "                  self.min_batch, self.max_batch)\n    \n    def _run_hardware_diagnostics(self):\n        \"\"\"Run diagnostics to adjust batch size limits based on hardware characteristics.\"\"\"\n        logger.info(\"Running hardware diagnostics for batch size boundaries\")\n        \n        # Calculate minimum batch size based on hardware characteristics\n        if self.device.type == \"cuda\" and torch.cuda.is_available():\n            # Get properties of the specified or default GPU\n            device_index = self.device.index if self.device.index is not None else 0\n            try:\n                device_props = torch.cuda.get_device_properties(device_index)\n                \n                # Get the number of Streaming Multiprocessors (SMs)\n                sm_count = device_props.multi_processor_count\n                logger.debug(f\"GPU has {sm_count} streaming multiprocessors\")\n                \n                # Calculate minimum batch size that ensures reasonable SM utilization\n                # We want at least 1 sample per 4 SMs to ensure reasonable parallelism\n                min_batch = max(1, sm_count // 4)\n                \n                logger.info(f\"Calculated hardware-based minimum batch size: {min_batch} based on {sm_count} streaming multiprocessors\")\n                self.min_batch = min_batch\n                    \n            except Exception as e:\n                logger.warning(f\"Error calculating GPU-based min batch size: {str(e)}\")\n                # Fallback to a safe default for GPU\n                self.min_batch = 4\n        else:\n            # For CPU, base it on core count\n            try:\n                import multiprocessing\n                cpu_count = multiprocessing.cpu_count()\n                # CPUs benefit from smaller min batch sizes due to different parallelism model\n                min_batch = max(1, cpu_count // 8)\n                logger.info(f\"Calculated hardware-based minimum batch size: {min_batch} based on {cpu_count} CPU cores\")\n                self.min_batch = min_batch\n            except Exception as e:\n                logger.warning(f\"Error calculating CPU-based min batch size: {str(e)}\")\n                # Absolute fallback\n                self.min_batch = 1\n        \n        # Detect BatchNorm for better batch size selection\n        has_batch_norm = any(isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)) \n                             for m in self.model.modules())\n        \n        # Ensure minimum batch size is at least 2 for BatchNorm\n        if has_batch_norm and self.min_batch < 2:\n            self.min_batch = 2\n            logger.info(\"Adjusted minimum batch size to 2 for BatchNorm compatibility\")\n        \n        # Update aliases for trainer compatibility\n        self.min_batch_size = self.min_batch\n        self.max_batch_size = self.max_batch\n        \n        logger.info(f\"Batch size boundaries: [{self.min_batch}, {self.max_batch}]\")\n\n    \n    def update_metrics(self, train_acc, val_acc, improved=False):\n        \"\"\""
        },
        "update_metrics": {
          "start_line": 147,
          "end_line": 178,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "train_acc"
            },
            {
              "name": "val_acc"
            },
            {
              "name": "improved"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "logger.info",
              "line": 173
            }
          ],
          "docstring": "\n        Update metrics used for batch size decisions.\n        \n        Args:\n            train_acc: Training accuracy\n            val_acc: Validation accuracy\n            improved: Whether validation accuracy improved\n        ",
          "code_snippet": "\n    \n    def update_metrics(self, train_acc, val_acc, improved=False):\n        \"\"\"\n        Update metrics used for batch size decisions.\n        \n        Args:\n            train_acc: Training accuracy\n            val_acc: Validation accuracy\n            improved: Whether validation accuracy improved\n        \"\"\"\n        self.train_acc = train_acc\n        self.val_acc = val_acc\n        \n        # Update improvement tracking\n        if improved:\n            self.consecutive_no_improvement = 0\n            if val_acc > self.best_val_acc:\n                self.best_val_acc = val_acc\n        else:\n            self.consecutive_no_improvement += 1\n        \n        # Check for underfitting - clear definition: val_acc > train_acc\n        self.underfitting_detected = val_acc > train_acc\n        \n        # Update protection flag\n        if self.underfitting_detected:\n            self.prevent_batch_size_decrease = True\n            logger.info(\"Underfitting detected (val_acc > train_acc) - preventing batch size decrease\")\n        else:\n            # Only clear protection after underfitting resolves\n            self.prevent_batch_size_decrease = False\n    \n    def get_optimal_batch_size(self, current_batch=None):\n        \"\"\"\n        Calculate optimal batch size for the next epoch."
        },
        "get_optimal_batch_size": {
          "start_line": 178,
          "end_line": 241,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "current_batch"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "self.batch_history.append",
              "line": 238
            },
            {
              "name": "any",
              "line": 197
            },
            {
              "name": "self.batch_history.append",
              "line": 204
            },
            {
              "name": "round",
              "line": 200
            },
            {
              "name": "max",
              "line": 201
            },
            {
              "name": "logger.info",
              "line": 202
            },
            {
              "name": "max",
              "line": 219
            },
            {
              "name": "min",
              "line": 230
            },
            {
              "name": "isinstance",
              "line": 197
            },
            {
              "name": "math.log2",
              "line": 200
            },
            {
              "name": "min",
              "line": 201
            },
            {
              "name": "int",
              "line": 219
            },
            {
              "name": "logger.info",
              "line": 222
            },
            {
              "name": "int",
              "line": 230
            },
            {
              "name": "logger.info",
              "line": 233
            },
            {
              "name": "self.model.modules",
              "line": 198
            }
          ],
          "docstring": "\n        Calculate optimal batch size for the next epoch.\n        \n        Args:\n            current_batch: Current batch size (None for initial batch size)\n            \n        Returns:\n            Optimal batch size for next epoch\n        ",
          "code_snippet": "            self.prevent_batch_size_decrease = False\n    \n    def get_optimal_batch_size(self, current_batch=None):\n        \"\"\"\n        Calculate optimal batch size for the next epoch.\n        \n        Args:\n            current_batch: Current batch size (None for initial batch size)\n            \n        Returns:\n            Optimal batch size for next epoch\n        \"\"\"\n        # Increment epoch counter\n        self.epoch += 1\n        \n        # Initialize with middle of range for first epoch\n        if current_batch is None or self.epoch == 1:\n            # Use 1/3 of range as starting point for initial batch size\n            batch_size = self.min_batch + (self.max_batch - self.min_batch) // 3\n            \n            # For better BatchNorm, use power-of-2 batch size if possible\n            has_batch_norm = any(isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)) \n                                for m in self.model.modules())\n            if has_batch_norm:\n                power = round(math.log2(batch_size))\n                batch_size = max(self.min_batch, min(self.max_batch, 2 ** power))\n                logger.info(\"Using power-of-2 batch size for BatchNorm model: %d\", batch_size)\n            \n            self.batch_history.append(batch_size)\n            return batch_size\n        \n        # For subsequent epochs, use current batch as base\n        batch_size = current_batch\n        \n        # Apply batch size adjustment based on two clear rules:\n        # 1. Decrease batch size for overfitting\n        train_test_gap = (self.train_acc or 0) - (self.val_acc or 0)\n        \n        # Rule 1: Overfitting - train accuracy exceeds validation by threshold\n        if train_test_gap > self.overfitting_threshold:\n            # Only decrease if not in underfitting protection mode\n            if not self.prevent_batch_size_decrease:\n                # Use a fixed, more moderate reduction factor (75% of current size)\n                new_batch = max(self.min_batch, int(batch_size * 0.75))\n                \n                if new_batch != batch_size:\n                    logger.info(\"Decreasing batch size due to overfitting (gap: %.2f%%): %d -> %d\",\n                             train_test_gap, batch_size, new_batch)\n                    batch_size = new_batch\n        \n        # Rule 2: Stagnation - validation hasn't improved for N consecutive epochs\n        elif self.consecutive_no_improvement >= self.stagnation_threshold and self.epoch > 3:\n            # Increase batch size to escape local minimum\n            increase_factor = 1.25  # 25% increase\n            new_batch = min(self.max_batch, int(batch_size * increase_factor))\n            \n            if new_batch != batch_size:\n                logger.info(\"Increasing batch size due to %d epochs of stagnation: %d -> %d\",\n                         self.consecutive_no_improvement, batch_size, new_batch)\n                batch_size = new_batch\n        \n        # Store in history\n        self.batch_history.append(batch_size)\n        return batch_size\n        \n    # Legacy methods for compatibility with existing code\n    \n    def update_batch_size(self, train_loss, val_loss, pattern_metrics=None, verbose=False):"
        },
        "update_batch_size": {
          "start_line": 243,
          "end_line": 270,
          "parameters": [
            {
              "name": "self"
            },
            {
              "name": "train_loss"
            },
            {
              "name": "val_loss"
            },
            {
              "name": "pattern_metrics"
            },
            {
              "name": "verbose"
            }
          ],
          "return_type": null,
          "calls": [
            {
              "name": "pattern_metrics.get",
              "line": 258
            },
            {
              "name": "pattern_metrics.get",
              "line": 259
            },
            {
              "name": "self.get_optimal_batch_size",
              "line": 268
            },
            {
              "name": "self.update_metrics",
              "line": 262
            }
          ],
          "docstring": "\n        Compatibility method for UnifiedRatioTrainer.\n        \n        Args:\n            train_loss: Training loss\n            val_loss: Validation loss\n            pattern_metrics: Additional pattern metrics\n            verbose: Whether to print verbose output\n            \n        Returns:\n            Current batch size\n        ",
          "code_snippet": "    # Legacy methods for compatibility with existing code\n    \n    def update_batch_size(self, train_loss, val_loss, pattern_metrics=None, verbose=False):\n        \"\"\"\n        Compatibility method for UnifiedRatioTrainer.\n        \n        Args:\n            train_loss: Training loss\n            val_loss: Validation loss\n            pattern_metrics: Additional pattern metrics\n            verbose: Whether to print verbose output\n            \n        Returns:\n            Current batch size\n        \"\"\"\n        # Extract metrics if provided\n        if pattern_metrics:\n            train_acc = pattern_metrics.get('train_acc')\n            val_acc = pattern_metrics.get('val_acc')\n            \n            if train_acc is not None and val_acc is not None:\n                self.update_metrics(train_acc, val_acc)\n                \n        # Return current batch size (updates happen in get_optimal_batch_size)\n        if self.batch_history:\n            return self.batch_history[-1]\n        else:\n            return self.get_optimal_batch_size()"
        }
      },
      "class_variables": [],
      "bases": [],
      "docstring": "\n    Streamlined batch size optimizer with simplified decision logic.\n    \n    This optimizer implements a clear, non-conflicting set of rules for\n    batch size adjustments based only on overfitting detection and\n    validation stagnation.\n    \n    Attributes:\n        model: Model being trained\n        device: Training device\n        min_batch: Minimum allowed batch size\n        max_batch: Maximum allowed batch size\n        batch_history: Deque of recent batch sizes with bounded length\n        consecutive_no_improvement: Counter for validation stagnation\n        underfitting_detected: Flag for underfitting detection\n    "
    }
  },
  "functions": {},
  "constants": {}
}